{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "145_PyTorch_Tricks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T8fuVdeJ2ily",
        "fS8Qzs_S8Lo3",
        "bGFUQPW4EzyW",
        "gYI6oXV2zwX5",
        "ElRC_UyfwEOT",
        "VeCwrRaRyUNG",
        "B1wXhJpVzwFn",
        "o77f6yEAzv0b",
        "5QgaUjHXzwPE",
        "8iUk8aILzwSZ",
        "SnlJ9ELgzwVP",
        "ohdMNkUQNBQ7",
        "JUn7Wei7zwbp",
        "imaxKeZGZtMd",
        "DcFCJj0DDCfJ",
        "8zZ5zNkcEOpJ",
        "V7LIvq8nEy60",
        "zjqTJwQtEx6i",
        "BT2KrdfdLdwY",
        "jtZVDwbzNYsy",
        "vX5XZlAEruzL",
        "tgO1eS7Zsrem",
        "ILWXL973ux5h",
        "ROAwd1T6vePz",
        "J1zJV81TxE_b",
        "j541So3MyFzt",
        "BCGGt3N_y8RQ",
        "1H8EcBe_0TQT",
        "w24eoBxC1Aa4",
        "oBT6K7QX0swj"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sylar257/My-data-science-tool-kit/blob/master/145_PyTorch_Tricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_rSH7id15Fy",
        "colab_type": "text"
      },
      "source": [
        "# 145 PyTorch Tricks\n",
        "This is a series of useful PyTorch tricks inspired by **vainaijr** in his [YouTube channel](https://www.youtube.com/watch?v=nnHQT9JnY74&list=PLUY8w37x-QUUkawz-cBnjLpvaZWvPZh_s&index=2&t=29s).<br>\n",
        "This notebook is an implementation of all these techniques and is designed in a way to best demonstrate their usefulness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8fuVdeJ2ily",
        "colab_type": "text"
      },
      "source": [
        "# Trick #1\n",
        "Visualization model using `torchsummaryX`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQnXYH10AdtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from Utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTuqtpoh5_mF",
        "colab_type": "text"
      },
      "source": [
        "Here we will build a Single-shot-detection model with just 20 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzAiSJmbAz4h",
        "colab_type": "code",
        "outputId": "23be6a00-28b3-44c1-e45f-9f738eeb8158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Create SSD300 with pretrained weights in the base-architecture\n",
        "n_classes = 20\n",
        "model = SSD300(n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 107MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbRH1ipJBrYR",
        "colab_type": "code",
        "outputId": "51470b25-223b-4fe8-d256-95eba43b1a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# install torchsummaryX\n",
        "!pip install torchsummaryX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading https://files.pythonhosted.org/packages/36/23/87eeaaf70daa61aa21495ece0969c50c446b8fd42c4b8905af264b40fe7f/torchsummaryX-1.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (0.25.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.3.1+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->torchsummaryX) (1.12.0)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcUf7Bgp6dZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummaryX import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B78vIOLG6vY9",
        "colab_type": "text"
      },
      "source": [
        "`summary(model, input)` takes our intentional model and a pseudo input **with the correct shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0Hgjdv6pLu",
        "colab_type": "code",
        "outputId": "1fa823e8-b2e6-486a-aef0-3b9632d8eb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# pseudo input of batch size = 3, num_channel = 3, pixel: 300x300\n",
        "summary(model, torch.zeros((3,3,300,300)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================================================================\n",
            "                                         Kernel Shape        Output Shape  \\\n",
            "Layer                                                                       \n",
            "0_base.Conv2d_conv1_1                   [3, 64, 3, 3]   [3, 64, 300, 300]   \n",
            "1_base.BatchNorm2d_bn_1_1                        [64]   [3, 64, 300, 300]   \n",
            "2_base.Conv2d_conv1_2                  [64, 64, 3, 3]   [3, 64, 300, 300]   \n",
            "3_base.BatchNorm2d_bn_1_2                        [64]   [3, 64, 300, 300]   \n",
            "4_base.MaxPool2d_pool1                              -   [3, 64, 150, 150]   \n",
            "5_base.Conv2d_conv2_1                 [64, 128, 3, 3]  [3, 128, 150, 150]   \n",
            "6_base.BatchNorm2d_bn_2_1                       [128]  [3, 128, 150, 150]   \n",
            "7_base.Conv2d_conv2_2                [128, 128, 3, 3]  [3, 128, 150, 150]   \n",
            "8_base.BatchNorm2d_bn_2_2                       [128]  [3, 128, 150, 150]   \n",
            "9_base.MaxPool2d_pool2                              -    [3, 128, 75, 75]   \n",
            "10_base.Conv2d_conv3_1               [128, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "11_base.BatchNorm2d_bn_3_1                      [256]    [3, 256, 75, 75]   \n",
            "12_base.Conv2d_conv3_2               [256, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "13_base.BatchNorm2d_bn_3_2                      [256]    [3, 256, 75, 75]   \n",
            "14_base.Conv2d_conv3_3               [256, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "15_base.BatchNorm2d_bn_3_3                      [256]    [3, 256, 75, 75]   \n",
            "16_base.MaxPool2d_pool3                             -    [3, 256, 38, 38]   \n",
            "17_base.Conv2d_conv4_1               [256, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "18_base.BatchNorm2d_bn_4_1                      [512]    [3, 512, 38, 38]   \n",
            "19_base.Conv2d_conv4_2               [512, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "20_base.BatchNorm2d_bn_4_2                      [512]    [3, 512, 38, 38]   \n",
            "21_base.Conv2d_conv4_3               [512, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "22_base.BatchNorm2d_bn_4_3                      [512]    [3, 512, 38, 38]   \n",
            "23_base.MaxPool2d_pool4                             -    [3, 512, 19, 19]   \n",
            "24_base.Conv2d_conv5_1               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "25_base.BatchNorm2d_bn_5_1                      [512]    [3, 512, 19, 19]   \n",
            "26_base.Conv2d_conv5_2               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "27_base.BatchNorm2d_bn_5_2                      [512]    [3, 512, 19, 19]   \n",
            "28_base.Conv2d_conv5_3               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "29_base.BatchNorm2d_bn_5_3                      [512]    [3, 512, 19, 19]   \n",
            "30_base.MaxPool2d_pool5                             -    [3, 512, 19, 19]   \n",
            "31_base.Conv2d_conv6                [512, 1024, 3, 3]   [3, 1024, 19, 19]   \n",
            "32_base.Conv2d_conv7               [1024, 1024, 1, 1]   [3, 1024, 19, 19]   \n",
            "33_aux_convs.Conv2d_conv8_1         [1024, 256, 1, 1]    [3, 256, 19, 19]   \n",
            "34_aux_convs.Conv2d_conv8_2          [256, 512, 3, 3]    [3, 512, 10, 10]   \n",
            "35_aux_convs.Conv2d_conv9_1          [512, 128, 1, 1]    [3, 128, 10, 10]   \n",
            "36_aux_convs.Conv2d_conv9_2          [128, 256, 3, 3]      [3, 256, 5, 5]   \n",
            "37_aux_convs.Conv2d_conv10_1         [256, 128, 1, 1]      [3, 128, 5, 5]   \n",
            "38_aux_convs.Conv2d_conv10_2         [128, 256, 3, 3]      [3, 256, 3, 3]   \n",
            "39_aux_convs.Conv2d_conv11_1         [256, 128, 1, 1]      [3, 128, 3, 3]   \n",
            "40_aux_convs.Conv2d_conv11_2         [128, 256, 3, 3]      [3, 256, 1, 1]   \n",
            "41_pred_convs.Conv2d_loc_conv4_3      [512, 16, 3, 3]     [3, 16, 38, 38]   \n",
            "42_pred_convs.Conv2d_loc_conv7       [1024, 24, 3, 3]     [3, 24, 19, 19]   \n",
            "43_pred_convs.Conv2d_loc_conv8_2      [512, 24, 3, 3]     [3, 24, 10, 10]   \n",
            "44_pred_convs.Conv2d_loc_conv9_2      [256, 24, 3, 3]       [3, 24, 5, 5]   \n",
            "45_pred_convs.Conv2d_loc_conv10_2     [256, 16, 3, 3]       [3, 16, 3, 3]   \n",
            "46_pred_convs.Conv2d_loc_conv11_2     [256, 16, 3, 3]       [3, 16, 1, 1]   \n",
            "47_pred_convs.Conv2d_cl_conv4_3       [512, 80, 3, 3]     [3, 80, 38, 38]   \n",
            "48_pred_convs.Conv2d_cl_conv7       [1024, 120, 3, 3]    [3, 120, 19, 19]   \n",
            "49_pred_convs.Conv2d_cl_conv8_2      [512, 120, 3, 3]    [3, 120, 10, 10]   \n",
            "50_pred_convs.Conv2d_cl_conv9_2      [256, 120, 3, 3]      [3, 120, 5, 5]   \n",
            "51_pred_convs.Conv2d_cl_conv10_2      [256, 80, 3, 3]       [3, 80, 3, 3]   \n",
            "52_pred_convs.Conv2d_cl_conv11_2      [256, 80, 3, 3]       [3, 80, 1, 1]   \n",
            "\n",
            "                                      Params     Mult-Adds  \n",
            "Layer                                                       \n",
            "0_base.Conv2d_conv1_1                 1.792k       155.52M  \n",
            "1_base.BatchNorm2d_bn_1_1              128.0          64.0  \n",
            "2_base.Conv2d_conv1_2                36.928k      3.31776G  \n",
            "3_base.BatchNorm2d_bn_1_2              128.0          64.0  \n",
            "4_base.MaxPool2d_pool1                     -             -  \n",
            "5_base.Conv2d_conv2_1                73.856k      1.65888G  \n",
            "6_base.BatchNorm2d_bn_2_1              256.0         128.0  \n",
            "7_base.Conv2d_conv2_2               147.584k      3.31776G  \n",
            "8_base.BatchNorm2d_bn_2_2              256.0         128.0  \n",
            "9_base.MaxPool2d_pool2                     -             -  \n",
            "10_base.Conv2d_conv3_1              295.168k      1.65888G  \n",
            "11_base.BatchNorm2d_bn_3_1             512.0         256.0  \n",
            "12_base.Conv2d_conv3_2               590.08k      3.31776G  \n",
            "13_base.BatchNorm2d_bn_3_2             512.0         256.0  \n",
            "14_base.Conv2d_conv3_3               590.08k      3.31776G  \n",
            "15_base.BatchNorm2d_bn_3_3             512.0         256.0  \n",
            "16_base.MaxPool2d_pool3                    -             -  \n",
            "17_base.Conv2d_conv4_1              1.18016M  1.703411712G  \n",
            "18_base.BatchNorm2d_bn_4_1            1.024k         512.0  \n",
            "19_base.Conv2d_conv4_2             2.359808M  3.406823424G  \n",
            "20_base.BatchNorm2d_bn_4_2            1.024k         512.0  \n",
            "21_base.Conv2d_conv4_3             2.359808M  3.406823424G  \n",
            "22_base.BatchNorm2d_bn_4_3            1.024k         512.0  \n",
            "23_base.MaxPool2d_pool4                    -             -  \n",
            "24_base.Conv2d_conv5_1             2.359808M   851.705856M  \n",
            "25_base.BatchNorm2d_bn_5_1            1.024k         512.0  \n",
            "26_base.Conv2d_conv5_2             2.359808M   851.705856M  \n",
            "27_base.BatchNorm2d_bn_5_2            1.024k         512.0  \n",
            "28_base.Conv2d_conv5_3             2.359808M   851.705856M  \n",
            "29_base.BatchNorm2d_bn_5_3            1.024k         512.0  \n",
            "30_base.MaxPool2d_pool5                    -             -  \n",
            "31_base.Conv2d_conv6               4.719616M  1.703411712G  \n",
            "32_base.Conv2d_conv7                 1.0496M   378.535936M  \n",
            "33_aux_convs.Conv2d_conv8_1           262.4k    94.633984M  \n",
            "34_aux_convs.Conv2d_conv8_2         1.18016M     117.9648M  \n",
            "35_aux_convs.Conv2d_conv9_1          65.664k       6.5536M  \n",
            "36_aux_convs.Conv2d_conv9_2         295.168k       7.3728M  \n",
            "37_aux_convs.Conv2d_conv10_1         32.896k        819.2k  \n",
            "38_aux_convs.Conv2d_conv10_2        295.168k     2.654208M  \n",
            "39_aux_convs.Conv2d_conv11_1         32.896k      294.912k  \n",
            "40_aux_convs.Conv2d_conv11_2        295.168k      294.912k  \n",
            "41_pred_convs.Conv2d_loc_conv4_3     73.744k   106.463232M  \n",
            "42_pred_convs.Conv2d_loc_conv7      221.208k    79.847424M  \n",
            "43_pred_convs.Conv2d_loc_conv8_2    110.616k      11.0592M  \n",
            "44_pred_convs.Conv2d_loc_conv9_2      55.32k       1.3824M  \n",
            "45_pred_convs.Conv2d_loc_conv10_2     36.88k      331.776k  \n",
            "46_pred_convs.Conv2d_loc_conv11_2     36.88k       36.864k  \n",
            "47_pred_convs.Conv2d_cl_conv4_3      368.72k    532.31616M  \n",
            "48_pred_convs.Conv2d_cl_conv7       1.10604M    399.23712M  \n",
            "49_pred_convs.Conv2d_cl_conv8_2      553.08k       55.296M  \n",
            "50_pred_convs.Conv2d_cl_conv9_2       276.6k        6.912M  \n",
            "51_pred_convs.Conv2d_cl_conv10_2      184.4k      1.65888M  \n",
            "52_pred_convs.Conv2d_cl_conv11_2      184.4k       184.32k  \n",
            "--------------------------------------------------------------------------------------------------\n",
            "                             Totals\n",
            "Total params              26.15976M\n",
            "Trainable params          26.15976M\n",
            "Non-trainable params            0.0\n",
            "Mult-Adds             31.323761792G\n",
            "==================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_base.Conv2d_conv1_1</th>\n",
              "      <td>[3, 64, 3, 3]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>1792.0</td>\n",
              "      <td>1.555200e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_base.BatchNorm2d_bn_1_1</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_base.Conv2d_conv1_2</th>\n",
              "      <td>[64, 64, 3, 3]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>36928.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_base.BatchNorm2d_bn_1_2</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_base.MaxPool2d_pool1</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 64, 150, 150]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_base.Conv2d_conv2_1</th>\n",
              "      <td>[64, 128, 3, 3]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>73856.0</td>\n",
              "      <td>1.658880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_base.BatchNorm2d_bn_2_1</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.280000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_base.Conv2d_conv2_2</th>\n",
              "      <td>[128, 128, 3, 3]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>147584.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_base.BatchNorm2d_bn_2_2</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.280000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_base.MaxPool2d_pool2</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 128, 75, 75]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_base.Conv2d_conv3_1</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>1.658880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_base.BatchNorm2d_bn_3_1</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_base.Conv2d_conv3_2</th>\n",
              "      <td>[256, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>590080.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_base.BatchNorm2d_bn_3_2</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_base.Conv2d_conv3_3</th>\n",
              "      <td>[256, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>590080.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_base.BatchNorm2d_bn_3_3</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_base.MaxPool2d_pool3</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 256, 38, 38]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_base.Conv2d_conv4_1</th>\n",
              "      <td>[256, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1180160.0</td>\n",
              "      <td>1.703412e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_base.BatchNorm2d_bn_4_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_base.Conv2d_conv4_2</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>3.406823e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_base.BatchNorm2d_bn_4_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_base.Conv2d_conv4_3</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>3.406823e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_base.BatchNorm2d_bn_4_3</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_base.MaxPool2d_pool4</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_base.Conv2d_conv5_1</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_base.BatchNorm2d_bn_5_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_base.Conv2d_conv5_2</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_base.BatchNorm2d_bn_5_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_base.Conv2d_conv5_3</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_base.BatchNorm2d_bn_5_3</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_base.MaxPool2d_pool5</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_base.Conv2d_conv6</th>\n",
              "      <td>[512, 1024, 3, 3]</td>\n",
              "      <td>[3, 1024, 19, 19]</td>\n",
              "      <td>4719616.0</td>\n",
              "      <td>1.703412e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_base.Conv2d_conv7</th>\n",
              "      <td>[1024, 1024, 1, 1]</td>\n",
              "      <td>[3, 1024, 19, 19]</td>\n",
              "      <td>1049600.0</td>\n",
              "      <td>3.785359e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_aux_convs.Conv2d_conv8_1</th>\n",
              "      <td>[1024, 256, 1, 1]</td>\n",
              "      <td>[3, 256, 19, 19]</td>\n",
              "      <td>262400.0</td>\n",
              "      <td>9.463398e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_aux_convs.Conv2d_conv8_2</th>\n",
              "      <td>[256, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 10, 10]</td>\n",
              "      <td>1180160.0</td>\n",
              "      <td>1.179648e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_aux_convs.Conv2d_conv9_1</th>\n",
              "      <td>[512, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 10, 10]</td>\n",
              "      <td>65664.0</td>\n",
              "      <td>6.553600e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_aux_convs.Conv2d_conv9_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 5, 5]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>7.372800e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37_aux_convs.Conv2d_conv10_1</th>\n",
              "      <td>[256, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 5, 5]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>8.192000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38_aux_convs.Conv2d_conv10_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 3, 3]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>2.654208e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39_aux_convs.Conv2d_conv11_1</th>\n",
              "      <td>[256, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 3, 3]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>2.949120e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40_aux_convs.Conv2d_conv11_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 1, 1]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>2.949120e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41_pred_convs.Conv2d_loc_conv4_3</th>\n",
              "      <td>[512, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 38, 38]</td>\n",
              "      <td>73744.0</td>\n",
              "      <td>1.064632e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42_pred_convs.Conv2d_loc_conv7</th>\n",
              "      <td>[1024, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 19, 19]</td>\n",
              "      <td>221208.0</td>\n",
              "      <td>7.984742e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43_pred_convs.Conv2d_loc_conv8_2</th>\n",
              "      <td>[512, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 10, 10]</td>\n",
              "      <td>110616.0</td>\n",
              "      <td>1.105920e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44_pred_convs.Conv2d_loc_conv9_2</th>\n",
              "      <td>[256, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 5, 5]</td>\n",
              "      <td>55320.0</td>\n",
              "      <td>1.382400e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45_pred_convs.Conv2d_loc_conv10_2</th>\n",
              "      <td>[256, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 3, 3]</td>\n",
              "      <td>36880.0</td>\n",
              "      <td>3.317760e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46_pred_convs.Conv2d_loc_conv11_2</th>\n",
              "      <td>[256, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 1, 1]</td>\n",
              "      <td>36880.0</td>\n",
              "      <td>3.686400e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47_pred_convs.Conv2d_cl_conv4_3</th>\n",
              "      <td>[512, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 38, 38]</td>\n",
              "      <td>368720.0</td>\n",
              "      <td>5.323162e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48_pred_convs.Conv2d_cl_conv7</th>\n",
              "      <td>[1024, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 19, 19]</td>\n",
              "      <td>1106040.0</td>\n",
              "      <td>3.992371e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49_pred_convs.Conv2d_cl_conv8_2</th>\n",
              "      <td>[512, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 10, 10]</td>\n",
              "      <td>553080.0</td>\n",
              "      <td>5.529600e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50_pred_convs.Conv2d_cl_conv9_2</th>\n",
              "      <td>[256, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 5, 5]</td>\n",
              "      <td>276600.0</td>\n",
              "      <td>6.912000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51_pred_convs.Conv2d_cl_conv10_2</th>\n",
              "      <td>[256, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 3, 3]</td>\n",
              "      <td>184400.0</td>\n",
              "      <td>1.658880e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52_pred_convs.Conv2d_cl_conv11_2</th>\n",
              "      <td>[256, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 1, 1]</td>\n",
              "      <td>184400.0</td>\n",
              "      <td>1.843200e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Kernel Shape  ...     Mult-Adds\n",
              "Layer                                                  ...              \n",
              "0_base.Conv2d_conv1_1                   [3, 64, 3, 3]  ...  1.555200e+08\n",
              "1_base.BatchNorm2d_bn_1_1                        [64]  ...  6.400000e+01\n",
              "2_base.Conv2d_conv1_2                  [64, 64, 3, 3]  ...  3.317760e+09\n",
              "3_base.BatchNorm2d_bn_1_2                        [64]  ...  6.400000e+01\n",
              "4_base.MaxPool2d_pool1                              -  ...           NaN\n",
              "5_base.Conv2d_conv2_1                 [64, 128, 3, 3]  ...  1.658880e+09\n",
              "6_base.BatchNorm2d_bn_2_1                       [128]  ...  1.280000e+02\n",
              "7_base.Conv2d_conv2_2                [128, 128, 3, 3]  ...  3.317760e+09\n",
              "8_base.BatchNorm2d_bn_2_2                       [128]  ...  1.280000e+02\n",
              "9_base.MaxPool2d_pool2                              -  ...           NaN\n",
              "10_base.Conv2d_conv3_1               [128, 256, 3, 3]  ...  1.658880e+09\n",
              "11_base.BatchNorm2d_bn_3_1                      [256]  ...  2.560000e+02\n",
              "12_base.Conv2d_conv3_2               [256, 256, 3, 3]  ...  3.317760e+09\n",
              "13_base.BatchNorm2d_bn_3_2                      [256]  ...  2.560000e+02\n",
              "14_base.Conv2d_conv3_3               [256, 256, 3, 3]  ...  3.317760e+09\n",
              "15_base.BatchNorm2d_bn_3_3                      [256]  ...  2.560000e+02\n",
              "16_base.MaxPool2d_pool3                             -  ...           NaN\n",
              "17_base.Conv2d_conv4_1               [256, 512, 3, 3]  ...  1.703412e+09\n",
              "18_base.BatchNorm2d_bn_4_1                      [512]  ...  5.120000e+02\n",
              "19_base.Conv2d_conv4_2               [512, 512, 3, 3]  ...  3.406823e+09\n",
              "20_base.BatchNorm2d_bn_4_2                      [512]  ...  5.120000e+02\n",
              "21_base.Conv2d_conv4_3               [512, 512, 3, 3]  ...  3.406823e+09\n",
              "22_base.BatchNorm2d_bn_4_3                      [512]  ...  5.120000e+02\n",
              "23_base.MaxPool2d_pool4                             -  ...           NaN\n",
              "24_base.Conv2d_conv5_1               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "25_base.BatchNorm2d_bn_5_1                      [512]  ...  5.120000e+02\n",
              "26_base.Conv2d_conv5_2               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "27_base.BatchNorm2d_bn_5_2                      [512]  ...  5.120000e+02\n",
              "28_base.Conv2d_conv5_3               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "29_base.BatchNorm2d_bn_5_3                      [512]  ...  5.120000e+02\n",
              "30_base.MaxPool2d_pool5                             -  ...           NaN\n",
              "31_base.Conv2d_conv6                [512, 1024, 3, 3]  ...  1.703412e+09\n",
              "32_base.Conv2d_conv7               [1024, 1024, 1, 1]  ...  3.785359e+08\n",
              "33_aux_convs.Conv2d_conv8_1         [1024, 256, 1, 1]  ...  9.463398e+07\n",
              "34_aux_convs.Conv2d_conv8_2          [256, 512, 3, 3]  ...  1.179648e+08\n",
              "35_aux_convs.Conv2d_conv9_1          [512, 128, 1, 1]  ...  6.553600e+06\n",
              "36_aux_convs.Conv2d_conv9_2          [128, 256, 3, 3]  ...  7.372800e+06\n",
              "37_aux_convs.Conv2d_conv10_1         [256, 128, 1, 1]  ...  8.192000e+05\n",
              "38_aux_convs.Conv2d_conv10_2         [128, 256, 3, 3]  ...  2.654208e+06\n",
              "39_aux_convs.Conv2d_conv11_1         [256, 128, 1, 1]  ...  2.949120e+05\n",
              "40_aux_convs.Conv2d_conv11_2         [128, 256, 3, 3]  ...  2.949120e+05\n",
              "41_pred_convs.Conv2d_loc_conv4_3      [512, 16, 3, 3]  ...  1.064632e+08\n",
              "42_pred_convs.Conv2d_loc_conv7       [1024, 24, 3, 3]  ...  7.984742e+07\n",
              "43_pred_convs.Conv2d_loc_conv8_2      [512, 24, 3, 3]  ...  1.105920e+07\n",
              "44_pred_convs.Conv2d_loc_conv9_2      [256, 24, 3, 3]  ...  1.382400e+06\n",
              "45_pred_convs.Conv2d_loc_conv10_2     [256, 16, 3, 3]  ...  3.317760e+05\n",
              "46_pred_convs.Conv2d_loc_conv11_2     [256, 16, 3, 3]  ...  3.686400e+04\n",
              "47_pred_convs.Conv2d_cl_conv4_3       [512, 80, 3, 3]  ...  5.323162e+08\n",
              "48_pred_convs.Conv2d_cl_conv7       [1024, 120, 3, 3]  ...  3.992371e+08\n",
              "49_pred_convs.Conv2d_cl_conv8_2      [512, 120, 3, 3]  ...  5.529600e+07\n",
              "50_pred_convs.Conv2d_cl_conv9_2      [256, 120, 3, 3]  ...  6.912000e+06\n",
              "51_pred_convs.Conv2d_cl_conv10_2      [256, 80, 3, 3]  ...  1.658880e+06\n",
              "52_pred_convs.Conv2d_cl_conv11_2      [256, 80, 3, 3]  ...  1.843200e+05\n",
              "\n",
              "[53 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgGy0J07PYI",
        "colab_type": "text"
      },
      "source": [
        "Final Note: Normally, if we use architectures directly from `TorchVision` or `Keras` we would have nice model summary just like this.<br>\n",
        "This libarary is particular useful when we want to inspect user people's model or a verions that we have modified besed on commonly used models like the example above.<br>\n",
        "In addition, we have a nice visualization of **num of parameters** & **output demension** for each layer which is kind of nice for debugging your own model or simply for reference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS8Qzs_S8Lo3",
        "colab_type": "text"
      },
      "source": [
        "# Trick #2\n",
        "PyTorch Hooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWIJf1TcEv03",
        "colab_type": "text"
      },
      "source": [
        "PyTorch hook is a tool that we can *register* to any **tensor** or **nn.Module** during our computation so that we can monitor what is going on with our `forward` and `backward` loops.<bR>\n",
        "The `forward` is not refered to `nn.Module.forward` bu the `torch.Autograd.Function` object that is the `grad_fn` of a **tensor**.<br>\n",
        "Notice, that a `nn.Module` like `nn.Linear` can have multiple `forward` invocations. It's output is created by two operations, $Y = W*X+B$, *addition* and *multiplication* and thus there will be two `forward` calls. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGFUQPW4EzyW",
        "colab_type": "text"
      },
      "source": [
        "## Hook types\n",
        "1. The Forward Hook\n",
        "2. The Backward Hook\n",
        "\n",
        "A forward hook is excuted during the forward pass, while the backward hook is executed when `backward` function is called both of which are *functions* of `Autograd.Funciton` object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCcDR2L2E8lh",
        "colab_type": "text"
      },
      "source": [
        "A hook in PyTorch is basically a function, with a very specific signature. When we say a hook is executed, in reality, we are talkingabout this function being executed.<br>\n",
        "`grad` is basically the value contained in the `grad` attribute of the tensor **after** `backward` is called. The function is not supposed to modify it's argument. It must either return `None` or a Tensor which will be used in place of `grad` for further gradient computations.<br>\n",
        "The below example clarifies this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt1yLHsIE-kH",
        "colab_type": "code",
        "outputId": "46825495-22c9-4cc0-b18a-53f310620006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "a = torch.ones(10)\n",
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6umlITCaE_-r",
        "colab_type": "code",
        "outputId": "39ee53ac-cf72-4d1c-fe61-2e6966584776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.requires_grad = True\n",
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOXhle3FMu5",
        "colab_type": "code",
        "outputId": "4db600c2-c6d9-41e2-b95a-81b7976e8600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = 2*a\n",
        "b.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBCy0MTPFNw6",
        "colab_type": "code",
        "outputId": "dbcd0199-12a9-4ea3-c8d9-207c92a2b49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(a.is_leaf)\n",
        "print(b.is_leaf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COtQrZf3Gb_M",
        "colab_type": "text"
      },
      "source": [
        "Since `b` is not a **leaf Variable**, its `grad` will by degault be destroyed during computation.<br>\n",
        "We can used `b.retain_grad()` to ask PyTorch to retain its `grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4dnUuoGr7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.retain_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A13yk-8XGteU",
        "colab_type": "code",
        "outputId": "c6e1459b-41ff-49df-b02c-a84687acf16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "c = b.mean()\n",
        "print(f\"requires_grad: {c.requires_grad}\")\n",
        "print(f\"is_lead: {c.is_leaf}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requires_grad: True\n",
            "is_lead: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCBXiXdGvM7",
        "colab_type": "code",
        "outputId": "df1b209d-b5df-4a94-b7c7-d4b28dd92f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# pretend c is the loss being computed\n",
        "c.backward()\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnyGJjm7G9yM",
        "colab_type": "text"
      },
      "source": [
        "Now we redo the experiment but with a **hook** that multiplies `b`'s grad by 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-2bzclHJUs",
        "colab_type": "code",
        "outputId": "6fba9014-a249-431b-85d5-da8482cbe9c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "a = torch.ones(10)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.register_hook(lambda x:print(x))\n",
        "b.mean().backward() # pretend the mean of b is the loss we want to back-prop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtFRGFtlHd0t",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that, the print out is exactly the same result by using **hook** on `b`, and the `lambda` function automatically take the `b.grad` as input.<br>\n",
        "This gives us a sense that hook is tracking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilIASlZvH963",
        "colab_type": "code",
        "outputId": "51f118b1-72f6-4950-f3c0-872184b45606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJA-J_laIA_H",
        "colab_type": "text"
      },
      "source": [
        "There are several uses of functionality as above:\n",
        "1. We can print the *value* of gradient for **debugging**. We can also log them. This is especially useful with `non-leaf` variables whose gradients are freed up unless we perform `retain_grad` upon them. Doing the latter can lead to increased memory retention. Hooks provide much cleaner way to aggregate these values.\n",
        "2. We can modify gradient **during** the backward pass. This is very important. While we can still access the `grad` variable of a tensor in a network, we can only access it after the **entire backward pass** has been processed. For example, we multiplied `b`'s gradient by 2, and now the subsequent gradient calculations, like those of `a`(or any tensor that will depend upon `b` for gradient) used `2*brad(b)` instead of `grad(b)`. In contrast, had we individually updated the parameters **after** the `backward`, we'd have to multily `b.grad` as well as `a.grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHm9_tHdJHt-",
        "colab_type": "code",
        "outputId": "eafe0e32-3579-467d-fb5b-344a59f4a264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# to demonstrate\n",
        "a = torch.ones(10)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.mean().backward()\n",
        "\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r6lGboZJXVn",
        "colab_type": "code",
        "outputId": "146abb5b-dd76-48e7-a2df-2491abd50910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "b.grad *= 2\n",
        "print(a.grad, b.grad) # Note that in this case, a's grad needs to be updated mannually"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbaWOr3vJbWQ",
        "colab_type": "text"
      },
      "source": [
        "## Hooks for nn.Module objects\n",
        "For **backward hook**:\n",
        "`hook(module, grad_input, grad_output)`\n",
        "___\n",
        "For **forward hook**:\n",
        "`hook(module, input, output)`\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQT_tOFZJs6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride=2) # (8-2+0)/2+1 = 4\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I1E-eIqJvZQ",
        "colab_type": "code",
        "outputId": "2cbf707d-6957-4f9d-e74a-1c87a6941013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "Net = myNet()\n",
        "summary(Net,torch.zeros(1,3,8,8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================================================\n",
            "         Kernel Shape   Output Shape Params Mult-Adds\n",
            "Layer                                                \n",
            "0_conv  [3, 10, 2, 2]  [1, 10, 4, 4]  130.0     1.92k\n",
            "1_relu              -  [1, 10, 4, 4]      -         -\n",
            "2_fc1        [160, 5]            [5]  805.0     800.0\n",
            "-------------------------------------------------------\n",
            "                      Totals\n",
            "Total params           935.0\n",
            "Trainable params       935.0\n",
            "Non-trainable params     0.0\n",
            "Mult-Adds              2.72k\n",
            "=======================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_conv</th>\n",
              "      <td>[3, 10, 2, 2]</td>\n",
              "      <td>[1, 10, 4, 4]</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[1, 10, 4, 4]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_fc1</th>\n",
              "      <td>[160, 5]</td>\n",
              "      <td>[5]</td>\n",
              "      <td>805.0</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Kernel Shape   Output Shape  Params  Mult-Adds\n",
              "Layer                                                  \n",
              "0_conv  [3, 10, 2, 2]  [1, 10, 4, 4]   130.0     1920.0\n",
              "1_relu              -  [1, 10, 4, 4]     NaN        NaN\n",
              "2_fc1        [160, 5]            [5]   805.0      800.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iLsBZPUJ6hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hook_fn(m,i,o):\n",
        "    print(m)\n",
        "    print(\"---------Input Grad----------\")\n",
        "\n",
        "    for grad in i:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print(\"None found for input Gradient\")\n",
        "    \n",
        "    print(\"--------Output Grad----------\")\n",
        "    for grad in o:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print(\"None found for output Gradient\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHzpCMysq0zd",
        "colab_type": "code",
        "outputId": "377ab6c8-9591-4236-f959-3e7eaa4b4fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "Net.named_modules"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.named_modules of myNet(\n",
              "  (conv): Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=160, out_features=5, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m11brNsmq9J8",
        "colab_type": "code",
        "outputId": "98618e7c-a1e5-444d-cb41-3ed2e0c4b682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net.conv.register_backward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7fc70953ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWCYFGuZrDiN",
        "colab_type": "code",
        "outputId": "6c9ed40d-f0e7-4094-a119-cb2b442a69c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net.fc1.register_backward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7fc709536b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgqlLmXOrKhc",
        "colab_type": "code",
        "outputId": "6e4cdd1a-3958-4dca-98c1-f547d0b76ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inp = torch.rand(1,3,8,8)\n",
        "out = Net(inp)\n",
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1495, -0.0683,  0.1981,  0.0851, -0.0905], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kweZoTb1rQB8",
        "colab_type": "code",
        "outputId": "14cedf15-2e41-4265-ffe9-6b86b84633c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# pretend we have the following as loss\n",
        "(1-out.mean()).backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=160, out_features=5, bias=True)\n",
            "---------Input Grad----------\n",
            "torch.Size([5])\n",
            "torch.Size([5])\n",
            "--------Output Grad----------\n",
            "torch.Size([5])\n",
            "\n",
            "\n",
            "Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
            "---------Input Grad----------\n",
            "None found for input Gradient\n",
            "torch.Size([10, 3, 2, 2])\n",
            "torch.Size([10])\n",
            "--------Output Grad----------\n",
            "torch.Size([1, 10, 4, 4])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-_oNZPrQsX",
        "colab_type": "text"
      },
      "source": [
        "Note that, the `Linear layer` gets called first because the backward pass actually go through it first and then backprop to the `conv layer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxa-QfPNsG__",
        "colab_type": "text"
      },
      "source": [
        "## Proper way of implementing Hooks(in **back-prop**)er way of implementing Hooks(in **back-prop**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gggioe8JvXQ2",
        "colab_type": "text"
      },
      "source": [
        "We have:\n",
        "1.  torch.autograd.Variable.register_hook (Python method, in Automatic differentiation package)\n",
        "2.  torch.nn.Module.register_backward_hook (Python method, in torch.nn)\n",
        "3.  torch.nn.Module.register_forward_hook\n",
        "\n",
        "The first `register_hook`，is for any **Variable**. It's essentially a **callback** function that is going to be executed every time when `Autograd` gradient is computed.<br>\n",
        "While `Module.register_backward_hook` & `n.Module.register_forward_hook` are for `nn.Module` object and their `hook_fn` shoud take torch:\n",
        "<br>`def hook_fn(m, i, o):` where `i` refers to input and `o` refers to output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIL-6XN9vduD",
        "colab_type": "text"
      },
      "source": [
        "### An example\n",
        "Using `named_parameters` function we can accomplish `gradient modifying/clipping`. <br>\n",
        "The following example does two things:\n",
        "1. Turn gradients of linear biases into zero while back-prop (no updates for biase)\n",
        "2. Make sure that for no gradient going to `conv layer` is less than 0 (all positive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5G2odS-vmgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2,stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "    def forward(self,x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        x.register_hook(lambda grad: torch.clamp(grad, min=0)) # minimun back-prop gradient of value 0\n",
        "\n",
        "        # print whether there is any negative grad\n",
        "        x.register_hook(lambda grad: print(\"Gradients less than zero:\", bool((grad<0).any())))\n",
        "        \n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1zPOxs9z2yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = myNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV_j9ytFz4HL",
        "colab_type": "code",
        "outputId": "17ca2a2e-a15a-4a7e-a81e-a69a18c77811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    print(name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv.weight\n",
            "conv.bias\n",
            "fc1.weight\n",
            "fc1.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSf36kx90BOa",
        "colab_type": "code",
        "outputId": "5b848d26-b650-4f71-d161-863a0c99b331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    if 'fc' in name and 'bias' in name:\n",
        "        print(name, param, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.bias\n",
            "Parameter containing:\n",
            "tensor([-0.0190, -0.0193, -0.0728,  0.0082,  0.0160], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsd-dQl0PJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    if 'fc' in name and 'bias' in name:\n",
        "        # assign zero to bias grad with identical dimensions\n",
        "        param.register_hook(lambda grad: torch.zeros_like(grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-l2x34d0kcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = net(torch.randn(1,3,8,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bAPAHHX0pq8",
        "colab_type": "code",
        "outputId": "b26853f6-a771-40d3-9b3f-830c7a541531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(1-out).mean().backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients less than zero: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quh1OR4606RE",
        "colab_type": "code",
        "outputId": "f6f4c1e2-a0ce-40ef-8a5f-8749d5ad1fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'the bias for linear layer is: {net.fc1.bias.grad}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the bias for linear layer is: tensor([0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYI6oXV2zwX5"
      },
      "source": [
        "# Trick #3\n",
        "`pack_padded_sequence` & `pad_packed_sequence`\n",
        "often used together dynamic RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaCV9F9DkDH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP451m89kSuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a tensor with variable length sequences and pads (25)\n",
        "seqs = torch.LongTensor([[0, 1, 2, 3, 25, 25, 25],\n",
        "                         [4, 5, 25, 25, 25, 25, 25],\n",
        "                         [6, 7, 8, 9, 10, 11, 25]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sudQrogkWzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store lengths of the actual sequences, ignoring padding(25)\n",
        "# These are the points up to which we want the RNN to process the sequence\n",
        "seq_lens = torch.LongTensor([4,3,6]) # number of non-trivial elements in each row"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKndlzr7kqkX",
        "colab_type": "code",
        "outputId": "e7c90632-d494-48f5-ed55-da6336679e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seq_lens, sort_ind = seq_lens.sort(dim=0, descending=True)\n",
        "seq_lens, sort_ind"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6, 4, 3]), tensor([2, 0, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w81KurAXlDaI",
        "colab_type": "code",
        "outputId": "7c0be8f1-2ac3-456a-9791-bf8940714f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seqs = seqs[sort_ind]\n",
        "seqs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  7,  8,  9, 10, 11, 25],\n",
              "        [ 0,  1,  2,  3, 25, 25, 25],\n",
              "        [ 4,  5, 25, 25, 25, 25, 25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU23CdNblMVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an embedding layer, with 0 vectors for the pads\n",
        "embeds = nn.Embedding(num_embeddings=26,\n",
        "                      embedding_dim=10,\n",
        "                      padding_idx=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV6UH9WPmnOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = nn.LSTM(10, 50, bidirectional=False, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJPBWOVwm6g-",
        "colab_type": "code",
        "outputId": "95e28194-655f-49c1-dd80-014bfab64825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# WITHOUT dynamic batching\n",
        "embeddings = embeds(seqs)\n",
        "print(embeddings.size())\n",
        "out_static, _ = lstm(embeddings)\n",
        "out_static.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 7, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 7, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuDUeG_vng7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The number of timesteps in the output will be the same as the total padded timesteps in the input,\n",
        "# since the LSTM computed over the pads\n",
        "assert out_static.size(1) == embeddings.size(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imH2F-wpnzaJ",
        "colab_type": "code",
        "outputId": "4329363a-4fe6-433b-fb90-076b9afdcb22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Look at the output at a timestep that we know is a pad\n",
        "print(out_static[1,-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0821, -0.0592, -0.0492,  0.0023, -0.0777, -0.0576, -0.0531,  0.1315,\n",
            "         0.0021,  0.0473,  0.0195,  0.0764, -0.1129, -0.0334,  0.0724,  0.1498,\n",
            "        -0.0529, -0.0625, -0.0379,  0.0425,  0.0015,  0.1318,  0.0448, -0.0354,\n",
            "         0.1645, -0.0835,  0.0134,  0.0614,  0.0697,  0.0223,  0.0131,  0.0646,\n",
            "        -0.0725, -0.0345,  0.0158, -0.1179,  0.0900,  0.0378, -0.1458,  0.0356,\n",
            "         0.0207, -0.0591, -0.0921, -0.0226,  0.0078,  0.0157,  0.0773,  0.0889,\n",
            "        -0.0189,  0.0382], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1NTw-2wnI5H",
        "colab_type": "text"
      },
      "source": [
        "Now let's try the same process with **Dynamic Batching**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xojQ7wloIAJ",
        "colab_type": "code",
        "outputId": "fec6bf9f-4f1d-46bc-9163-2212ae2c1cf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pack the sequence\n",
        "packed_seqs = pack_padded_sequence(embeddings, seq_lens.tolist(), batch_first=True)\n",
        "print(f'the values in the seq_lens: {seq_lens.tolist()}, with the effective sum of {sum(seq_lens.tolist())}')\n",
        "embeddings.shape,packed_seqs.data.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the values in the seq_lens: [6, 4, 3], with the effective sum of 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 7, 10]), torch.Size([13, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECe_JCb9pLXr",
        "colab_type": "code",
        "outputId": "759fa8ec-e71a-4a76-872b-0e9111716051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out_dynamic, _ = lstm(packed_seqs)\n",
        "out_dynamic.data.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mngu7v5pdB0",
        "colab_type": "code",
        "outputId": "844124f7-1f49-4319-a145-646216f9584d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out_dynamic, lens = pad_packed_sequence(out_dynamic, batch_first=True)\n",
        "out_dynamic.size(), lens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 6, 50]), tensor([6, 4, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqXUQgz4ppLt",
        "colab_type": "text"
      },
      "source": [
        "Note that here, `out_dynamic` is padded in shape of `[3,6,50]` instead of `[3,7,50]` because we know we can discard one pad from all rows to make it even more compact. <br>\n",
        "In short, `6` is the longest sequence length in all batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9XWpws1par8",
        "colab_type": "code",
        "outputId": "64fce72c-c0c4-4a92-b157-7a0b02f11483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "assert out_dynamic.size(1) != embeddings.size(1)\n",
        "print(out_dynamic.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 6, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcsdoAMApFB0",
        "colab_type": "code",
        "outputId": "ed485fb4-bbf3-4150-e1d4-310fa463aa78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Look at the output at a timestep that we know is a pad\n",
        "print(out_dynamic[1, -1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibkIMBGao4_7",
        "colab_type": "text"
      },
      "source": [
        "Final note:<br>\n",
        "* `pack_padded_sequence` removes pads, flattens by timestep, and keeps track of **effective batch_size** at each timestep\n",
        "* The RNN computes only on the effective batch size \"b_t\" at each timestep while save computation from computing *pads*\n",
        "* This is why we sort, so that top \"b_t\" rows at timestep \"t\" are aligned with the top \"b_t\"\" outputs from timestep \"t-1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElRC_UyfwEOT",
        "colab_type": "text"
      },
      "source": [
        "# Trick #4\n",
        "Torchviz to visualize PyTorch execution graphs and traces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LZJ7O8F0gc-",
        "colab_type": "code",
        "outputId": "0aaa0939-5149-46df-e9a4-0bd5eef0b5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.3.1+cu100)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.17.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=0affc6da8f5f01332395a52be0b79c445c33958b783e4ccfcd50fedb29b878bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCT2cafk0ht1",
        "colab_type": "text"
      },
      "source": [
        "### Let's start with a basic example(base MLP model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhrQ0obV1ovZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchviz import make_dot, make_dot_from_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEQ44ppZ1w52",
        "colab_type": "code",
        "outputId": "3d5088a9-4826-4d80-cc45-c499fdc90702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('W0', nn.Linear(8,16))\n",
        "model.add_module('tanh', nn.Tanh())\n",
        "model.add_module('W1', nn.Linear(16,1))\n",
        "\n",
        "inp = torch.randn(1,8)\n",
        "\n",
        "make_dot(model(inp), params = dict(model.named_parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f00957d9630>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"266pt\" height=\"309pt\"\n viewBox=\"0.00 0.00 265.50 309.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 305)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-305 261.5,-305 261.5,4 -4,4\"/>\n<!-- 139640484763240 -->\n<g id=\"node1\" class=\"node\">\n<title>139640484763240</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"171,-21 67,-21 67,0 171,0 171,-21\"/>\n<text text-anchor=\"middle\" x=\"119\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640484762400 -->\n<g id=\"node2\" class=\"node\">\n<title>139640484762400</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"56,-91 0,-91 0,-57 56,-57 56,-91\"/>\n<text text-anchor=\"middle\" x=\"28\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W1.bias</text>\n<text text-anchor=\"middle\" x=\"28\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139640484762400&#45;&gt;139640484763240 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139640484762400&#45;&gt;139640484763240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M52.3863,-56.9832C65.6468,-47.73 81.9815,-36.3316 95.1567,-27.1379\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"97.4986,-29.7717 103.6965,-21.1788 93.4928,-24.0311 97.4986,-29.7717\"/>\n</g>\n<!-- 139640484763352 -->\n<g id=\"node3\" class=\"node\">\n<title>139640484763352</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-84.5 74.5,-84.5 74.5,-63.5 163.5,-63.5 163.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"119\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TanhBackward</text>\n</g>\n<!-- 139640484763352&#45;&gt;139640484763240 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139640484763352&#45;&gt;139640484763240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M119,-63.2281C119,-54.5091 119,-41.9699 119,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.5001,-31.1128 119,-21.1128 115.5001,-31.1129 122.5001,-31.1128\"/>\n</g>\n<!-- 139640484763520 -->\n<g id=\"node4\" class=\"node\">\n<title>139640484763520</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"169,-154.5 65,-154.5 65,-133.5 169,-133.5 169,-154.5\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640484763520&#45;&gt;139640484763352 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139640484763520&#45;&gt;139640484763352</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M117.3038,-133.3685C117.5945,-123.1925 118.0411,-107.5606 118.4031,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.9063,-94.8275 118.6934,-84.7315 114.9091,-94.6275 121.9063,-94.8275\"/>\n</g>\n<!-- 139640484763632 -->\n<g id=\"node5\" class=\"node\">\n<title>139640484763632</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"104,-231 48,-231 48,-197 104,-197 104,-231\"/>\n<text text-anchor=\"middle\" x=\"76\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W0.bias</text>\n<text text-anchor=\"middle\" x=\"76\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 139640484763632&#45;&gt;139640484763520 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139640484763632&#45;&gt;139640484763520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M86.1348,-196.6966C92.0172,-186.6535 99.4448,-173.9722 105.5395,-163.5667\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.6454,-165.189 110.6794,-154.7913 102.6052,-161.6512 108.6454,-165.189\"/>\n</g>\n<!-- 139640484763688 -->\n<g id=\"node6\" class=\"node\">\n<title>139640484763688</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"195.5,-224.5 122.5,-224.5 122.5,-203.5 195.5,-203.5 195.5,-224.5\"/>\n<text text-anchor=\"middle\" x=\"159\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640484763688&#45;&gt;139640484763520 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139640484763688&#45;&gt;139640484763520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M152.6211,-203.3685C146.2688,-192.7814 136.3731,-176.2886 128.6223,-163.3705\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.5852,-161.5057 123.4389,-154.7315 125.5827,-165.1072 131.5852,-161.5057\"/>\n</g>\n<!-- 139640484763800 -->\n<g id=\"node7\" class=\"node\">\n<title>139640484763800</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"193.5,-301 124.5,-301 124.5,-267 193.5,-267 193.5,-301\"/>\n<text text-anchor=\"middle\" x=\"159\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W0.weight</text>\n<text text-anchor=\"middle\" x=\"159\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 8)</text>\n</g>\n<!-- 139640484763800&#45;&gt;139640484763688 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139640484763800&#45;&gt;139640484763688</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159,-266.6966C159,-257.0634 159,-245.003 159,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.5001,-234.7912 159,-224.7913 155.5001,-234.7913 162.5001,-234.7912\"/>\n</g>\n<!-- 139640484763408 -->\n<g id=\"node8\" class=\"node\">\n<title>139640484763408</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"257.5,-84.5 184.5,-84.5 184.5,-63.5 257.5,-63.5 257.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640484763408&#45;&gt;139640484763240 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139640484763408&#45;&gt;139640484763240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M203.6971,-63.2281C187.4805,-53.1325 163.0365,-37.9149 144.5702,-26.4187\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"146.3865,-23.4266 136.0474,-21.1128 142.6869,-29.3692 146.3865,-23.4266\"/>\n</g>\n<!-- 139640484763576 -->\n<g id=\"node9\" class=\"node\">\n<title>139640484763576</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"256.5,-161 187.5,-161 187.5,-127 256.5,-127 256.5,-161\"/>\n<text text-anchor=\"middle\" x=\"222\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W1.weight</text>\n<text text-anchor=\"middle\" x=\"222\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 16)</text>\n</g>\n<!-- 139640484763576&#45;&gt;139640484763408 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139640484763576&#45;&gt;139640484763408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.7528,-126.6966C221.6152,-117.0634 221.4429,-105.003 221.2979,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"224.7967,-94.7402 221.1542,-84.7913 217.7975,-94.8403 224.7967,-94.7402\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P22juagj2XOP",
        "colab_type": "text"
      },
      "source": [
        "The method is built for directed graphs of PyTorch operations, built during **forward** propagation and showing which operations will be called on **backward**. <br>\n",
        "It omits subgraphs which do not require gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrGtgTXg3CP1",
        "colab_type": "text"
      },
      "source": [
        "### Visualiza AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGh60Zs3t7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models import AlexNet\n",
        "\n",
        "model = AlexNet()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhMRGffO3zo7",
        "colab_type": "code",
        "outputId": "c13229bb-5362-4762-8a2c-a50fbba24479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = torch.randn(1,3,227,227).requires_grad_(True)\n",
        "y = model(x)\n",
        "make_dot(y, params = dict(list(model.named_parameters()) + [('x',x)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f008c7eda90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"562pt\" height=\"896pt\"\n viewBox=\"0.00 0.00 562.36 896.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.6283 .6283) rotate(0) translate(4 1422)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1422 891,-1422 891,4 -4,4\"/>\n<!-- 139640333723520 -->\n<g id=\"node1\" class=\"node\">\n<title>139640333723520</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"772.5,-21 668.5,-21 668.5,0 772.5,0 772.5,-21\"/>\n<text text-anchor=\"middle\" x=\"720.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640333723744 -->\n<g id=\"node2\" class=\"node\">\n<title>139640333723744</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"655.5,-91 567.5,-91 567.5,-57 655.5,-57 655.5,-91\"/>\n<text text-anchor=\"middle\" x=\"611.5\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.6.bias</text>\n<text text-anchor=\"middle\" x=\"611.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1000)</text>\n</g>\n<!-- 139640333723744&#45;&gt;139640333723520 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139640333723744&#45;&gt;139640333723520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M640.71,-56.9832C657.0516,-47.4631 677.2911,-35.6722 693.2964,-26.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"695.2906,-29.2369 702.1694,-21.1788 691.7669,-23.1884 695.2906,-29.2369\"/>\n</g>\n<!-- 139640333725480 -->\n<g id=\"node3\" class=\"node\">\n<title>139640333725480</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"767.5,-84.5 673.5,-84.5 673.5,-63.5 767.5,-63.5 767.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"720.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333725480&#45;&gt;139640333723520 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139640333725480&#45;&gt;139640333723520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M720.5,-63.2281C720.5,-54.5091 720.5,-41.9699 720.5,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"724.0001,-31.1128 720.5,-21.1128 717.0001,-31.1129 724.0001,-31.1128\"/>\n</g>\n<!-- 139640333722288 -->\n<g id=\"node4\" class=\"node\">\n<title>139640333722288</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"767.5,-154.5 663.5,-154.5 663.5,-133.5 767.5,-133.5 767.5,-154.5\"/>\n<text text-anchor=\"middle\" x=\"715.5\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640333722288&#45;&gt;139640333725480 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139640333722288&#45;&gt;139640333725480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M716.2594,-133.3685C716.9862,-123.1925 718.1028,-107.5606 719.0078,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"722.512,-94.9555 719.7335,-84.7315 715.5298,-94.4567 722.512,-94.9555\"/>\n</g>\n<!-- 139640333722008 -->\n<g id=\"node5\" class=\"node\">\n<title>139640333722008</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"651.5,-231 563.5,-231 563.5,-197 651.5,-197 651.5,-231\"/>\n<text text-anchor=\"middle\" x=\"607.5\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.4.bias</text>\n<text text-anchor=\"middle\" x=\"607.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096)</text>\n</g>\n<!-- 139640333722008&#45;&gt;139640333722288 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139640333722008&#45;&gt;139640333722288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M633.9198,-196.8761C651.0968,-185.7428 673.3632,-171.3109 690.2931,-160.3378\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"692.5955,-163.0165 699.0834,-154.6404 688.7882,-157.1424 692.5955,-163.0165\"/>\n</g>\n<!-- 139640333725536 -->\n<g id=\"node6\" class=\"node\">\n<title>139640333725536</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"761,-224.5 670,-224.5 670,-203.5 761,-203.5 761,-224.5\"/>\n<text text-anchor=\"middle\" x=\"715.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139640333725536&#45;&gt;139640333722288 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139640333725536&#45;&gt;139640333722288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M715.5,-203.3685C715.5,-193.1925 715.5,-177.5606 715.5,-164.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"719.0001,-164.7315 715.5,-154.7315 712.0001,-164.7316 719.0001,-164.7315\"/>\n</g>\n<!-- 139640333721728 -->\n<g id=\"node7\" class=\"node\">\n<title>139640333721728</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"758.5,-294.5 664.5,-294.5 664.5,-273.5 758.5,-273.5 758.5,-294.5\"/>\n<text text-anchor=\"middle\" x=\"711.5\" y=\"-280.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333721728&#45;&gt;139640333725536 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139640333721728&#45;&gt;139640333725536</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M712.1075,-273.3685C712.689,-263.1925 713.5822,-247.5606 714.3062,-234.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"717.8105,-234.915 714.8868,-224.7315 710.8219,-234.5156 717.8105,-234.915\"/>\n</g>\n<!-- 139640333723240 -->\n<g id=\"node8\" class=\"node\">\n<title>139640333723240</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"763.5,-358 659.5,-358 659.5,-337 763.5,-337 763.5,-358\"/>\n<text text-anchor=\"middle\" x=\"711.5\" y=\"-344.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640333723240&#45;&gt;139640333721728 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139640333723240&#45;&gt;139640333721728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.5,-336.7281C711.5,-328.0091 711.5,-315.4699 711.5,-304.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"715.0001,-304.6128 711.5,-294.6128 708.0001,-304.6129 715.0001,-304.6128\"/>\n</g>\n<!-- 139640333722680 -->\n<g id=\"node9\" class=\"node\">\n<title>139640333722680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"647.5,-428 559.5,-428 559.5,-394 647.5,-394 647.5,-428\"/>\n<text text-anchor=\"middle\" x=\"603.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.1.bias</text>\n<text text-anchor=\"middle\" x=\"603.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096)</text>\n</g>\n<!-- 139640333722680&#45;&gt;139640333723240 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139640333722680&#45;&gt;139640333723240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M632.442,-393.9832C648.6337,-384.4631 668.6875,-372.6722 684.546,-363.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"686.4912,-366.2645 693.3376,-358.1788 682.9432,-360.2302 686.4912,-366.2645\"/>\n</g>\n<!-- 139640333724808 -->\n<g id=\"node10\" class=\"node\">\n<title>139640333724808</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"757,-421.5 666,-421.5 666,-400.5 757,-400.5 757,-421.5\"/>\n<text text-anchor=\"middle\" x=\"711.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139640333724808&#45;&gt;139640333723240 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139640333724808&#45;&gt;139640333723240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.5,-400.2281C711.5,-391.5091 711.5,-378.9699 711.5,-368.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"715.0001,-368.1128 711.5,-358.1128 708.0001,-368.1129 715.0001,-368.1128\"/>\n</g>\n<!-- 139640333724192 -->\n<g id=\"node11\" class=\"node\">\n<title>139640333724192</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"762,-491.5 649,-491.5 649,-470.5 762,-470.5 762,-491.5\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-477.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n</g>\n<!-- 139640333724192&#45;&gt;139640333724808 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139640333724192&#45;&gt;139640333724808</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M706.4113,-470.3685C707.2835,-460.1925 708.6234,-444.5606 709.7093,-431.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"713.2133,-431.9939 710.5802,-421.7315 706.2388,-431.3961 713.2133,-431.9939\"/>\n</g>\n<!-- 139640333722848 -->\n<g id=\"node12\" class=\"node\">\n<title>139640333722848</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"788.5,-555 622.5,-555 622.5,-534 788.5,-534 788.5,-555\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AdaptiveAvgPool2DBackward</text>\n</g>\n<!-- 139640333722848&#45;&gt;139640333724192 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139640333722848&#45;&gt;139640333724192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-533.7281C705.5,-525.0091 705.5,-512.4699 705.5,-501.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-501.6128 705.5,-491.6128 702.0001,-501.6129 709.0001,-501.6128\"/>\n</g>\n<!-- 139640333440112 -->\n<g id=\"node13\" class=\"node\">\n<title>139640333440112</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"795.5,-612 615.5,-612 615.5,-591 795.5,-591 795.5,-612\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-598.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139640333440112&#45;&gt;139640333722848 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139640333440112&#45;&gt;139640333722848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-590.7787C705.5,-583.6134 705.5,-573.9517 705.5,-565.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-565.1732 705.5,-555.1732 702.0001,-565.1732 709.0001,-565.1732\"/>\n</g>\n<!-- 139640333440784 -->\n<g id=\"node14\" class=\"node\">\n<title>139640333440784</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"752.5,-669 658.5,-669 658.5,-648 752.5,-648 752.5,-669\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-655.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333440784&#45;&gt;139640333440112 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139640333440784&#45;&gt;139640333440112</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-647.7787C705.5,-640.6134 705.5,-630.9517 705.5,-622.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-622.1732 705.5,-612.1732 702.0001,-622.1732 709.0001,-622.1732\"/>\n</g>\n<!-- 139640333441960 -->\n<g id=\"node15\" class=\"node\">\n<title>139640333441960</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"786.5,-726 624.5,-726 624.5,-705 786.5,-705 786.5,-726\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-712.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333441960&#45;&gt;139640333440784 -->\n<g id=\"edge14\" class=\"edge\">\n<title>139640333441960&#45;&gt;139640333440784</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-704.7787C705.5,-697.6134 705.5,-687.9517 705.5,-679.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-679.1732 705.5,-669.1732 702.0001,-679.1732 709.0001,-679.1732\"/>\n</g>\n<!-- 139640333442968 -->\n<g id=\"node16\" class=\"node\">\n<title>139640333442968</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"635.5,-789.5 541.5,-789.5 541.5,-768.5 635.5,-768.5 635.5,-789.5\"/>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-775.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333442968&#45;&gt;139640333441960 -->\n<g id=\"edge15\" class=\"edge\">\n<title>139640333442968&#45;&gt;139640333441960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M608.0832,-768.3715C626.8966,-758.1608 655.5379,-742.6162 676.902,-731.0212\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"678.7335,-734.0094 685.8529,-726.1631 675.3944,-727.8571 678.7335,-734.0094\"/>\n</g>\n<!-- 139640333441512 -->\n<g id=\"node17\" class=\"node\">\n<title>139640333441512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"669.5,-853 507.5,-853 507.5,-832 669.5,-832 669.5,-853\"/>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-839.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333441512&#45;&gt;139640333442968 -->\n<g id=\"edge16\" class=\"edge\">\n<title>139640333441512&#45;&gt;139640333442968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M588.5,-831.7281C588.5,-823.0091 588.5,-810.4699 588.5,-799.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"592.0001,-799.6128 588.5,-789.6128 585.0001,-799.6129 592.0001,-799.6128\"/>\n</g>\n<!-- 139640333442408 -->\n<g id=\"node18\" class=\"node\">\n<title>139640333442408</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"521.5,-916.5 427.5,-916.5 427.5,-895.5 521.5,-895.5 521.5,-916.5\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-902.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333442408&#45;&gt;139640333441512 -->\n<g id=\"edge17\" class=\"edge\">\n<title>139640333442408&#45;&gt;139640333441512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M493.581,-895.3715C511.8299,-885.2066 539.5689,-869.7555 560.3548,-858.1774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"562.3237,-861.087 569.3567,-853.1631 558.9174,-854.9717 562.3237,-861.087\"/>\n</g>\n<!-- 139640333440560 -->\n<g id=\"node19\" class=\"node\">\n<title>139640333440560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"555.5,-980 393.5,-980 393.5,-959 555.5,-959 555.5,-980\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-966.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333440560&#45;&gt;139640333442408 -->\n<g id=\"edge18\" class=\"edge\">\n<title>139640333440560&#45;&gt;139640333442408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M474.5,-958.7281C474.5,-950.0091 474.5,-937.4699 474.5,-926.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.0001,-926.6128 474.5,-916.6128 471.0001,-926.6129 478.0001,-926.6128\"/>\n</g>\n<!-- 139640333440224 -->\n<g id=\"node20\" class=\"node\">\n<title>139640333440224</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"407.5,-1043.5 227.5,-1043.5 227.5,-1022.5 407.5,-1022.5 407.5,-1043.5\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1029.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139640333440224&#45;&gt;139640333440560 -->\n<g id=\"edge19\" class=\"edge\">\n<title>139640333440224&#45;&gt;139640333440560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M343.7783,-1022.3715C369.8946,-1011.8086 410.1242,-995.5374 439.0559,-983.8357\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.4396,-987.0515 448.3977,-980.0573 437.8149,-980.5622 440.4396,-987.0515\"/>\n</g>\n<!-- 139640333440448 -->\n<g id=\"node21\" class=\"node\">\n<title>139640333440448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"364.5,-1107 270.5,-1107 270.5,-1086 364.5,-1086 364.5,-1107\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1093.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333440448&#45;&gt;139640333440224 -->\n<g id=\"edge20\" class=\"edge\">\n<title>139640333440448&#45;&gt;139640333440224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-1085.7281C317.5,-1077.0091 317.5,-1064.4699 317.5,-1053.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-1053.6128 317.5,-1043.6128 314.0001,-1053.6129 321.0001,-1053.6128\"/>\n</g>\n<!-- 139640333442240 -->\n<g id=\"node22\" class=\"node\">\n<title>139640333442240</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"398.5,-1164 236.5,-1164 236.5,-1143 398.5,-1143 398.5,-1164\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1150.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333442240&#45;&gt;139640333440448 -->\n<g id=\"edge21\" class=\"edge\">\n<title>139640333442240&#45;&gt;139640333440448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-1142.7787C317.5,-1135.6134 317.5,-1125.9517 317.5,-1117.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-1117.1732 317.5,-1107.1732 314.0001,-1117.1732 321.0001,-1117.1732\"/>\n</g>\n<!-- 139640333442856 -->\n<g id=\"node23\" class=\"node\">\n<title>139640333442856</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"250.5,-1227.5 70.5,-1227.5 70.5,-1206.5 250.5,-1206.5 250.5,-1227.5\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1213.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139640333442856&#45;&gt;139640333442240 -->\n<g id=\"edge22\" class=\"edge\">\n<title>139640333442856&#45;&gt;139640333442240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M186.7783,-1206.3715C212.8946,-1195.8086 253.1242,-1179.5374 282.0559,-1167.8357\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.4396,-1171.0515 291.3977,-1164.0573 280.8149,-1164.5622 283.4396,-1171.0515\"/>\n</g>\n<!-- 139640333439776 -->\n<g id=\"node24\" class=\"node\">\n<title>139640333439776</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"207.5,-1291 113.5,-1291 113.5,-1270 207.5,-1270 207.5,-1291\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1277.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333439776&#45;&gt;139640333442856 -->\n<g id=\"edge23\" class=\"edge\">\n<title>139640333439776&#45;&gt;139640333442856</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.5,-1269.7281C160.5,-1261.0091 160.5,-1248.4699 160.5,-1237.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.0001,-1237.6128 160.5,-1227.6128 157.0001,-1237.6129 164.0001,-1237.6128\"/>\n</g>\n<!-- 139640333440840 -->\n<g id=\"node25\" class=\"node\">\n<title>139640333440840</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"241.5,-1348 79.5,-1348 79.5,-1327 241.5,-1327 241.5,-1348\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1334.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333440840&#45;&gt;139640333439776 -->\n<g id=\"edge24\" class=\"edge\">\n<title>139640333440840&#45;&gt;139640333439776</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.5,-1326.7787C160.5,-1319.6134 160.5,-1309.9517 160.5,-1301.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.0001,-1301.1732 160.5,-1291.1732 157.0001,-1301.1732 164.0001,-1301.1732\"/>\n</g>\n<!-- 139640333440896 -->\n<g id=\"node26\" class=\"node\">\n<title>139640333440896</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"93,-1418 0,-1418 0,-1384 93,-1384 93,-1418\"/>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-1404.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">x</text>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-1391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 3, 227, 227)</text>\n</g>\n<!-- 139640333440896&#45;&gt;139640333440840 -->\n<g id=\"edge25\" class=\"edge\">\n<title>139640333440896&#45;&gt;139640333440840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.0499,-1383.9832C94.3009,-1374.3741 115.705,-1362.4516 132.5167,-1353.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.2956,-1356.1027 141.3286,-1348.1788 130.8892,-1349.9874 134.2956,-1356.1027\"/>\n</g>\n<!-- 139640333439944 -->\n<g id=\"node27\" class=\"node\">\n<title>139640333439944</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"209.5,-1418 111.5,-1418 111.5,-1384 209.5,-1384 209.5,-1418\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1404.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.0.weight</text>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 3, 11, 11)</text>\n</g>\n<!-- 139640333439944&#45;&gt;139640333440840 -->\n<g id=\"edge26\" class=\"edge\">\n<title>139640333439944&#45;&gt;139640333440840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.5,-1383.9832C160.5,-1376.1157 160.5,-1366.6973 160.5,-1358.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.0001,-1358.3686 160.5,-1348.3687 157.0001,-1358.3687 164.0001,-1358.3686\"/>\n</g>\n<!-- 139640333441232 -->\n<g id=\"node28\" class=\"node\">\n<title>139640333441232</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"311.5,-1418 227.5,-1418 227.5,-1384 311.5,-1384 311.5,-1418\"/>\n<text text-anchor=\"middle\" x=\"269.5\" y=\"-1404.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.0.bias</text>\n<text text-anchor=\"middle\" x=\"269.5\" y=\"-1391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 139640333441232&#45;&gt;139640333440840 -->\n<g id=\"edge27\" class=\"edge\">\n<title>139640333441232&#45;&gt;139640333440840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.29,-1383.9832C223.9484,-1374.4631 203.7089,-1362.6722 187.7036,-1353.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.2331,-1350.1884 178.8306,-1348.1788 185.7094,-1356.2369 189.2331,-1350.1884\"/>\n</g>\n<!-- 139640333443024 -->\n<g id=\"node29\" class=\"node\">\n<title>139640333443024</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"366.5,-1234 268.5,-1234 268.5,-1200 366.5,-1200 366.5,-1234\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1220.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.3.weight</text>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1207.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (192, 64, 5, 5)</text>\n</g>\n<!-- 139640333443024&#45;&gt;139640333442240 -->\n<g id=\"edge28\" class=\"edge\">\n<title>139640333443024&#45;&gt;139640333442240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-1199.9832C317.5,-1192.1157 317.5,-1182.6973 317.5,-1174.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-1174.3686 317.5,-1164.3687 314.0001,-1174.3687 321.0001,-1174.3686\"/>\n</g>\n<!-- 139640333441456 -->\n<g id=\"node30\" class=\"node\">\n<title>139640333441456</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"468.5,-1234 384.5,-1234 384.5,-1200 468.5,-1200 468.5,-1234\"/>\n<text text-anchor=\"middle\" x=\"426.5\" y=\"-1220.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.3.bias</text>\n<text text-anchor=\"middle\" x=\"426.5\" y=\"-1207.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (192)</text>\n</g>\n<!-- 139640333441456&#45;&gt;139640333442240 -->\n<g id=\"edge29\" class=\"edge\">\n<title>139640333441456&#45;&gt;139640333442240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M397.29,-1199.9832C380.9484,-1190.4631 360.7089,-1178.6722 344.7036,-1169.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"346.2331,-1166.1884 335.8306,-1164.1788 342.7094,-1172.2369 346.2331,-1166.1884\"/>\n</g>\n<!-- 139640333442352 -->\n<g id=\"node31\" class=\"node\">\n<title>139640333442352</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"523.5,-1050 425.5,-1050 425.5,-1016 523.5,-1016 523.5,-1050\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-1036.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.6.weight</text>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-1023.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (384, 192, 3, 3)</text>\n</g>\n<!-- 139640333442352&#45;&gt;139640333440560 -->\n<g id=\"edge30\" class=\"edge\">\n<title>139640333442352&#45;&gt;139640333440560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M474.5,-1015.9832C474.5,-1008.1157 474.5,-998.6973 474.5,-990.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.0001,-990.3686 474.5,-980.3687 471.0001,-990.3687 478.0001,-990.3686\"/>\n</g>\n<!-- 139640333441792 -->\n<g id=\"node32\" class=\"node\">\n<title>139640333441792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"625.5,-1050 541.5,-1050 541.5,-1016 625.5,-1016 625.5,-1050\"/>\n<text text-anchor=\"middle\" x=\"583.5\" y=\"-1036.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.6.bias</text>\n<text text-anchor=\"middle\" x=\"583.5\" y=\"-1023.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (384)</text>\n</g>\n<!-- 139640333441792&#45;&gt;139640333440560 -->\n<g id=\"edge31\" class=\"edge\">\n<title>139640333441792&#45;&gt;139640333440560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M554.29,-1015.9832C537.9484,-1006.4631 517.7089,-994.6722 501.7036,-985.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"503.2331,-982.1884 492.8306,-980.1788 499.7094,-988.2369 503.2331,-982.1884\"/>\n</g>\n<!-- 139640333441176 -->\n<g id=\"node33\" class=\"node\">\n<title>139640333441176</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"637.5,-923 539.5,-923 539.5,-889 637.5,-889 637.5,-923\"/>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-909.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.8.weight</text>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-896.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 384, 3, 3)</text>\n</g>\n<!-- 139640333441176&#45;&gt;139640333441512 -->\n<g id=\"edge32\" class=\"edge\">\n<title>139640333441176&#45;&gt;139640333441512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M588.5,-888.9832C588.5,-881.1157 588.5,-871.6973 588.5,-863.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"592.0001,-863.3686 588.5,-853.3687 585.0001,-863.3687 592.0001,-863.3686\"/>\n</g>\n<!-- 139640333441680 -->\n<g id=\"node34\" class=\"node\">\n<title>139640333441680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"739.5,-923 655.5,-923 655.5,-889 739.5,-889 739.5,-923\"/>\n<text text-anchor=\"middle\" x=\"697.5\" y=\"-909.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.8.bias</text>\n<text text-anchor=\"middle\" x=\"697.5\" y=\"-896.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 139640333441680&#45;&gt;139640333441512 -->\n<g id=\"edge33\" class=\"edge\">\n<title>139640333441680&#45;&gt;139640333441512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M668.29,-888.9832C651.9484,-879.4631 631.7089,-867.6722 615.7036,-858.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.2331,-855.1884 606.8306,-853.1788 613.7094,-861.2369 617.2331,-855.1884\"/>\n</g>\n<!-- 139640333442576 -->\n<g id=\"node35\" class=\"node\">\n<title>139640333442576</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"757.5,-796 653.5,-796 653.5,-762 757.5,-762 757.5,-796\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-782.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.10.weight</text>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-769.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 256, 3, 3)</text>\n</g>\n<!-- 139640333442576&#45;&gt;139640333441960 -->\n<g id=\"edge34\" class=\"edge\">\n<title>139640333442576&#45;&gt;139640333441960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-761.9832C705.5,-754.1157 705.5,-744.6973 705.5,-736.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-736.3686 705.5,-726.3687 702.0001,-736.3687 709.0001,-736.3686\"/>\n</g>\n<!-- 139640333441568 -->\n<g id=\"node36\" class=\"node\">\n<title>139640333441568</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"865.5,-796 775.5,-796 775.5,-762 865.5,-762 865.5,-796\"/>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-782.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.10.bias</text>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-769.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 139640333441568&#45;&gt;139640333441960 -->\n<g id=\"edge35\" class=\"edge\">\n<title>139640333441568&#45;&gt;139640333441960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M789.6821,-761.9832C772.2798,-752.3741 750.6879,-740.4516 733.7287,-731.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"735.2856,-727.9487 724.8396,-726.1788 731.9019,-734.0766 735.2856,-727.9487\"/>\n</g>\n<!-- 139640333723576 -->\n<g id=\"node37\" class=\"node\">\n<title>139640333723576</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"860,-421.5 787,-421.5 787,-400.5 860,-400.5 860,-421.5\"/>\n<text text-anchor=\"middle\" x=\"823.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640333723576&#45;&gt;139640333723240 -->\n<g id=\"edge36\" class=\"edge\">\n<title>139640333723576&#45;&gt;139640333723240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M804.7537,-400.3715C786.825,-390.2066 759.5727,-374.7555 739.1514,-363.1774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"740.7328,-360.0506 730.3074,-358.1631 737.2803,-366.14 740.7328,-360.0506\"/>\n</g>\n<!-- 139640333724416 -->\n<g id=\"node38\" class=\"node\">\n<title>139640333724416</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"881,-498 780,-498 780,-464 881,-464 881,-498\"/>\n<text text-anchor=\"middle\" x=\"830.5\" y=\"-484.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.1.weight</text>\n<text text-anchor=\"middle\" x=\"830.5\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096, 9216)</text>\n</g>\n<!-- 139640333724416&#45;&gt;139640333723576 -->\n<g id=\"edge37\" class=\"edge\">\n<title>139640333724416&#45;&gt;139640333723576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M828.7697,-463.6966C827.8063,-454.0634 826.6003,-442.003 825.5852,-431.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"829.0569,-431.3933 824.5791,-421.7913 822.0916,-432.0899 829.0569,-431.3933\"/>\n</g>\n<!-- 139640333722792 -->\n<g id=\"node39\" class=\"node\">\n<title>139640333722792</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"860,-224.5 787,-224.5 787,-203.5 860,-203.5 860,-224.5\"/>\n<text text-anchor=\"middle\" x=\"823.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640333722792&#45;&gt;139640333722288 -->\n<g id=\"edge38\" class=\"edge\">\n<title>139640333722792&#45;&gt;139640333722288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M807.0971,-203.3685C789.3119,-191.841 760.7246,-173.3123 740.2161,-160.0197\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"741.9986,-157.0041 731.7034,-154.5022 738.1913,-162.8782 741.9986,-157.0041\"/>\n</g>\n<!-- 139640333725144 -->\n<g id=\"node40\" class=\"node\">\n<title>139640333725144</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"878,-301 777,-301 777,-267 878,-267 878,-301\"/>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.4.weight</text>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096, 4096)</text>\n</g>\n<!-- 139640333725144&#45;&gt;139640333722792 -->\n<g id=\"edge39\" class=\"edge\">\n<title>139640333725144&#45;&gt;139640333722792</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M826.5112,-266.6966C825.9608,-257.0634 825.2716,-245.003 824.6915,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"828.1815,-234.5753 824.1166,-224.7913 821.1929,-234.9747 828.1815,-234.5753\"/>\n</g>\n<!-- 139640333722512 -->\n<g id=\"node41\" class=\"node\">\n<title>139640333722512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"868,-84.5 795,-84.5 795,-63.5 868,-63.5 868,-84.5\"/>\n<text text-anchor=\"middle\" x=\"831.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640333722512&#45;&gt;139640333723520 -->\n<g id=\"edge40\" class=\"edge\">\n<title>139640333722512&#45;&gt;139640333723520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M812.9211,-63.3715C795.1525,-53.2066 768.1434,-37.7555 747.9046,-26.1774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"749.5575,-23.0908 739.1395,-21.1631 746.0816,-29.1668 749.5575,-23.0908\"/>\n</g>\n<!-- 139640333724024 -->\n<g id=\"node42\" class=\"node\">\n<title>139640333724024</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"887,-161 786,-161 786,-127 887,-127 887,-161\"/>\n<text text-anchor=\"middle\" x=\"836.5\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.6.weight</text>\n<text text-anchor=\"middle\" x=\"836.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1000, 4096)</text>\n</g>\n<!-- 139640333724024&#45;&gt;139640333722512 -->\n<g id=\"edge41\" class=\"edge\">\n<title>139640333724024&#45;&gt;139640333722512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M835.264,-126.6966C834.576,-117.0634 833.7145,-105.003 832.9894,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"836.4745,-94.5165 832.2708,-84.7913 829.4923,-95.0153 836.4745,-94.5165\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm-T7L-b0iEd",
        "colab_type": "code",
        "outputId": "fb4a4506-94ef-4268-902c-d2bc1652aae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from Utils import *\n",
        "\n",
        "# Create SSD300 with pretrained weights in the base-architecture\n",
        "n_classes = 20\n",
        "model = SSD300(n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJBrmUrg0iUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(1,3,300,300)\n",
        "y = model(x)\n",
        "dot = make_dot(y, params = dict(list(model.named_parameters())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDXQGEYD5exK",
        "colab_type": "code",
        "outputId": "508e3499-290e-4738-9710-0bbc6edf0658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dot.render('VGG300_BN.gv', view=True)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'VGG300_BN.gv.pdf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0teUrcv7KGr",
        "colab_type": "code",
        "outputId": "491bca3a-587e-46d1-89db-7ffb7cd717ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gabOHy7FZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DerHv4qw5gcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCwrRaRyUNG",
        "colab_type": "text"
      },
      "source": [
        "# Trick #5\n",
        "[Awesome PyTorch list](https://github.com/bharathgs/Awesome-pytorch-list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CaC118W0KqS",
        "colab_type": "text"
      },
      "source": [
        "This is a truly awesome repo full of practical tutorials that implements various state-of-the-art deep learning techniques using PyTorch including:\n",
        "1. NLP & Speech Processing\n",
        "2. Computer Vision\n",
        "3. Probabilistic/Generative Libraries\n",
        "4. Other libraries\n",
        "5. Paper implementations<br>\n",
        "\n",
        "Basically a good place to look into when starting a new project to check for relevant realization techniques.<br>\n",
        "Since deep learning is such a fast developing fielding, if it weren't for the reason that this repo stoped getting updated 2 years ago, it should be #1 on this list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B1wXhJpVzwFn"
      },
      "source": [
        "# Trick #6\n",
        "**AdaBound optimizer**<br>\n",
        "Finally, AdaBound is available in PyTorch. One of the most powerful optimizer that out performs Adam in some cases with super fast convergence rate. Definely, something you would want to try out when fast prototyping.<br>\n",
        "The method is based on [Adaptive Gradient Methods with Dynamic Bound of Learning Rate](https://openreview.net/forum?id=Bkg3g2R9FX).In Proc. of ICLR 2019."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDzlQWrgBod4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## implementation\n",
        "optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOIUgigYBbw3",
        "colab_type": "text"
      },
      "source": [
        "As described in the paper, AdaBound is an optimizer that behavces like **Adam** at the beginning of the training, and gradually transforms to SGD at the end.  In this way, it can **combines the benefits of adaptive methods, viz. fast initial process, and the good final generalization properties of SGD.** <br>\n",
        "The `final_lr` parameter indicates **Adabound** would transforms to an SGD with this learninig rate. In common cases, a default final learning rate of `0.1` can achieve relatively good and statble results on *unseen data*.<br>\n",
        "This method is not very sensitive to it's hyperparameters. *See Appendix G of the paper for more details*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWOrq3XtCP4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o77f6yEAzv0b"
      },
      "source": [
        "# Trick #7\n",
        "Flatten layer in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVrkmIRzUnOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE3xuFq1UpPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5QgaUjHXzwPE"
      },
      "source": [
        "# Trick #8\n",
        "Expand_as in PyTorch for broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE0KN7UzVW2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdoVBBVyVZzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "b = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFfXN9FHVgZU",
        "colab_type": "code",
        "outputId": "122932a7-e5df-4131-ad4c-c33e9577e75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "c = a.expand_as(b)\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3],\n",
              "        [1, 2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwJYaKpXVohS",
        "colab_type": "code",
        "outputId": "2ebd87af-0b1a-418f-c230-95afe520fed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "d = a+b\n",
        "d # here a will be broadcasted before compute addition with b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  4,  6],\n",
              "        [ 5,  7,  9],\n",
              "        [ 8, 10, 12]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8iUk8aILzwSZ"
      },
      "source": [
        "# Trick #9\n",
        "**FastAI** listify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpZW3xFHV-02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [1,2,3]\n",
        "y = torch.arange(12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AZXPzb7WIW0",
        "colab_type": "code",
        "outputId": "0ab0116d-47c4-4298-bde4-fe7a2f4730e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68_RDQ4EWIza",
        "colab_type": "code",
        "outputId": "278ab8f9-1b58-4365-e0af-4ac45a6da10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BawbWL_YWKNI",
        "colab_type": "code",
        "outputId": "ea8c05e9-7e15-4d8d-9016-9ff3d5a37b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from fastai.train import listify\n",
        "z = listify(x)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk9N8wYlWlAc",
        "colab_type": "code",
        "outputId": "a0847674-5e86-4f2f-83ee-ec44d2c3febe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = listify(1,x)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZypzjAq3Wqlb",
        "colab_type": "code",
        "outputId": "76dd7cd2-8160-4795-d695-b6d0e9b07cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = listify(1,y)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cQGujMuWmH8",
        "colab_type": "code",
        "outputId": "e64af336-687a-4589-eaf7-77b95cc38e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = listify('good',x)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'good', 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SnlJ9ELgzwVP"
      },
      "source": [
        "# Trick #10\n",
        "In_place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OozWWn_PXG7l",
        "colab_type": "code",
        "outputId": "acba2a22-e493-4592-a22e-a58e78edfaa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# an example of NOT in-place\n",
        "a = torch.randn(1)\n",
        "b = torch.randn(1)\n",
        "id(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812240960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqQb62vJXOvN",
        "colab_type": "code",
        "outputId": "3694f491-addd-45f5-8e28-be64beaab7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "id(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812224360"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ong_aoDpXP6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNSyh60HXT61",
        "colab_type": "code",
        "outputId": "a23cd726-54b9-4ebf-cc42-ebb2ffa58d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# an example of in-place\n",
        "c = torch.randn(1)\n",
        "d = torch.randn(1)\n",
        "id(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812367792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5sHnnKBXh4_",
        "colab_type": "code",
        "outputId": "1ed9c67d-1065-4a6b-d293-17f9c1ad9aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "id(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812492616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAoN-WhwXjKu",
        "colab_type": "code",
        "outputId": "6a32ab94-d806-4afa-d56c-9229e4979fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c += d\n",
        "id(c)   # not changed because in-place"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812367792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r7tmfFoXsb2",
        "colab_type": "code",
        "outputId": "dd5244b4-ed48-4d38-96d7-4aea699868da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# another example of in-place\n",
        "e = torch.randn(1)\n",
        "f = torch.randn(1)\n",
        "id(e)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812423848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQgKsYrWXzfW",
        "colab_type": "code",
        "outputId": "dc8524f1-adc8-491d-cf94-7fd007e9f698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "id(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812422336"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6tMAO8jX0Rc",
        "colab_type": "code",
        "outputId": "7046ac82-c01e-4fe1-b31c-769d2191bf0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e.add_(f)\n",
        "id(e)       # this case, in-place"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139797812423848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM5TYI8zX6eG",
        "colab_type": "text"
      },
      "source": [
        "In PyTroch _ as postfix means inplace.<br>\n",
        "The variable will be modified and stored in the same memory place without creating a no vacancy for storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohdMNkUQNBQ7",
        "colab_type": "text"
      },
      "source": [
        "# Trick #11\n",
        "`AdaptiveConcatPool2d`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZYvRi7OZ_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "# nn.AdaptiveAvgPool2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teL0zd5xMSJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaptiveConcatPool2d(nn.Module):\n",
        "    def __init__(self, sz=1):\n",
        "        super().__init__()\n",
        "        self.dropout_size = sz\n",
        "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
        "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.ap(x), self.mp(x)],dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w81dlJwoO8Zh",
        "colab_type": "code",
        "outputId": "d9cbfb73-17bf-4f4a-ad83-4f7261054f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([\n",
        "                  [\n",
        "                   [1.,2.,3.],\n",
        "                   [1.,2.,3.],\n",
        "                   [1.,2.,4.]\n",
        "                  ],\n",
        "                  [\n",
        "                   [1.,2.,3.],\n",
        "                   [1.,2.,3.],\n",
        "                   [1.,2.,5.]\n",
        "                  ],\n",
        "                  [\n",
        "                   [1.,2.,3.],\n",
        "                   [1.,2.,3.],\n",
        "                   [1.,2.,3.]\n",
        "                  ]\n",
        "])\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bV0cMTAPV4L",
        "colab_type": "code",
        "outputId": "a1a19042-b086-416f-9eae-46cd1a563c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "A = nn.AdaptiveAvgPool2d(1) # specify the output size\n",
        "print(A(x).shape)\n",
        "A(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.3333]],\n",
              "\n",
              "        [[2.2222]],\n",
              "\n",
              "        [[2.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Jp5KetPnhG",
        "colab_type": "code",
        "outputId": "b1f6037a-6847-468e-8725-18a3b80d89ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "M = nn.AdaptiveMaxPool2d(1)\n",
        "M(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[4.]],\n",
              "\n",
              "        [[5.]],\n",
              "\n",
              "        [[3.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGhO8jFwPrMo",
        "colab_type": "code",
        "outputId": "8fcdffbe-7eb5-4246-cc99-75dd154ded0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "A = nn.AdaptiveAvgPool2d((1,3))\n",
        "print(A(x).shape)\n",
        "A(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 2.0000, 3.3333]],\n",
              "\n",
              "        [[1.0000, 2.0000, 3.6667]],\n",
              "\n",
              "        [[1.0000, 2.0000, 3.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86WaLxiLQDDf",
        "colab_type": "code",
        "outputId": "c1d99c92-e5d1-4db5-ebfe-af5251290e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "C = AdaptiveConcatPool2d(1)\n",
        "C(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.1111],\n",
              "         [4.0000]],\n",
              "\n",
              "        [[2.2222],\n",
              "         [5.0000]],\n",
              "\n",
              "        [[2.0000],\n",
              "         [3.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JUn7Wei7zwbp"
      },
      "source": [
        "# Trick #12\n",
        "logsumexp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATMMO0ZWYU5f",
        "colab_type": "code",
        "outputId": "843c6c64-963f-485a-d683-acf8a7c97565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.zeros(1,3)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8MCdTk-YXrq",
        "colab_type": "code",
        "outputId": "39a5d169-f6b9-48f0-9b4d-dc89e90c79b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = torch.logsumexp(input=a,dim=1,keepdim=False)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0986])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLi-n2uuYxSv",
        "colab_type": "code",
        "outputId": "2dd05abb-d116-476a-dfe1-54bfcf17fbeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "zero = torch.tensor([0],dtype=torch.float)\n",
        "torch.log(torch.exp(zero)+torch.exp(zero)+torch.exp(zero))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0986])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8aGPeLpZ9t5",
        "colab_type": "code",
        "outputId": "f33d1cc6-14a4-4c9a-dbc9-c138bcc7c441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = torch.ones(1,3)\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgg7W2qHaFhu",
        "colab_type": "code",
        "outputId": "3a0b0c5c-d65c-4478-f69f-405a27409822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d = torch.logsumexp(c,dim=1)\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0986])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFD43nIDaLPh",
        "colab_type": "code",
        "outputId": "fd2c91a3-7851-47ac-9362-ad034578861d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "one = torch.tensor([1], dtype=torch.float)\n",
        "torch.log(torch.exp(one)+torch.exp(one)+torch.exp(one))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0986])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imaxKeZGZtMd",
        "colab_type": "text"
      },
      "source": [
        "# Trick 13\n",
        "Named_children"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_tshn3iadzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8UkM4SCMWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d( 1, 10, 3)\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
        "        self.conv2_dropout = nn.Dropout2d(p=0.5)\n",
        "        self.fc1   = nn.Linear(320, 50)\n",
        "        self.fc2   = nn.Linear(50, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arKow5UoC3ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU3mvhzfC6Sp",
        "colab_type": "code",
        "outputId": "c1005f50-09ec-47f0-cdcd-ec65953e5359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "for l, name in x.named_children():\n",
        "    print(f\"layer {l} is: {name}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer conv1 is: Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "layer conv2 is: Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
            "layer conv2_dropout is: Dropout2d(p=0.5, inplace=False)\n",
            "layer fc1 is: Linear(in_features=320, out_features=50, bias=True)\n",
            "layer fc2 is: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcFCJj0DDCfJ",
        "colab_type": "text"
      },
      "source": [
        "# Trick #14\n",
        "`torch.addcmul()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRlBw6xEDSlX",
        "colab_type": "code",
        "outputId": "184b2d72-5ea5-404e-aba7-092b92f95d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "x = torch.ones(1,3)\n",
        "y = torch.ones(3,1)\n",
        "z = torch.ones(1,1)*2\n",
        "x, y, z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1.]]), tensor([[1.],\n",
              "         [1.],\n",
              "         [1.]]), tensor([[2.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL5kSGcgDaqS",
        "colab_type": "code",
        "outputId": "c20f74e4-984e-42b3-c2c1-ec6a3636b214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.addcmul(input, value=1, tensor1, tensor2)\n",
        "a = torch.addcmul(z, 0.5, x, y) # z + 0.5*x*y\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5000, 2.5000, 2.5000],\n",
              "        [2.5000, 2.5000, 2.5000],\n",
              "        [2.5000, 2.5000, 2.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiTz5JqeDu7S",
        "colab_type": "code",
        "outputId": "13432fae-1c0c-4288-b5a4-c06eeb436c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "x,y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1.]]), tensor([[1.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV-u2bCEEAtS",
        "colab_type": "code",
        "outputId": "38daad83-3ac0-4f88-c0bc-0016201ce9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "x*y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEtfEg7VEBvD",
        "colab_type": "code",
        "outputId": "c76c8bcc-db48-4d31-d7a4-1d68b93a8169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "z + 0.5*x*y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5000, 2.5000, 2.5000],\n",
              "        [2.5000, 2.5000, 2.5000],\n",
              "        [2.5000, 2.5000, 2.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zZ5zNkcEOpJ",
        "colab_type": "text"
      },
      "source": [
        "# Trick #15\n",
        "`torch.permute` used to re-arrange the dimension of a given tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED63MybnDQ0U",
        "colab_type": "code",
        "outputId": "dbe3dc7f-83a1-48b5-ad7f-e802c81b3ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "x = torch.randn(3,4)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2616,  0.5046, -0.1475,  0.4465],\n",
              "        [-0.1938,  0.4212, -0.4747,  0.7031],\n",
              "        [ 1.9922,  2.0265, -0.9237, -1.6005]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybOth5BEhqw",
        "colab_type": "code",
        "outputId": "46b7b34c-9901-4219-d148-643ac4203e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y = x.permute(1,0)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2616, -0.1938,  1.9922],\n",
              "        [ 0.5046,  0.4212,  2.0265],\n",
              "        [-0.1475, -0.4747, -0.9237],\n",
              "        [ 0.4465,  0.7031, -1.6005]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwsBfjXjEmwc",
        "colab_type": "code",
        "outputId": "58516f29-530c-4f2e-e03b-4282f3dd184d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.randn(3,4,5,6,7,8)\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 5, 6, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c-br_-tEssk",
        "colab_type": "code",
        "outputId": "12cad909-261d-4c19-fb88-b20e90302966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = a.permute(2,1,0,4,3,5)\n",
        "b.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 7, 6, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7LIvq8nEy60",
        "colab_type": "text"
      },
      "source": [
        "# Trick #16\n",
        "Creating a concise four layer CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHr0EEQxFDwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, 2),\n",
        "                         nn.BatchNorm2d(out_channels),\n",
        "                         nn.ReLU(),\n",
        "                         nn.MaxPool2d(kernel_size=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz2pUW4tFfb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(x_dim,   hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, z_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = nn.MaxPool2d(5)(x)\n",
        "        x = x.view(x.size(0), -1)  # flatten while only retain the batch_size dimenison\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXU5fHSgGX_f",
        "colab_type": "code",
        "outputId": "7f0274d3-d468-4425-8fea-7c03d23ca333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "net = ConvNet()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (encoder): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjqTJwQtEx6i",
        "colab_type": "text"
      },
      "source": [
        "# Trick #17\n",
        "The mechanism behind `torch.dropout()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRbupYDJG-__",
        "colab_type": "code",
        "outputId": "2e648be8-8c83-4bbf-905c-5731c691af7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y = torch.ones(3,3)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMsg24P6KyeM",
        "colab_type": "code",
        "outputId": "473f0f0c-2967-4b86-c24b-853955f37776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "D = nn.Dropout(0)\n",
        "D(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZydiclwZK6Tb",
        "colab_type": "code",
        "outputId": "8becec58-96f6-49d4-c4d1-fb506938ff2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "D = nn.Dropout(0.5)\n",
        "D(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 2., 0.],\n",
              "        [2., 2., 0.],\n",
              "        [0., 2., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEa3dO7_Elcc",
        "colab_type": "code",
        "outputId": "19af6aaf-cad5-4ba1-e208-b639f5e08ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "D = nn.Dropout(1)\n",
        "D(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uex2zJP8LGRD",
        "colab_type": "code",
        "outputId": "51e6a1f2-374e-423f-ffc1-200528c95ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "D = nn.Dropout(0.3)\n",
        "D(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000],\n",
              "        [1.4286, 0.0000, 1.4286],\n",
              "        [1.4286, 1.4286, 1.4286]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm6SWrpULKsO",
        "colab_type": "code",
        "outputId": "a975d0e5-20fc-469e-e2ba-5019cba28a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "D = nn.Dropout(0.8)\n",
        "D(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 5.],\n",
              "        [5., 0., 5.],\n",
              "        [5., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJbu6-_wLPQf",
        "colab_type": "text"
      },
      "source": [
        "Final note, the output value will be `original/(1-p)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT2KrdfdLdwY",
        "colab_type": "text"
      },
      "source": [
        "# Trick #18\n",
        "Creating mini-batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIr_l46xLpip",
        "colab_type": "code",
        "outputId": "3e9d8c59-3d3b-4c14-f164-81a7c46472e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "x = torch.randn(3,128,128)\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz2cPvSpNOd8",
        "colab_type": "code",
        "outputId": "846399ae-53b0-4ce1-f81c-93cd1c1b2cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = x.unsqueeze(0)\n",
        "t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sFrzvpmNR_Q",
        "colab_type": "code",
        "outputId": "6c7c49d1-afe8-45de-98bf-9b6fe6321d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "u = x[None,:]\n",
        "u.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai-go78fNVO7",
        "colab_type": "code",
        "outputId": "c08237ca-eebc-4f00-ac00-e32f987a920d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = x[None]\n",
        "v.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtZVDwbzNYsy",
        "colab_type": "text"
      },
      "source": [
        "# Trick #19\n",
        "Look into `torch.nn.ReLU()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mum2Z5ewQqeQ",
        "colab_type": "code",
        "outputId": "e588a248-c3b3-4e0b-e968-5233ca088b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "x = torch.randn(3,3)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1243,  0.5653,  0.3340],\n",
              "        [-1.7015, -0.8263,  0.2759],\n",
              "        [ 0.5675,  0.8615, -0.4378]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqes_NVMrHN6",
        "colab_type": "code",
        "outputId": "86d2e0d2-6098-439d-9133-b49a16285912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "y = nn.ReLU()\n",
        "print(y(x)) # All negative values goes to zero, inplance default is False\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.5653, 0.3340],\n",
            "        [0.0000, 0.0000, 0.2759],\n",
            "        [0.5675, 0.8615, 0.0000]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1243,  0.5653,  0.3340],\n",
              "        [-1.7015, -0.8263,  0.2759],\n",
              "        [ 0.5675,  0.8615, -0.4378]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw6Cq2VPrsUE",
        "colab_type": "code",
        "outputId": "0f771bbb-03f0-4cb9-89e2-1c9d52951a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "y = nn.ReLU(inplace=True)\n",
        "print(y(x))\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.5653, 0.3340],\n",
            "        [0.0000, 0.0000, 0.2759],\n",
            "        [0.5675, 0.8615, 0.0000]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.5653, 0.3340],\n",
              "        [0.0000, 0.0000, 0.2759],\n",
              "        [0.5675, 0.8615, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX5XZlAEruzL",
        "colab_type": "text"
      },
      "source": [
        "# Trick #20\n",
        "change torch.tensor **type**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if6NM_O1sTXR",
        "colab_type": "code",
        "outputId": "c46d719c-c6ee-4dd2-e213-4cb963e07e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3,3)\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAkGwVlRsY2M",
        "colab_type": "code",
        "outputId": "f7ce18f8-2ae6-44ea-bc28-d95c203cefc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = x.type(torch.long)\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADzgiO8bsdJF",
        "colab_type": "code",
        "outputId": "7a7fabaa-2cce-44be-d56a-a433dcc084a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3,3).type(torch.float)\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqUm0mFNsjul",
        "colab_type": "code",
        "outputId": "72a82e94-fd70-4112-b451-482d4f9f768d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.ones(3,3, dtype=torch.long)\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgO1eS7Zsrem",
        "colab_type": "text"
      },
      "source": [
        "# Trick #21\n",
        "`L1Loss` vs `MSELoss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zSMytZ3uY74",
        "colab_type": "code",
        "outputId": "090c9786-bd41-4e07-fac5-dc54dccbfe01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8117])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVQ-VlX3ubNY",
        "colab_type": "code",
        "outputId": "c5b4446b-a2a7-4d26-d51f-1cfc647e9fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = torch.ones(1)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx_TKNLTudHR",
        "colab_type": "code",
        "outputId": "8d468b9d-66d5-46a4-e5ec-1c6ab240d03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = nn.L1Loss()\n",
        "z(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.8117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPiUDKvDugmo",
        "colab_type": "code",
        "outputId": "13111ea4-f3e2-4276-c8b6-7318c4781b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "abs(x-y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.8117])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmV9CUNistam",
        "colab_type": "code",
        "outputId": "d3154117-8728-43a4-e3b0-873079d28ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = nn.MSELoss()\n",
        "a(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.2822)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiT_Jykcutfw",
        "colab_type": "code",
        "outputId": "b93ddbff-3625-49b3-824d-dcf6d8a4f9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pow((x-y),2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.2822])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILWXL973ux5h",
        "colab_type": "text"
      },
      "source": [
        "# Trick #22\n",
        "Sigmoid in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W35dGXEbu6Ih",
        "colab_type": "code",
        "outputId": "ed610f5e-e5a9-4dc6-b6ff-e032901e1999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1949])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3jC4BnNvHoM",
        "colab_type": "code",
        "outputId": "d02420d9-6357-4988-8510-7dc9d4dbb683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = nn.Sigmoid()\n",
        "y(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2324])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHN-14hZvLFh",
        "colab_type": "code",
        "outputId": "52d15675-9e13-47b6-90c6-afbb4cf9e550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "(1/(1+math.exp(-x)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23237839781597944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvkA-of-vQax",
        "colab_type": "code",
        "outputId": "94ef9ea8-c809-455d-dc11-21b9350bba42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "z = torch.ones(3,4)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWD7ekO9vXLb",
        "colab_type": "code",
        "outputId": "2ec3156d-77ff-474b-cbe1-0a6c4e79c673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
              "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
              "        [0.7311, 0.7311, 0.7311, 0.7311]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee11ypKTvYt6",
        "colab_type": "code",
        "outputId": "8ce49144-e562-48a4-fc7a-564d50e2972c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "z = torch.randn(3,4)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0480,  0.2540,  1.5722,  0.3227],\n",
              "        [-1.0730,  0.8581, -1.3591, -0.2922],\n",
              "        [ 0.6118,  0.5229,  0.0910,  1.1228]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPZfBj6JvdnK",
        "colab_type": "code",
        "outputId": "0665be43-b935-4607-e904-0b1d87c3b52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5120, 0.5632, 0.8281, 0.5800],\n",
              "        [0.2548, 0.7023, 0.2044, 0.4275],\n",
              "        [0.6484, 0.6278, 0.5227, 0.7545]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROAwd1T6vePz",
        "colab_type": "text"
      },
      "source": [
        "# Trick #23\n",
        "Softmax in Pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rij4NRhJwkHP",
        "colab_type": "code",
        "outputId": "489ff6e7-17ea-4220-9311-4ee252f82f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = torch.randn(2,2)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0719, -0.8291],\n",
              "        [-0.3748,  0.0375]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FEYDm5zw0K3",
        "colab_type": "code",
        "outputId": "6c3c2ee6-ecc2-4836-fc15-51becb186dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y = nn.Softmax()\n",
        "a = y(x);a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4396, 0.5604],\n",
              "        [0.3983, 0.6017]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MBhmDJmw93S",
        "colab_type": "code",
        "outputId": "b0cca35d-ac55-4624-dedf-ea2e0a05a6b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a[0][0]+a[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms59a58oxBTt",
        "colab_type": "code",
        "outputId": "fb7873bf-f905-4ddd-8ee0-2b7f2807925f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a[1][0]+a[1][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1zJV81TxE_b",
        "colab_type": "text"
      },
      "source": [
        "# Trick #24\n",
        "`nn.ModuleList`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE1cjq92w4XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = nn.ModuleList([nn.Dropout(0.5),\n",
        "                   nn.ReLU()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR08mHkuxX1F",
        "colab_type": "code",
        "outputId": "44d435ca-63e5-4acd-c1eb-530a5ee6d74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Dropout(p=0.5, inplace=False)\n",
              "  (1): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h02z0YqtxZRI",
        "colab_type": "code",
        "outputId": "a4a34fc2-9329-4eb2-bbe7-781aa4cda6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y = torch.randn(3,3)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233, -0.3660,  0.8597],\n",
              "        [-1.4992, -0.3499,  1.3273],\n",
              "        [ 0.5832, -1.0665, -1.6803]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1g7AA4dxdZl",
        "colab_type": "code",
        "outputId": "d01824f2-2ba2-4411-92f4-437e808b4ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "t = x[0](y);t  # performed dropout, and value modified as original/(1-0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000, -0.7321,  1.7194],\n",
              "        [-2.9985, -0.6999,  2.6546],\n",
              "        [ 0.0000, -2.1329, -0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI9t1mStxhOM",
        "colab_type": "code",
        "outputId": "5fd9ad79-d5c6-40b9-808e-f75f6e593464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "r = x[1](t);r   # performed ReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 1.7194],\n",
              "        [0.0000, 0.0000, 2.6546],\n",
              "        [0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j541So3MyFzt",
        "colab_type": "text"
      },
      "source": [
        "# Trick #25\n",
        "`nn.Linear`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcBzuUWkvN2x",
        "colab_type": "code",
        "outputId": "aa26cd0e-efcc-4d12-9ebd-538aa29bd307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(2);x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0459, 0.0121])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp-_2FeVy3pG",
        "colab_type": "code",
        "outputId": "57c3288c-00b2-448e-b61c-1e30b78a263c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = nn.Linear(2,1);a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=2, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLGYBisBy6sZ",
        "colab_type": "code",
        "outputId": "7c9e3f5f-80f7-4c3b-db91-f322ef07d963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "a.weight, a.bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0.1052, 0.3337]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.3842], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMGgn_Phy_V3",
        "colab_type": "code",
        "outputId": "49c8ce70-59e5-4b12-982a-eac1d4042273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3754], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFrqvJFzCU4",
        "colab_type": "code",
        "outputId": "d3530056-8068-43f9-b9e2-e68c0825ce1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x@a.weight.t()+a.bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3754], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCGGt3N_y8RQ",
        "colab_type": "text"
      },
      "source": [
        "# Trick #26\n",
        "`torch.mean()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifl5fOhmzeJg",
        "colab_type": "code",
        "outputId": "5a28c645-4350-44fb-e618-b7a2cd2a42eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.FloatTensor([[1,2,3,4],[5,6,7,8]])\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT43puedzm0K",
        "colab_type": "code",
        "outputId": "8313c3a0-8651-45f3-bb9d-fe417b7999ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x.mean()\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y52Bq0okzo2B",
        "colab_type": "code",
        "outputId": "28b1754e-b209-4e7e-fba6-64f1dea0d303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y = x.mean(dim=1, keepdim=True);y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5000],\n",
              "        [6.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVgGr3RzxFZ",
        "colab_type": "code",
        "outputId": "09e0aae8-cf56-4395-b4e0-05193fc63693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x.mean(dim=1, keepdim=False);y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5000, 6.5000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFmcWQsJzz0x",
        "colab_type": "code",
        "outputId": "03ceaf3e-22c0-489d-a142-d5e44da9492d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b62Krk8vz8M6",
        "colab_type": "code",
        "outputId": "78c910dc-7c5c-4d2e-f798-49f44613e4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3,4,5)\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FaLET1K0Bs5",
        "colab_type": "code",
        "outputId": "8e1e2de8-3ec1-43c1-92e6-f4b0a916631d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x.mean(dim=1, keepdim=False);y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uisw9xc0GWw",
        "colab_type": "code",
        "outputId": "0159b9d8-f611-498c-c8ab-684315780bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x.mean(dim=1, keepdim=True);y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY8vOw_G0IL5",
        "colab_type": "code",
        "outputId": "5786eba6-2269-4a7a-eb4c-89b46725c06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1030, -0.2823, -0.3783, -0.4649, -0.4580]],\n",
              "\n",
              "        [[-0.0760, -0.3777, -0.3589,  0.6745,  0.0425]],\n",
              "\n",
              "        [[ 0.5953, -0.7010, -0.4688,  0.1781, -0.3393]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H8EcBe_0TQT",
        "colab_type": "text"
      },
      "source": [
        "# Trick #27\n",
        "Use  `dropblock` in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVH5SH9G0lGF",
        "colab_type": "code",
        "outputId": "d92f3f9d-3a46-462f-a6ab-bd496a3c5d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip install dropblock"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dropblock\n",
            "  Downloading https://files.pythonhosted.org/packages/92/ba/a2c6388f228045fa543f263923804e799b2e9d86b0517c5a53564ae0de3e/dropblock-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from dropblock) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dropblock) (1.17.4)\n",
            "Installing collected packages: dropblock\n",
            "Successfully installed dropblock-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hptIZWR50ozO",
        "colab_type": "code",
        "outputId": "afdd9f23-f742-4bb4-a7f9-8abcd57b0da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.ones(5,5,5,5);x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 5, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymSw4Arw0vri",
        "colab_type": "code",
        "outputId": "ffe3cb5f-9bd6-476f-dcb3-dc975fb1dcc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import dropblock\n",
        "y = dropblock.DropBlock2D(drop_prob=0.5, block_size=2)\n",
        "y(x)    # dropout 2x2 size blocks with chance of 50%"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1.4706, 0.0000, 0.0000, 1.4706, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.4706, 0.0000, 0.0000, 1.4706, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.4706, 0.0000, 0.0000, 1.4706, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.4706, 0.0000, 0.0000, 1.4706, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.4706, 0.0000, 0.0000, 1.4706, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000]]],\n",
              "\n",
              "\n",
              "        [[[1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]]],\n",
              "\n",
              "\n",
              "        [[[1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 0.0000, 0.0000, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]]],\n",
              "\n",
              "\n",
              "        [[[1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]],\n",
              "\n",
              "         [[1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 0.0000, 0.0000],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706]]],\n",
              "\n",
              "\n",
              "        [[[0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 0.0000, 1.4706]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 0.0000, 1.4706]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 0.0000, 1.4706]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 0.0000, 1.4706]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [0.0000, 0.0000, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 1.4706, 1.4706, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 1.4706, 1.4706],\n",
              "          [1.4706, 0.0000, 0.0000, 0.0000, 1.4706]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObqGSNvF1EQb",
        "colab_type": "code",
        "outputId": "24ae55a2-43ff-4324-fa96-05ae6c04522b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y = dropblock.DropBlock2D(drop_prob=0.5, block_size=3)\n",
        "y(x)    # dropout 3x3 size blocks with chance of 50%"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]]],\n",
              "\n",
              "\n",
              "        [[[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]]],\n",
              "\n",
              "\n",
              "        [[[0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887]],\n",
              "\n",
              "         [[0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887],\n",
              "          [1.2887, 0.0000, 0.0000, 0.0000, 1.2887]]],\n",
              "\n",
              "\n",
              "        [[[1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000],\n",
              "          [1.2887, 1.2887, 1.2887, 0.0000, 0.0000]]],\n",
              "\n",
              "\n",
              "        [[[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]],\n",
              "\n",
              "         [[1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887],\n",
              "          [1.2887, 1.2887, 1.2887, 1.2887, 1.2887]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w24eoBxC1Aa4",
        "colab_type": "text"
      },
      "source": [
        "# Trick #28\n",
        "Orthogonal Initialization in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D-Jo1BwPEu5",
        "colab_type": "code",
        "outputId": "959e83c8-056d-459e-de39-4a4eb690f6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "x, y, z = [torch.zeros(3, 3)]*3\n",
        "x, y, z\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]), tensor([[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]), tensor([[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cpH1a1BP5e8",
        "colab_type": "code",
        "outputId": "88a6178b-c31c-4ef3-deec-04dc7a75f73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "a = nn.init.orthogonal_(x, gain=1) # orthogonal means A@A.t() = I\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6239,  0.4647, -0.6283],\n",
              "        [-0.7781,  0.2945, -0.5549],\n",
              "        [-0.0729,  0.8350,  0.5453]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1My4TAc5QJ_0",
        "colab_type": "code",
        "outputId": "ca8d698f-455c-458f-de68-c8516750c607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "a@a.t()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 1.1334e-07, 1.4851e-07],\n",
              "        [1.1334e-07, 1.0000e+00, 7.9556e-08],\n",
              "        [1.4851e-07, 7.9556e-08, 1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCiaBaLoQM_K",
        "colab_type": "code",
        "outputId": "6277504c-ae9c-4718-80b6-40d0fbbbc7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "torch.eye(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0aimW2BQVEF",
        "colab_type": "code",
        "outputId": "ecb5f6fe-9c7a-432a-ce64-c87a93612f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "b = nn.init.orthogonal_(y, gain=5) # gain adjusted\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8261, -0.1627, -4.9286],\n",
              "        [ 4.9304,  0.0674, -0.8286],\n",
              "        [ 0.0934, -4.9969,  0.1493]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWjFYEDMQcGK",
        "colab_type": "code",
        "outputId": "f71c6ef6-ce06-4765-8fe4-8dd146db237d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "b@b.t()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.5000e+01,  2.8265e-07, -1.1301e-06],\n",
              "        [ 2.8265e-07,  2.5000e+01, -2.2266e-07],\n",
              "        [-1.1301e-06, -2.2266e-07,  2.5000e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ENyQO1mQfAF",
        "colab_type": "code",
        "outputId": "503c667e-437b-4380-c1a8-d06710e67a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "25*torch.eye(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[25.,  0.,  0.],\n",
              "        [ 0., 25.,  0.],\n",
              "        [ 0.,  0., 25.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew7uzK4vQjwt",
        "colab_type": "text"
      },
      "source": [
        "Final note: remember the initialization process is random. We get different matrix by re-running the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi7YHvOPP3K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBT6K7QX0swj",
        "colab_type": "text"
      },
      "source": [
        "# Trick #29\n",
        "Param_groups in `nn.Modules`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2M9qiDaRS1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESLviRG1RbLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = nn.Linear(3,3)\n",
        "r = optim.SGD(l.parameters(),lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt4i56wARalF",
        "colab_type": "code",
        "outputId": "69abb6e0-b0a5-4259-aeb9-2925223b0632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "r"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    lr: 0.01\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obX4rfOGRrN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "40e36887-3ead-4806-d03e-abb5cdf46159"
      },
      "source": [
        "r.param_groups"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'dampening': 0,\n",
              "  'lr': 0.01,\n",
              "  'momentum': 0,\n",
              "  'nesterov': False,\n",
              "  'params': [Parameter containing:\n",
              "   tensor([[-0.0972,  0.1965,  0.2558],\n",
              "           [-0.1338, -0.2729,  0.3077],\n",
              "           [ 0.0461,  0.3657, -0.1356]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0.2679, 0.1912, 0.1528], requires_grad=True)],\n",
              "  'weight_decay': 0}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekZCUCU5aoZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "18903894-d1cc-46fa-c6a5-9957aa101c35"
      },
      "source": [
        "r.param_groups[0]['params']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0972,  0.1965,  0.2558],\n",
              "         [-0.1338, -0.2729,  0.3077],\n",
              "         [ 0.0461,  0.3657, -0.1356]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.2679, 0.1912, 0.1528], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbfTW3oZdRfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "f31e3925-808b-4e5e-977b-18fec42649bc"
      },
      "source": [
        "# The first is the weight, the second is the bias\n",
        "for count, i in enumerate(l.parameters()):\n",
        "    print(count)\n",
        "    print(i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Parameter containing:\n",
            "tensor([[-0.0972,  0.1965,  0.2558],\n",
            "        [-0.1338, -0.2729,  0.3077],\n",
            "        [ 0.0461,  0.3657, -0.1356]], requires_grad=True)\n",
            "1\n",
            "Parameter containing:\n",
            "tensor([0.2679, 0.1912, 0.1528], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdE96ZBsamhJ",
        "colab_type": "text"
      },
      "source": [
        "All of these info can be accessed by the **optimizor**'s `param_groups`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTniwlrOQS0",
        "colab_type": "text"
      },
      "source": [
        "# Trick #30\n",
        "Math behind \"standard_deviation\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywxp8GQ7RZh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crGEABZ2O2oj",
        "colab_type": "text"
      },
      "source": [
        "# Trick #30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clLy3J4xO3l1",
        "colab_type": "text"
      },
      "source": [
        "# Trick #30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKhNJ66RO4jM",
        "colab_type": "text"
      },
      "source": [
        "# Trick #30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPWW19VYO5Qt",
        "colab_type": "text"
      },
      "source": [
        "# Trick #30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G23UxtD6O6Jn",
        "colab_type": "text"
      },
      "source": [
        "# Trick #30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNYd5W1xOQuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}