{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "145_PyTorch_Tricks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T8fuVdeJ2ily"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sylar257/My-data-science-tool-kit/blob/master/145_PyTorch_Tricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_rSH7id15Fy",
        "colab_type": "text"
      },
      "source": [
        "# 145 PyTorch Tricks\n",
        "This is a series of useful PyTorch tricks inspired by **vainaijr** in his [YouTube channel](https://www.youtube.com/watch?v=nnHQT9JnY74&list=PLUY8w37x-QUUkawz-cBnjLpvaZWvPZh_s&index=2&t=29s).<br>\n",
        "This notebook is an implementation of all these techniques and is designed in a way to best demonstrate their usefulness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8fuVdeJ2ily",
        "colab_type": "text"
      },
      "source": [
        "## Trick #1\n",
        "Visualization model using `torchsummaryX`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQnXYH10AdtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from Utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTuqtpoh5_mF",
        "colab_type": "text"
      },
      "source": [
        "Here we will build a Single-shot-detection model with just 20 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzAiSJmbAz4h",
        "colab_type": "code",
        "outputId": "060a3e66-2d0f-4e1b-9643-ad6900a020f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Create SSD300 with pretrained weights in the base-architecture\n",
        "n_classes = 20\n",
        "model = SSD300(n_classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:14<00:00, 39.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbRH1ipJBrYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "527c2474-0ff2-46ba-b3e8-04bb9fdf39bc"
      },
      "source": [
        "# install torchsummaryX\n",
        "!pip install torchsummaryX"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading https://files.pythonhosted.org/packages/36/23/87eeaaf70daa61aa21495ece0969c50c446b8fd42c4b8905af264b40fe7f/torchsummaryX-1.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.3.1+cu100)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.17.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->torchsummaryX) (1.12.0)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcUf7Bgp6dZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummaryX import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B78vIOLG6vY9",
        "colab_type": "text"
      },
      "source": [
        "`summary(model, input)` takes our intentional model and a pseudo input **with the correct shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0Hgjdv6pLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fa823e8-b2e6-486a-aef0-3b9632d8eb09"
      },
      "source": [
        "# pseudo input of batch size = 3, num_channel = 3, pixel: 300x300\n",
        "summary(model, torch.zeros((3,3,300,300)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================================================================\n",
            "                                         Kernel Shape        Output Shape  \\\n",
            "Layer                                                                       \n",
            "0_base.Conv2d_conv1_1                   [3, 64, 3, 3]   [3, 64, 300, 300]   \n",
            "1_base.BatchNorm2d_bn_1_1                        [64]   [3, 64, 300, 300]   \n",
            "2_base.Conv2d_conv1_2                  [64, 64, 3, 3]   [3, 64, 300, 300]   \n",
            "3_base.BatchNorm2d_bn_1_2                        [64]   [3, 64, 300, 300]   \n",
            "4_base.MaxPool2d_pool1                              -   [3, 64, 150, 150]   \n",
            "5_base.Conv2d_conv2_1                 [64, 128, 3, 3]  [3, 128, 150, 150]   \n",
            "6_base.BatchNorm2d_bn_2_1                       [128]  [3, 128, 150, 150]   \n",
            "7_base.Conv2d_conv2_2                [128, 128, 3, 3]  [3, 128, 150, 150]   \n",
            "8_base.BatchNorm2d_bn_2_2                       [128]  [3, 128, 150, 150]   \n",
            "9_base.MaxPool2d_pool2                              -    [3, 128, 75, 75]   \n",
            "10_base.Conv2d_conv3_1               [128, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "11_base.BatchNorm2d_bn_3_1                      [256]    [3, 256, 75, 75]   \n",
            "12_base.Conv2d_conv3_2               [256, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "13_base.BatchNorm2d_bn_3_2                      [256]    [3, 256, 75, 75]   \n",
            "14_base.Conv2d_conv3_3               [256, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "15_base.BatchNorm2d_bn_3_3                      [256]    [3, 256, 75, 75]   \n",
            "16_base.MaxPool2d_pool3                             -    [3, 256, 38, 38]   \n",
            "17_base.Conv2d_conv4_1               [256, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "18_base.BatchNorm2d_bn_4_1                      [512]    [3, 512, 38, 38]   \n",
            "19_base.Conv2d_conv4_2               [512, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "20_base.BatchNorm2d_bn_4_2                      [512]    [3, 512, 38, 38]   \n",
            "21_base.Conv2d_conv4_3               [512, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "22_base.BatchNorm2d_bn_4_3                      [512]    [3, 512, 38, 38]   \n",
            "23_base.MaxPool2d_pool4                             -    [3, 512, 19, 19]   \n",
            "24_base.Conv2d_conv5_1               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "25_base.BatchNorm2d_bn_5_1                      [512]    [3, 512, 19, 19]   \n",
            "26_base.Conv2d_conv5_2               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "27_base.BatchNorm2d_bn_5_2                      [512]    [3, 512, 19, 19]   \n",
            "28_base.Conv2d_conv5_3               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "29_base.BatchNorm2d_bn_5_3                      [512]    [3, 512, 19, 19]   \n",
            "30_base.MaxPool2d_pool5                             -    [3, 512, 19, 19]   \n",
            "31_base.Conv2d_conv6                [512, 1024, 3, 3]   [3, 1024, 19, 19]   \n",
            "32_base.Conv2d_conv7               [1024, 1024, 1, 1]   [3, 1024, 19, 19]   \n",
            "33_aux_convs.Conv2d_conv8_1         [1024, 256, 1, 1]    [3, 256, 19, 19]   \n",
            "34_aux_convs.Conv2d_conv8_2          [256, 512, 3, 3]    [3, 512, 10, 10]   \n",
            "35_aux_convs.Conv2d_conv9_1          [512, 128, 1, 1]    [3, 128, 10, 10]   \n",
            "36_aux_convs.Conv2d_conv9_2          [128, 256, 3, 3]      [3, 256, 5, 5]   \n",
            "37_aux_convs.Conv2d_conv10_1         [256, 128, 1, 1]      [3, 128, 5, 5]   \n",
            "38_aux_convs.Conv2d_conv10_2         [128, 256, 3, 3]      [3, 256, 3, 3]   \n",
            "39_aux_convs.Conv2d_conv11_1         [256, 128, 1, 1]      [3, 128, 3, 3]   \n",
            "40_aux_convs.Conv2d_conv11_2         [128, 256, 3, 3]      [3, 256, 1, 1]   \n",
            "41_pred_convs.Conv2d_loc_conv4_3      [512, 16, 3, 3]     [3, 16, 38, 38]   \n",
            "42_pred_convs.Conv2d_loc_conv7       [1024, 24, 3, 3]     [3, 24, 19, 19]   \n",
            "43_pred_convs.Conv2d_loc_conv8_2      [512, 24, 3, 3]     [3, 24, 10, 10]   \n",
            "44_pred_convs.Conv2d_loc_conv9_2      [256, 24, 3, 3]       [3, 24, 5, 5]   \n",
            "45_pred_convs.Conv2d_loc_conv10_2     [256, 16, 3, 3]       [3, 16, 3, 3]   \n",
            "46_pred_convs.Conv2d_loc_conv11_2     [256, 16, 3, 3]       [3, 16, 1, 1]   \n",
            "47_pred_convs.Conv2d_cl_conv4_3       [512, 80, 3, 3]     [3, 80, 38, 38]   \n",
            "48_pred_convs.Conv2d_cl_conv7       [1024, 120, 3, 3]    [3, 120, 19, 19]   \n",
            "49_pred_convs.Conv2d_cl_conv8_2      [512, 120, 3, 3]    [3, 120, 10, 10]   \n",
            "50_pred_convs.Conv2d_cl_conv9_2      [256, 120, 3, 3]      [3, 120, 5, 5]   \n",
            "51_pred_convs.Conv2d_cl_conv10_2      [256, 80, 3, 3]       [3, 80, 3, 3]   \n",
            "52_pred_convs.Conv2d_cl_conv11_2      [256, 80, 3, 3]       [3, 80, 1, 1]   \n",
            "\n",
            "                                      Params     Mult-Adds  \n",
            "Layer                                                       \n",
            "0_base.Conv2d_conv1_1                 1.792k       155.52M  \n",
            "1_base.BatchNorm2d_bn_1_1              128.0          64.0  \n",
            "2_base.Conv2d_conv1_2                36.928k      3.31776G  \n",
            "3_base.BatchNorm2d_bn_1_2              128.0          64.0  \n",
            "4_base.MaxPool2d_pool1                     -             -  \n",
            "5_base.Conv2d_conv2_1                73.856k      1.65888G  \n",
            "6_base.BatchNorm2d_bn_2_1              256.0         128.0  \n",
            "7_base.Conv2d_conv2_2               147.584k      3.31776G  \n",
            "8_base.BatchNorm2d_bn_2_2              256.0         128.0  \n",
            "9_base.MaxPool2d_pool2                     -             -  \n",
            "10_base.Conv2d_conv3_1              295.168k      1.65888G  \n",
            "11_base.BatchNorm2d_bn_3_1             512.0         256.0  \n",
            "12_base.Conv2d_conv3_2               590.08k      3.31776G  \n",
            "13_base.BatchNorm2d_bn_3_2             512.0         256.0  \n",
            "14_base.Conv2d_conv3_3               590.08k      3.31776G  \n",
            "15_base.BatchNorm2d_bn_3_3             512.0         256.0  \n",
            "16_base.MaxPool2d_pool3                    -             -  \n",
            "17_base.Conv2d_conv4_1              1.18016M  1.703411712G  \n",
            "18_base.BatchNorm2d_bn_4_1            1.024k         512.0  \n",
            "19_base.Conv2d_conv4_2             2.359808M  3.406823424G  \n",
            "20_base.BatchNorm2d_bn_4_2            1.024k         512.0  \n",
            "21_base.Conv2d_conv4_3             2.359808M  3.406823424G  \n",
            "22_base.BatchNorm2d_bn_4_3            1.024k         512.0  \n",
            "23_base.MaxPool2d_pool4                    -             -  \n",
            "24_base.Conv2d_conv5_1             2.359808M   851.705856M  \n",
            "25_base.BatchNorm2d_bn_5_1            1.024k         512.0  \n",
            "26_base.Conv2d_conv5_2             2.359808M   851.705856M  \n",
            "27_base.BatchNorm2d_bn_5_2            1.024k         512.0  \n",
            "28_base.Conv2d_conv5_3             2.359808M   851.705856M  \n",
            "29_base.BatchNorm2d_bn_5_3            1.024k         512.0  \n",
            "30_base.MaxPool2d_pool5                    -             -  \n",
            "31_base.Conv2d_conv6               4.719616M  1.703411712G  \n",
            "32_base.Conv2d_conv7                 1.0496M   378.535936M  \n",
            "33_aux_convs.Conv2d_conv8_1           262.4k    94.633984M  \n",
            "34_aux_convs.Conv2d_conv8_2         1.18016M     117.9648M  \n",
            "35_aux_convs.Conv2d_conv9_1          65.664k       6.5536M  \n",
            "36_aux_convs.Conv2d_conv9_2         295.168k       7.3728M  \n",
            "37_aux_convs.Conv2d_conv10_1         32.896k        819.2k  \n",
            "38_aux_convs.Conv2d_conv10_2        295.168k     2.654208M  \n",
            "39_aux_convs.Conv2d_conv11_1         32.896k      294.912k  \n",
            "40_aux_convs.Conv2d_conv11_2        295.168k      294.912k  \n",
            "41_pred_convs.Conv2d_loc_conv4_3     73.744k   106.463232M  \n",
            "42_pred_convs.Conv2d_loc_conv7      221.208k    79.847424M  \n",
            "43_pred_convs.Conv2d_loc_conv8_2    110.616k      11.0592M  \n",
            "44_pred_convs.Conv2d_loc_conv9_2      55.32k       1.3824M  \n",
            "45_pred_convs.Conv2d_loc_conv10_2     36.88k      331.776k  \n",
            "46_pred_convs.Conv2d_loc_conv11_2     36.88k       36.864k  \n",
            "47_pred_convs.Conv2d_cl_conv4_3      368.72k    532.31616M  \n",
            "48_pred_convs.Conv2d_cl_conv7       1.10604M    399.23712M  \n",
            "49_pred_convs.Conv2d_cl_conv8_2      553.08k       55.296M  \n",
            "50_pred_convs.Conv2d_cl_conv9_2       276.6k        6.912M  \n",
            "51_pred_convs.Conv2d_cl_conv10_2      184.4k      1.65888M  \n",
            "52_pred_convs.Conv2d_cl_conv11_2      184.4k       184.32k  \n",
            "--------------------------------------------------------------------------------------------------\n",
            "                             Totals\n",
            "Total params              26.15976M\n",
            "Trainable params          26.15976M\n",
            "Non-trainable params            0.0\n",
            "Mult-Adds             31.323761792G\n",
            "==================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_base.Conv2d_conv1_1</th>\n",
              "      <td>[3, 64, 3, 3]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>1792.0</td>\n",
              "      <td>1.555200e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_base.BatchNorm2d_bn_1_1</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_base.Conv2d_conv1_2</th>\n",
              "      <td>[64, 64, 3, 3]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>36928.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_base.BatchNorm2d_bn_1_2</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_base.MaxPool2d_pool1</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 64, 150, 150]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_base.Conv2d_conv2_1</th>\n",
              "      <td>[64, 128, 3, 3]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>73856.0</td>\n",
              "      <td>1.658880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_base.BatchNorm2d_bn_2_1</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.280000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_base.Conv2d_conv2_2</th>\n",
              "      <td>[128, 128, 3, 3]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>147584.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_base.BatchNorm2d_bn_2_2</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.280000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_base.MaxPool2d_pool2</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 128, 75, 75]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_base.Conv2d_conv3_1</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>1.658880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_base.BatchNorm2d_bn_3_1</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_base.Conv2d_conv3_2</th>\n",
              "      <td>[256, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>590080.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_base.BatchNorm2d_bn_3_2</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_base.Conv2d_conv3_3</th>\n",
              "      <td>[256, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>590080.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_base.BatchNorm2d_bn_3_3</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_base.MaxPool2d_pool3</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 256, 38, 38]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_base.Conv2d_conv4_1</th>\n",
              "      <td>[256, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1180160.0</td>\n",
              "      <td>1.703412e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_base.BatchNorm2d_bn_4_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_base.Conv2d_conv4_2</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>3.406823e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_base.BatchNorm2d_bn_4_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_base.Conv2d_conv4_3</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>3.406823e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_base.BatchNorm2d_bn_4_3</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_base.MaxPool2d_pool4</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_base.Conv2d_conv5_1</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_base.BatchNorm2d_bn_5_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_base.Conv2d_conv5_2</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_base.BatchNorm2d_bn_5_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_base.Conv2d_conv5_3</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_base.BatchNorm2d_bn_5_3</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_base.MaxPool2d_pool5</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_base.Conv2d_conv6</th>\n",
              "      <td>[512, 1024, 3, 3]</td>\n",
              "      <td>[3, 1024, 19, 19]</td>\n",
              "      <td>4719616.0</td>\n",
              "      <td>1.703412e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_base.Conv2d_conv7</th>\n",
              "      <td>[1024, 1024, 1, 1]</td>\n",
              "      <td>[3, 1024, 19, 19]</td>\n",
              "      <td>1049600.0</td>\n",
              "      <td>3.785359e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_aux_convs.Conv2d_conv8_1</th>\n",
              "      <td>[1024, 256, 1, 1]</td>\n",
              "      <td>[3, 256, 19, 19]</td>\n",
              "      <td>262400.0</td>\n",
              "      <td>9.463398e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_aux_convs.Conv2d_conv8_2</th>\n",
              "      <td>[256, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 10, 10]</td>\n",
              "      <td>1180160.0</td>\n",
              "      <td>1.179648e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_aux_convs.Conv2d_conv9_1</th>\n",
              "      <td>[512, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 10, 10]</td>\n",
              "      <td>65664.0</td>\n",
              "      <td>6.553600e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_aux_convs.Conv2d_conv9_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 5, 5]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>7.372800e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37_aux_convs.Conv2d_conv10_1</th>\n",
              "      <td>[256, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 5, 5]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>8.192000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38_aux_convs.Conv2d_conv10_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 3, 3]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>2.654208e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39_aux_convs.Conv2d_conv11_1</th>\n",
              "      <td>[256, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 3, 3]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>2.949120e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40_aux_convs.Conv2d_conv11_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 1, 1]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>2.949120e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41_pred_convs.Conv2d_loc_conv4_3</th>\n",
              "      <td>[512, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 38, 38]</td>\n",
              "      <td>73744.0</td>\n",
              "      <td>1.064632e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42_pred_convs.Conv2d_loc_conv7</th>\n",
              "      <td>[1024, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 19, 19]</td>\n",
              "      <td>221208.0</td>\n",
              "      <td>7.984742e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43_pred_convs.Conv2d_loc_conv8_2</th>\n",
              "      <td>[512, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 10, 10]</td>\n",
              "      <td>110616.0</td>\n",
              "      <td>1.105920e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44_pred_convs.Conv2d_loc_conv9_2</th>\n",
              "      <td>[256, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 5, 5]</td>\n",
              "      <td>55320.0</td>\n",
              "      <td>1.382400e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45_pred_convs.Conv2d_loc_conv10_2</th>\n",
              "      <td>[256, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 3, 3]</td>\n",
              "      <td>36880.0</td>\n",
              "      <td>3.317760e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46_pred_convs.Conv2d_loc_conv11_2</th>\n",
              "      <td>[256, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 1, 1]</td>\n",
              "      <td>36880.0</td>\n",
              "      <td>3.686400e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47_pred_convs.Conv2d_cl_conv4_3</th>\n",
              "      <td>[512, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 38, 38]</td>\n",
              "      <td>368720.0</td>\n",
              "      <td>5.323162e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48_pred_convs.Conv2d_cl_conv7</th>\n",
              "      <td>[1024, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 19, 19]</td>\n",
              "      <td>1106040.0</td>\n",
              "      <td>3.992371e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49_pred_convs.Conv2d_cl_conv8_2</th>\n",
              "      <td>[512, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 10, 10]</td>\n",
              "      <td>553080.0</td>\n",
              "      <td>5.529600e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50_pred_convs.Conv2d_cl_conv9_2</th>\n",
              "      <td>[256, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 5, 5]</td>\n",
              "      <td>276600.0</td>\n",
              "      <td>6.912000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51_pred_convs.Conv2d_cl_conv10_2</th>\n",
              "      <td>[256, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 3, 3]</td>\n",
              "      <td>184400.0</td>\n",
              "      <td>1.658880e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52_pred_convs.Conv2d_cl_conv11_2</th>\n",
              "      <td>[256, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 1, 1]</td>\n",
              "      <td>184400.0</td>\n",
              "      <td>1.843200e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Kernel Shape  ...     Mult-Adds\n",
              "Layer                                                  ...              \n",
              "0_base.Conv2d_conv1_1                   [3, 64, 3, 3]  ...  1.555200e+08\n",
              "1_base.BatchNorm2d_bn_1_1                        [64]  ...  6.400000e+01\n",
              "2_base.Conv2d_conv1_2                  [64, 64, 3, 3]  ...  3.317760e+09\n",
              "3_base.BatchNorm2d_bn_1_2                        [64]  ...  6.400000e+01\n",
              "4_base.MaxPool2d_pool1                              -  ...           NaN\n",
              "5_base.Conv2d_conv2_1                 [64, 128, 3, 3]  ...  1.658880e+09\n",
              "6_base.BatchNorm2d_bn_2_1                       [128]  ...  1.280000e+02\n",
              "7_base.Conv2d_conv2_2                [128, 128, 3, 3]  ...  3.317760e+09\n",
              "8_base.BatchNorm2d_bn_2_2                       [128]  ...  1.280000e+02\n",
              "9_base.MaxPool2d_pool2                              -  ...           NaN\n",
              "10_base.Conv2d_conv3_1               [128, 256, 3, 3]  ...  1.658880e+09\n",
              "11_base.BatchNorm2d_bn_3_1                      [256]  ...  2.560000e+02\n",
              "12_base.Conv2d_conv3_2               [256, 256, 3, 3]  ...  3.317760e+09\n",
              "13_base.BatchNorm2d_bn_3_2                      [256]  ...  2.560000e+02\n",
              "14_base.Conv2d_conv3_3               [256, 256, 3, 3]  ...  3.317760e+09\n",
              "15_base.BatchNorm2d_bn_3_3                      [256]  ...  2.560000e+02\n",
              "16_base.MaxPool2d_pool3                             -  ...           NaN\n",
              "17_base.Conv2d_conv4_1               [256, 512, 3, 3]  ...  1.703412e+09\n",
              "18_base.BatchNorm2d_bn_4_1                      [512]  ...  5.120000e+02\n",
              "19_base.Conv2d_conv4_2               [512, 512, 3, 3]  ...  3.406823e+09\n",
              "20_base.BatchNorm2d_bn_4_2                      [512]  ...  5.120000e+02\n",
              "21_base.Conv2d_conv4_3               [512, 512, 3, 3]  ...  3.406823e+09\n",
              "22_base.BatchNorm2d_bn_4_3                      [512]  ...  5.120000e+02\n",
              "23_base.MaxPool2d_pool4                             -  ...           NaN\n",
              "24_base.Conv2d_conv5_1               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "25_base.BatchNorm2d_bn_5_1                      [512]  ...  5.120000e+02\n",
              "26_base.Conv2d_conv5_2               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "27_base.BatchNorm2d_bn_5_2                      [512]  ...  5.120000e+02\n",
              "28_base.Conv2d_conv5_3               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "29_base.BatchNorm2d_bn_5_3                      [512]  ...  5.120000e+02\n",
              "30_base.MaxPool2d_pool5                             -  ...           NaN\n",
              "31_base.Conv2d_conv6                [512, 1024, 3, 3]  ...  1.703412e+09\n",
              "32_base.Conv2d_conv7               [1024, 1024, 1, 1]  ...  3.785359e+08\n",
              "33_aux_convs.Conv2d_conv8_1         [1024, 256, 1, 1]  ...  9.463398e+07\n",
              "34_aux_convs.Conv2d_conv8_2          [256, 512, 3, 3]  ...  1.179648e+08\n",
              "35_aux_convs.Conv2d_conv9_1          [512, 128, 1, 1]  ...  6.553600e+06\n",
              "36_aux_convs.Conv2d_conv9_2          [128, 256, 3, 3]  ...  7.372800e+06\n",
              "37_aux_convs.Conv2d_conv10_1         [256, 128, 1, 1]  ...  8.192000e+05\n",
              "38_aux_convs.Conv2d_conv10_2         [128, 256, 3, 3]  ...  2.654208e+06\n",
              "39_aux_convs.Conv2d_conv11_1         [256, 128, 1, 1]  ...  2.949120e+05\n",
              "40_aux_convs.Conv2d_conv11_2         [128, 256, 3, 3]  ...  2.949120e+05\n",
              "41_pred_convs.Conv2d_loc_conv4_3      [512, 16, 3, 3]  ...  1.064632e+08\n",
              "42_pred_convs.Conv2d_loc_conv7       [1024, 24, 3, 3]  ...  7.984742e+07\n",
              "43_pred_convs.Conv2d_loc_conv8_2      [512, 24, 3, 3]  ...  1.105920e+07\n",
              "44_pred_convs.Conv2d_loc_conv9_2      [256, 24, 3, 3]  ...  1.382400e+06\n",
              "45_pred_convs.Conv2d_loc_conv10_2     [256, 16, 3, 3]  ...  3.317760e+05\n",
              "46_pred_convs.Conv2d_loc_conv11_2     [256, 16, 3, 3]  ...  3.686400e+04\n",
              "47_pred_convs.Conv2d_cl_conv4_3       [512, 80, 3, 3]  ...  5.323162e+08\n",
              "48_pred_convs.Conv2d_cl_conv7       [1024, 120, 3, 3]  ...  3.992371e+08\n",
              "49_pred_convs.Conv2d_cl_conv8_2      [512, 120, 3, 3]  ...  5.529600e+07\n",
              "50_pred_convs.Conv2d_cl_conv9_2      [256, 120, 3, 3]  ...  6.912000e+06\n",
              "51_pred_convs.Conv2d_cl_conv10_2      [256, 80, 3, 3]  ...  1.658880e+06\n",
              "52_pred_convs.Conv2d_cl_conv11_2      [256, 80, 3, 3]  ...  1.843200e+05\n",
              "\n",
              "[53 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgGy0J07PYI",
        "colab_type": "text"
      },
      "source": [
        "Final Note: Normally, if we use architectures directly from `TorchVision` or `Keras` we would have nice model summary just like this.<br>\n",
        "This libarary is particular useful when we want to inspect user people's model or a verions that we have modified besed on commonly used models like the example above.<br>\n",
        "In addition, we have a nice visualization of **num of parameters** & **output demension** for each layer which is kind of nice for debugging your own model or simply for reference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS8Qzs_S8Lo3",
        "colab_type": "text"
      },
      "source": [
        "# Trick #2\n",
        "PyTorch Hooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWIJf1TcEv03",
        "colab_type": "text"
      },
      "source": [
        "PyTorch hook is a tool that we can *register* to any **tensor** or **nn.Module** during our computation so that we can monitor what is going on with our `forward` and `backward` loops.<bR>\n",
        "The `forward` is not refered to `nn.Module.forward` bu the `torch.Autograd.Function` object that is the `grad_fn` of a **tensor**.<br>\n",
        "Notice, that a `nn.Module` like `nn.Linear` can have multiple `forward` invocations. It's output is created by two operations, $Y = W*X+B$, *addition* and *multiplication* and thus there will be two `forward` calls. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGFUQPW4EzyW",
        "colab_type": "text"
      },
      "source": [
        "## Hook types\n",
        "1. The Forward Hook\n",
        "2. The Backward Hook\n",
        "\n",
        "A forward hook is excuted during the forward pass, while the backward hook is executed when `backward` function is called both of which are *functions* of `Autograd.Funciton` object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCcDR2L2E8lh",
        "colab_type": "text"
      },
      "source": [
        "A hook in PyTorch is basically a function, with a very specific signature. When we say a hook is executed, in reality, we are talkingabout this function being executed.<br>\n",
        "`grad` is basically the value contained in the `grad` attribute of the tensor **after** `backward` is called. The function is not supposed to modify it's argument. It must either return `None` or a Tensor which will be used in place of `grad` for further gradient computations.<br>\n",
        "The below example clarifies this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt1yLHsIE-kH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46825495-22c9-4cc0-b18a-53f310620006"
      },
      "source": [
        "import torch\n",
        "a = torch.ones(10)\n",
        "a.requires_grad"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6umlITCaE_-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39ee53ac-cf72-4d1c-fe61-2e6966584776"
      },
      "source": [
        "a.requires_grad = True\n",
        "a.requires_grad"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOXhle3FMu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4db600c2-c6d9-41e2-b95a-81b7976e8600"
      },
      "source": [
        "b = 2*a\n",
        "b.requires_grad"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBCy0MTPFNw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dbcd0199-12a9-4ea3-c8d9-207c92a2b49f"
      },
      "source": [
        "print(a.is_leaf)\n",
        "print(b.is_leaf)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COtQrZf3Gb_M",
        "colab_type": "text"
      },
      "source": [
        "Since `b` is not a **leaf Variable**, its `grad` will by degault be destroyed during computation.<br>\n",
        "We can used `b.retain_grad()` to ask PyTorch to retain its `grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4dnUuoGr7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.retain_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A13yk-8XGteU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c6e1459b-41ff-49df-b02c-a84687acf16d"
      },
      "source": [
        "c = b.mean()\n",
        "print(f\"requires_grad: {c.requires_grad}\")\n",
        "print(f\"is_lead: {c.is_leaf}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requires_grad: True\n",
            "is_lead: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCBXiXdGvM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "df1b209d-b5df-4a94-b7c7-d4b28dd92f72"
      },
      "source": [
        "# pretend c is the loss being computed\n",
        "c.backward()\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnyGJjm7G9yM",
        "colab_type": "text"
      },
      "source": [
        "Now we redo the experiment but with a **hook** that multiplies `b`'s grad by 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-2bzclHJUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6fba9014-a249-431b-85d5-da8482cbe9c3"
      },
      "source": [
        "a = torch.ones(10)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.register_hook(lambda x:print(x))\n",
        "b.mean().backward() # pretend the mean of b is the loss we want to back-prop"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtFRGFtlHd0t",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that, the print out is exactly the same result by using **hook** on `b`, and the `lambda` function automatically take the `b.grad` as input.<br>\n",
        "This gives us a sense that hook is tracking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilIASlZvH963",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "51f118b1-72f6-4950-f3c0-872184b45606"
      },
      "source": [
        "print(a.grad, b.grad)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJA-J_laIA_H",
        "colab_type": "text"
      },
      "source": [
        "There are several uses of functionality as above:\n",
        "1. We can print the *value* of gradient for **debugging**. We can also log them. This is especially useful with `non-leaf` variables whose gradients are freed up unless we perform `retain_grad` upon them. Doing the latter can lead to increased memory retention. Hooks provide much cleaner way to aggregate these values.\n",
        "2. We can modify gradient **during** the backward pass. This is very important. While we can still access the `grad` variable of a tensor in a network, we can only access it after the **entire backward pass** has been processed. For example, we multiplied `b`'s gradient by 2, and now the subsequent gradient calculations, like those of `a`(or any tensor that will depend upon `b` for gradient) used `2*brad(b)` instead of `grad(b)`. In contrast, had we individually updated the parameters **after** the `backward`, we'd have to multily `b.grad` as well as `a.grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHm9_tHdJHt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "eafe0e32-3579-467d-fb5b-344a59f4a264"
      },
      "source": [
        "# to demonstrate\n",
        "a = torch.ones(10)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.mean().backward()\n",
        "\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r6lGboZJXVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "146abb5b-dd76-48e7-a2df-2491abd50910"
      },
      "source": [
        "b.grad *= 2\n",
        "print(a.grad, b.grad) # Note that in this case, a's grad needs to be updated mannually"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbaWOr3vJbWQ",
        "colab_type": "text"
      },
      "source": [
        "## Hooks for nn.Module objects\n",
        "For **backward hook**:\n",
        "`hook(module, grad_input, grad_output)`\n",
        "___\n",
        "For **forward hook**:\n",
        "`hook(module, input, output)`\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQT_tOFZJs6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride=2) # (8-2+0)/2+1 = 4\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I1E-eIqJvZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6949fda0-0152-43bb-c8d3-26562f4f352b"
      },
      "source": [
        "Net = myNet()\n",
        "Net.named_modules"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.named_modules of myNet(\n",
              "  (conv): Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=160, out_features=5, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iLsBZPUJ6hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}