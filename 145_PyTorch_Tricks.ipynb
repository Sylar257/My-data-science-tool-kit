{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "145_PyTorch_Tricks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T8fuVdeJ2ily",
        "fS8Qzs_S8Lo3",
        "bGFUQPW4EzyW",
        "c-dt3yhb1BBk",
        "ElRC_UyfwEOT",
        "JrGtgTXg3CP1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sylar257/My-data-science-tool-kit/blob/master/145_PyTorch_Tricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_rSH7id15Fy",
        "colab_type": "text"
      },
      "source": [
        "# 145 PyTorch Tricks\n",
        "This is a series of useful PyTorch tricks inspired by **vainaijr** in his [YouTube channel](https://www.youtube.com/watch?v=nnHQT9JnY74&list=PLUY8w37x-QUUkawz-cBnjLpvaZWvPZh_s&index=2&t=29s).<br>\n",
        "This notebook is an implementation of all these techniques and is designed in a way to best demonstrate their usefulness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8fuVdeJ2ily",
        "colab_type": "text"
      },
      "source": [
        "# Trick #1\n",
        "Visualization model using `torchsummaryX`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQnXYH10AdtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from Utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTuqtpoh5_mF",
        "colab_type": "text"
      },
      "source": [
        "Here we will build a Single-shot-detection model with just 20 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzAiSJmbAz4h",
        "colab_type": "code",
        "outputId": "23be6a00-28b3-44c1-e45f-9f738eeb8158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Create SSD300 with pretrained weights in the base-architecture\n",
        "n_classes = 20\n",
        "model = SSD300(n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 107MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbRH1ipJBrYR",
        "colab_type": "code",
        "outputId": "51470b25-223b-4fe8-d256-95eba43b1a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# install torchsummaryX\n",
        "!pip install torchsummaryX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading https://files.pythonhosted.org/packages/36/23/87eeaaf70daa61aa21495ece0969c50c446b8fd42c4b8905af264b40fe7f/torchsummaryX-1.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (0.25.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.3.1+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->torchsummaryX) (1.12.0)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcUf7Bgp6dZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummaryX import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B78vIOLG6vY9",
        "colab_type": "text"
      },
      "source": [
        "`summary(model, input)` takes our intentional model and a pseudo input **with the correct shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0Hgjdv6pLu",
        "colab_type": "code",
        "outputId": "1fa823e8-b2e6-486a-aef0-3b9632d8eb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# pseudo input of batch size = 3, num_channel = 3, pixel: 300x300\n",
        "summary(model, torch.zeros((3,3,300,300)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================================================================\n",
            "                                         Kernel Shape        Output Shape  \\\n",
            "Layer                                                                       \n",
            "0_base.Conv2d_conv1_1                   [3, 64, 3, 3]   [3, 64, 300, 300]   \n",
            "1_base.BatchNorm2d_bn_1_1                        [64]   [3, 64, 300, 300]   \n",
            "2_base.Conv2d_conv1_2                  [64, 64, 3, 3]   [3, 64, 300, 300]   \n",
            "3_base.BatchNorm2d_bn_1_2                        [64]   [3, 64, 300, 300]   \n",
            "4_base.MaxPool2d_pool1                              -   [3, 64, 150, 150]   \n",
            "5_base.Conv2d_conv2_1                 [64, 128, 3, 3]  [3, 128, 150, 150]   \n",
            "6_base.BatchNorm2d_bn_2_1                       [128]  [3, 128, 150, 150]   \n",
            "7_base.Conv2d_conv2_2                [128, 128, 3, 3]  [3, 128, 150, 150]   \n",
            "8_base.BatchNorm2d_bn_2_2                       [128]  [3, 128, 150, 150]   \n",
            "9_base.MaxPool2d_pool2                              -    [3, 128, 75, 75]   \n",
            "10_base.Conv2d_conv3_1               [128, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "11_base.BatchNorm2d_bn_3_1                      [256]    [3, 256, 75, 75]   \n",
            "12_base.Conv2d_conv3_2               [256, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "13_base.BatchNorm2d_bn_3_2                      [256]    [3, 256, 75, 75]   \n",
            "14_base.Conv2d_conv3_3               [256, 256, 3, 3]    [3, 256, 75, 75]   \n",
            "15_base.BatchNorm2d_bn_3_3                      [256]    [3, 256, 75, 75]   \n",
            "16_base.MaxPool2d_pool3                             -    [3, 256, 38, 38]   \n",
            "17_base.Conv2d_conv4_1               [256, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "18_base.BatchNorm2d_bn_4_1                      [512]    [3, 512, 38, 38]   \n",
            "19_base.Conv2d_conv4_2               [512, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "20_base.BatchNorm2d_bn_4_2                      [512]    [3, 512, 38, 38]   \n",
            "21_base.Conv2d_conv4_3               [512, 512, 3, 3]    [3, 512, 38, 38]   \n",
            "22_base.BatchNorm2d_bn_4_3                      [512]    [3, 512, 38, 38]   \n",
            "23_base.MaxPool2d_pool4                             -    [3, 512, 19, 19]   \n",
            "24_base.Conv2d_conv5_1               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "25_base.BatchNorm2d_bn_5_1                      [512]    [3, 512, 19, 19]   \n",
            "26_base.Conv2d_conv5_2               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "27_base.BatchNorm2d_bn_5_2                      [512]    [3, 512, 19, 19]   \n",
            "28_base.Conv2d_conv5_3               [512, 512, 3, 3]    [3, 512, 19, 19]   \n",
            "29_base.BatchNorm2d_bn_5_3                      [512]    [3, 512, 19, 19]   \n",
            "30_base.MaxPool2d_pool5                             -    [3, 512, 19, 19]   \n",
            "31_base.Conv2d_conv6                [512, 1024, 3, 3]   [3, 1024, 19, 19]   \n",
            "32_base.Conv2d_conv7               [1024, 1024, 1, 1]   [3, 1024, 19, 19]   \n",
            "33_aux_convs.Conv2d_conv8_1         [1024, 256, 1, 1]    [3, 256, 19, 19]   \n",
            "34_aux_convs.Conv2d_conv8_2          [256, 512, 3, 3]    [3, 512, 10, 10]   \n",
            "35_aux_convs.Conv2d_conv9_1          [512, 128, 1, 1]    [3, 128, 10, 10]   \n",
            "36_aux_convs.Conv2d_conv9_2          [128, 256, 3, 3]      [3, 256, 5, 5]   \n",
            "37_aux_convs.Conv2d_conv10_1         [256, 128, 1, 1]      [3, 128, 5, 5]   \n",
            "38_aux_convs.Conv2d_conv10_2         [128, 256, 3, 3]      [3, 256, 3, 3]   \n",
            "39_aux_convs.Conv2d_conv11_1         [256, 128, 1, 1]      [3, 128, 3, 3]   \n",
            "40_aux_convs.Conv2d_conv11_2         [128, 256, 3, 3]      [3, 256, 1, 1]   \n",
            "41_pred_convs.Conv2d_loc_conv4_3      [512, 16, 3, 3]     [3, 16, 38, 38]   \n",
            "42_pred_convs.Conv2d_loc_conv7       [1024, 24, 3, 3]     [3, 24, 19, 19]   \n",
            "43_pred_convs.Conv2d_loc_conv8_2      [512, 24, 3, 3]     [3, 24, 10, 10]   \n",
            "44_pred_convs.Conv2d_loc_conv9_2      [256, 24, 3, 3]       [3, 24, 5, 5]   \n",
            "45_pred_convs.Conv2d_loc_conv10_2     [256, 16, 3, 3]       [3, 16, 3, 3]   \n",
            "46_pred_convs.Conv2d_loc_conv11_2     [256, 16, 3, 3]       [3, 16, 1, 1]   \n",
            "47_pred_convs.Conv2d_cl_conv4_3       [512, 80, 3, 3]     [3, 80, 38, 38]   \n",
            "48_pred_convs.Conv2d_cl_conv7       [1024, 120, 3, 3]    [3, 120, 19, 19]   \n",
            "49_pred_convs.Conv2d_cl_conv8_2      [512, 120, 3, 3]    [3, 120, 10, 10]   \n",
            "50_pred_convs.Conv2d_cl_conv9_2      [256, 120, 3, 3]      [3, 120, 5, 5]   \n",
            "51_pred_convs.Conv2d_cl_conv10_2      [256, 80, 3, 3]       [3, 80, 3, 3]   \n",
            "52_pred_convs.Conv2d_cl_conv11_2      [256, 80, 3, 3]       [3, 80, 1, 1]   \n",
            "\n",
            "                                      Params     Mult-Adds  \n",
            "Layer                                                       \n",
            "0_base.Conv2d_conv1_1                 1.792k       155.52M  \n",
            "1_base.BatchNorm2d_bn_1_1              128.0          64.0  \n",
            "2_base.Conv2d_conv1_2                36.928k      3.31776G  \n",
            "3_base.BatchNorm2d_bn_1_2              128.0          64.0  \n",
            "4_base.MaxPool2d_pool1                     -             -  \n",
            "5_base.Conv2d_conv2_1                73.856k      1.65888G  \n",
            "6_base.BatchNorm2d_bn_2_1              256.0         128.0  \n",
            "7_base.Conv2d_conv2_2               147.584k      3.31776G  \n",
            "8_base.BatchNorm2d_bn_2_2              256.0         128.0  \n",
            "9_base.MaxPool2d_pool2                     -             -  \n",
            "10_base.Conv2d_conv3_1              295.168k      1.65888G  \n",
            "11_base.BatchNorm2d_bn_3_1             512.0         256.0  \n",
            "12_base.Conv2d_conv3_2               590.08k      3.31776G  \n",
            "13_base.BatchNorm2d_bn_3_2             512.0         256.0  \n",
            "14_base.Conv2d_conv3_3               590.08k      3.31776G  \n",
            "15_base.BatchNorm2d_bn_3_3             512.0         256.0  \n",
            "16_base.MaxPool2d_pool3                    -             -  \n",
            "17_base.Conv2d_conv4_1              1.18016M  1.703411712G  \n",
            "18_base.BatchNorm2d_bn_4_1            1.024k         512.0  \n",
            "19_base.Conv2d_conv4_2             2.359808M  3.406823424G  \n",
            "20_base.BatchNorm2d_bn_4_2            1.024k         512.0  \n",
            "21_base.Conv2d_conv4_3             2.359808M  3.406823424G  \n",
            "22_base.BatchNorm2d_bn_4_3            1.024k         512.0  \n",
            "23_base.MaxPool2d_pool4                    -             -  \n",
            "24_base.Conv2d_conv5_1             2.359808M   851.705856M  \n",
            "25_base.BatchNorm2d_bn_5_1            1.024k         512.0  \n",
            "26_base.Conv2d_conv5_2             2.359808M   851.705856M  \n",
            "27_base.BatchNorm2d_bn_5_2            1.024k         512.0  \n",
            "28_base.Conv2d_conv5_3             2.359808M   851.705856M  \n",
            "29_base.BatchNorm2d_bn_5_3            1.024k         512.0  \n",
            "30_base.MaxPool2d_pool5                    -             -  \n",
            "31_base.Conv2d_conv6               4.719616M  1.703411712G  \n",
            "32_base.Conv2d_conv7                 1.0496M   378.535936M  \n",
            "33_aux_convs.Conv2d_conv8_1           262.4k    94.633984M  \n",
            "34_aux_convs.Conv2d_conv8_2         1.18016M     117.9648M  \n",
            "35_aux_convs.Conv2d_conv9_1          65.664k       6.5536M  \n",
            "36_aux_convs.Conv2d_conv9_2         295.168k       7.3728M  \n",
            "37_aux_convs.Conv2d_conv10_1         32.896k        819.2k  \n",
            "38_aux_convs.Conv2d_conv10_2        295.168k     2.654208M  \n",
            "39_aux_convs.Conv2d_conv11_1         32.896k      294.912k  \n",
            "40_aux_convs.Conv2d_conv11_2        295.168k      294.912k  \n",
            "41_pred_convs.Conv2d_loc_conv4_3     73.744k   106.463232M  \n",
            "42_pred_convs.Conv2d_loc_conv7      221.208k    79.847424M  \n",
            "43_pred_convs.Conv2d_loc_conv8_2    110.616k      11.0592M  \n",
            "44_pred_convs.Conv2d_loc_conv9_2      55.32k       1.3824M  \n",
            "45_pred_convs.Conv2d_loc_conv10_2     36.88k      331.776k  \n",
            "46_pred_convs.Conv2d_loc_conv11_2     36.88k       36.864k  \n",
            "47_pred_convs.Conv2d_cl_conv4_3      368.72k    532.31616M  \n",
            "48_pred_convs.Conv2d_cl_conv7       1.10604M    399.23712M  \n",
            "49_pred_convs.Conv2d_cl_conv8_2      553.08k       55.296M  \n",
            "50_pred_convs.Conv2d_cl_conv9_2       276.6k        6.912M  \n",
            "51_pred_convs.Conv2d_cl_conv10_2      184.4k      1.65888M  \n",
            "52_pred_convs.Conv2d_cl_conv11_2      184.4k       184.32k  \n",
            "--------------------------------------------------------------------------------------------------\n",
            "                             Totals\n",
            "Total params              26.15976M\n",
            "Trainable params          26.15976M\n",
            "Non-trainable params            0.0\n",
            "Mult-Adds             31.323761792G\n",
            "==================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_base.Conv2d_conv1_1</th>\n",
              "      <td>[3, 64, 3, 3]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>1792.0</td>\n",
              "      <td>1.555200e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_base.BatchNorm2d_bn_1_1</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_base.Conv2d_conv1_2</th>\n",
              "      <td>[64, 64, 3, 3]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>36928.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_base.BatchNorm2d_bn_1_2</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[3, 64, 300, 300]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_base.MaxPool2d_pool1</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 64, 150, 150]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_base.Conv2d_conv2_1</th>\n",
              "      <td>[64, 128, 3, 3]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>73856.0</td>\n",
              "      <td>1.658880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_base.BatchNorm2d_bn_2_1</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.280000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_base.Conv2d_conv2_2</th>\n",
              "      <td>[128, 128, 3, 3]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>147584.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_base.BatchNorm2d_bn_2_2</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[3, 128, 150, 150]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.280000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_base.MaxPool2d_pool2</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 128, 75, 75]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_base.Conv2d_conv3_1</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>1.658880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_base.BatchNorm2d_bn_3_1</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_base.Conv2d_conv3_2</th>\n",
              "      <td>[256, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>590080.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_base.BatchNorm2d_bn_3_2</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_base.Conv2d_conv3_3</th>\n",
              "      <td>[256, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>590080.0</td>\n",
              "      <td>3.317760e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_base.BatchNorm2d_bn_3_3</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[3, 256, 75, 75]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>2.560000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_base.MaxPool2d_pool3</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 256, 38, 38]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_base.Conv2d_conv4_1</th>\n",
              "      <td>[256, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1180160.0</td>\n",
              "      <td>1.703412e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_base.BatchNorm2d_bn_4_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_base.Conv2d_conv4_2</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>3.406823e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_base.BatchNorm2d_bn_4_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_base.Conv2d_conv4_3</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>3.406823e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_base.BatchNorm2d_bn_4_3</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 38, 38]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_base.MaxPool2d_pool4</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_base.Conv2d_conv5_1</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_base.BatchNorm2d_bn_5_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_base.Conv2d_conv5_2</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_base.BatchNorm2d_bn_5_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_base.Conv2d_conv5_3</th>\n",
              "      <td>[512, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>2359808.0</td>\n",
              "      <td>8.517059e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_base.BatchNorm2d_bn_5_3</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>5.120000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_base.MaxPool2d_pool5</th>\n",
              "      <td>-</td>\n",
              "      <td>[3, 512, 19, 19]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_base.Conv2d_conv6</th>\n",
              "      <td>[512, 1024, 3, 3]</td>\n",
              "      <td>[3, 1024, 19, 19]</td>\n",
              "      <td>4719616.0</td>\n",
              "      <td>1.703412e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_base.Conv2d_conv7</th>\n",
              "      <td>[1024, 1024, 1, 1]</td>\n",
              "      <td>[3, 1024, 19, 19]</td>\n",
              "      <td>1049600.0</td>\n",
              "      <td>3.785359e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_aux_convs.Conv2d_conv8_1</th>\n",
              "      <td>[1024, 256, 1, 1]</td>\n",
              "      <td>[3, 256, 19, 19]</td>\n",
              "      <td>262400.0</td>\n",
              "      <td>9.463398e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_aux_convs.Conv2d_conv8_2</th>\n",
              "      <td>[256, 512, 3, 3]</td>\n",
              "      <td>[3, 512, 10, 10]</td>\n",
              "      <td>1180160.0</td>\n",
              "      <td>1.179648e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_aux_convs.Conv2d_conv9_1</th>\n",
              "      <td>[512, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 10, 10]</td>\n",
              "      <td>65664.0</td>\n",
              "      <td>6.553600e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_aux_convs.Conv2d_conv9_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 5, 5]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>7.372800e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37_aux_convs.Conv2d_conv10_1</th>\n",
              "      <td>[256, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 5, 5]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>8.192000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38_aux_convs.Conv2d_conv10_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 3, 3]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>2.654208e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39_aux_convs.Conv2d_conv11_1</th>\n",
              "      <td>[256, 128, 1, 1]</td>\n",
              "      <td>[3, 128, 3, 3]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>2.949120e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40_aux_convs.Conv2d_conv11_2</th>\n",
              "      <td>[128, 256, 3, 3]</td>\n",
              "      <td>[3, 256, 1, 1]</td>\n",
              "      <td>295168.0</td>\n",
              "      <td>2.949120e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41_pred_convs.Conv2d_loc_conv4_3</th>\n",
              "      <td>[512, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 38, 38]</td>\n",
              "      <td>73744.0</td>\n",
              "      <td>1.064632e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42_pred_convs.Conv2d_loc_conv7</th>\n",
              "      <td>[1024, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 19, 19]</td>\n",
              "      <td>221208.0</td>\n",
              "      <td>7.984742e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43_pred_convs.Conv2d_loc_conv8_2</th>\n",
              "      <td>[512, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 10, 10]</td>\n",
              "      <td>110616.0</td>\n",
              "      <td>1.105920e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44_pred_convs.Conv2d_loc_conv9_2</th>\n",
              "      <td>[256, 24, 3, 3]</td>\n",
              "      <td>[3, 24, 5, 5]</td>\n",
              "      <td>55320.0</td>\n",
              "      <td>1.382400e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45_pred_convs.Conv2d_loc_conv10_2</th>\n",
              "      <td>[256, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 3, 3]</td>\n",
              "      <td>36880.0</td>\n",
              "      <td>3.317760e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46_pred_convs.Conv2d_loc_conv11_2</th>\n",
              "      <td>[256, 16, 3, 3]</td>\n",
              "      <td>[3, 16, 1, 1]</td>\n",
              "      <td>36880.0</td>\n",
              "      <td>3.686400e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47_pred_convs.Conv2d_cl_conv4_3</th>\n",
              "      <td>[512, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 38, 38]</td>\n",
              "      <td>368720.0</td>\n",
              "      <td>5.323162e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48_pred_convs.Conv2d_cl_conv7</th>\n",
              "      <td>[1024, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 19, 19]</td>\n",
              "      <td>1106040.0</td>\n",
              "      <td>3.992371e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49_pred_convs.Conv2d_cl_conv8_2</th>\n",
              "      <td>[512, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 10, 10]</td>\n",
              "      <td>553080.0</td>\n",
              "      <td>5.529600e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50_pred_convs.Conv2d_cl_conv9_2</th>\n",
              "      <td>[256, 120, 3, 3]</td>\n",
              "      <td>[3, 120, 5, 5]</td>\n",
              "      <td>276600.0</td>\n",
              "      <td>6.912000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51_pred_convs.Conv2d_cl_conv10_2</th>\n",
              "      <td>[256, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 3, 3]</td>\n",
              "      <td>184400.0</td>\n",
              "      <td>1.658880e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52_pred_convs.Conv2d_cl_conv11_2</th>\n",
              "      <td>[256, 80, 3, 3]</td>\n",
              "      <td>[3, 80, 1, 1]</td>\n",
              "      <td>184400.0</td>\n",
              "      <td>1.843200e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Kernel Shape  ...     Mult-Adds\n",
              "Layer                                                  ...              \n",
              "0_base.Conv2d_conv1_1                   [3, 64, 3, 3]  ...  1.555200e+08\n",
              "1_base.BatchNorm2d_bn_1_1                        [64]  ...  6.400000e+01\n",
              "2_base.Conv2d_conv1_2                  [64, 64, 3, 3]  ...  3.317760e+09\n",
              "3_base.BatchNorm2d_bn_1_2                        [64]  ...  6.400000e+01\n",
              "4_base.MaxPool2d_pool1                              -  ...           NaN\n",
              "5_base.Conv2d_conv2_1                 [64, 128, 3, 3]  ...  1.658880e+09\n",
              "6_base.BatchNorm2d_bn_2_1                       [128]  ...  1.280000e+02\n",
              "7_base.Conv2d_conv2_2                [128, 128, 3, 3]  ...  3.317760e+09\n",
              "8_base.BatchNorm2d_bn_2_2                       [128]  ...  1.280000e+02\n",
              "9_base.MaxPool2d_pool2                              -  ...           NaN\n",
              "10_base.Conv2d_conv3_1               [128, 256, 3, 3]  ...  1.658880e+09\n",
              "11_base.BatchNorm2d_bn_3_1                      [256]  ...  2.560000e+02\n",
              "12_base.Conv2d_conv3_2               [256, 256, 3, 3]  ...  3.317760e+09\n",
              "13_base.BatchNorm2d_bn_3_2                      [256]  ...  2.560000e+02\n",
              "14_base.Conv2d_conv3_3               [256, 256, 3, 3]  ...  3.317760e+09\n",
              "15_base.BatchNorm2d_bn_3_3                      [256]  ...  2.560000e+02\n",
              "16_base.MaxPool2d_pool3                             -  ...           NaN\n",
              "17_base.Conv2d_conv4_1               [256, 512, 3, 3]  ...  1.703412e+09\n",
              "18_base.BatchNorm2d_bn_4_1                      [512]  ...  5.120000e+02\n",
              "19_base.Conv2d_conv4_2               [512, 512, 3, 3]  ...  3.406823e+09\n",
              "20_base.BatchNorm2d_bn_4_2                      [512]  ...  5.120000e+02\n",
              "21_base.Conv2d_conv4_3               [512, 512, 3, 3]  ...  3.406823e+09\n",
              "22_base.BatchNorm2d_bn_4_3                      [512]  ...  5.120000e+02\n",
              "23_base.MaxPool2d_pool4                             -  ...           NaN\n",
              "24_base.Conv2d_conv5_1               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "25_base.BatchNorm2d_bn_5_1                      [512]  ...  5.120000e+02\n",
              "26_base.Conv2d_conv5_2               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "27_base.BatchNorm2d_bn_5_2                      [512]  ...  5.120000e+02\n",
              "28_base.Conv2d_conv5_3               [512, 512, 3, 3]  ...  8.517059e+08\n",
              "29_base.BatchNorm2d_bn_5_3                      [512]  ...  5.120000e+02\n",
              "30_base.MaxPool2d_pool5                             -  ...           NaN\n",
              "31_base.Conv2d_conv6                [512, 1024, 3, 3]  ...  1.703412e+09\n",
              "32_base.Conv2d_conv7               [1024, 1024, 1, 1]  ...  3.785359e+08\n",
              "33_aux_convs.Conv2d_conv8_1         [1024, 256, 1, 1]  ...  9.463398e+07\n",
              "34_aux_convs.Conv2d_conv8_2          [256, 512, 3, 3]  ...  1.179648e+08\n",
              "35_aux_convs.Conv2d_conv9_1          [512, 128, 1, 1]  ...  6.553600e+06\n",
              "36_aux_convs.Conv2d_conv9_2          [128, 256, 3, 3]  ...  7.372800e+06\n",
              "37_aux_convs.Conv2d_conv10_1         [256, 128, 1, 1]  ...  8.192000e+05\n",
              "38_aux_convs.Conv2d_conv10_2         [128, 256, 3, 3]  ...  2.654208e+06\n",
              "39_aux_convs.Conv2d_conv11_1         [256, 128, 1, 1]  ...  2.949120e+05\n",
              "40_aux_convs.Conv2d_conv11_2         [128, 256, 3, 3]  ...  2.949120e+05\n",
              "41_pred_convs.Conv2d_loc_conv4_3      [512, 16, 3, 3]  ...  1.064632e+08\n",
              "42_pred_convs.Conv2d_loc_conv7       [1024, 24, 3, 3]  ...  7.984742e+07\n",
              "43_pred_convs.Conv2d_loc_conv8_2      [512, 24, 3, 3]  ...  1.105920e+07\n",
              "44_pred_convs.Conv2d_loc_conv9_2      [256, 24, 3, 3]  ...  1.382400e+06\n",
              "45_pred_convs.Conv2d_loc_conv10_2     [256, 16, 3, 3]  ...  3.317760e+05\n",
              "46_pred_convs.Conv2d_loc_conv11_2     [256, 16, 3, 3]  ...  3.686400e+04\n",
              "47_pred_convs.Conv2d_cl_conv4_3       [512, 80, 3, 3]  ...  5.323162e+08\n",
              "48_pred_convs.Conv2d_cl_conv7       [1024, 120, 3, 3]  ...  3.992371e+08\n",
              "49_pred_convs.Conv2d_cl_conv8_2      [512, 120, 3, 3]  ...  5.529600e+07\n",
              "50_pred_convs.Conv2d_cl_conv9_2      [256, 120, 3, 3]  ...  6.912000e+06\n",
              "51_pred_convs.Conv2d_cl_conv10_2      [256, 80, 3, 3]  ...  1.658880e+06\n",
              "52_pred_convs.Conv2d_cl_conv11_2      [256, 80, 3, 3]  ...  1.843200e+05\n",
              "\n",
              "[53 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgGy0J07PYI",
        "colab_type": "text"
      },
      "source": [
        "Final Note: Normally, if we use architectures directly from `TorchVision` or `Keras` we would have nice model summary just like this.<br>\n",
        "This libarary is particular useful when we want to inspect user people's model or a verions that we have modified besed on commonly used models like the example above.<br>\n",
        "In addition, we have a nice visualization of **num of parameters** & **output demension** for each layer which is kind of nice for debugging your own model or simply for reference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS8Qzs_S8Lo3",
        "colab_type": "text"
      },
      "source": [
        "# Trick #2\n",
        "PyTorch Hooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWIJf1TcEv03",
        "colab_type": "text"
      },
      "source": [
        "PyTorch hook is a tool that we can *register* to any **tensor** or **nn.Module** during our computation so that we can monitor what is going on with our `forward` and `backward` loops.<bR>\n",
        "The `forward` is not refered to `nn.Module.forward` bu the `torch.Autograd.Function` object that is the `grad_fn` of a **tensor**.<br>\n",
        "Notice, that a `nn.Module` like `nn.Linear` can have multiple `forward` invocations. It's output is created by two operations, $Y = W*X+B$, *addition* and *multiplication* and thus there will be two `forward` calls. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGFUQPW4EzyW",
        "colab_type": "text"
      },
      "source": [
        "## Hook types\n",
        "1. The Forward Hook\n",
        "2. The Backward Hook\n",
        "\n",
        "A forward hook is excuted during the forward pass, while the backward hook is executed when `backward` function is called both of which are *functions* of `Autograd.Funciton` object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCcDR2L2E8lh",
        "colab_type": "text"
      },
      "source": [
        "A hook in PyTorch is basically a function, with a very specific signature. When we say a hook is executed, in reality, we are talkingabout this function being executed.<br>\n",
        "`grad` is basically the value contained in the `grad` attribute of the tensor **after** `backward` is called. The function is not supposed to modify it's argument. It must either return `None` or a Tensor which will be used in place of `grad` for further gradient computations.<br>\n",
        "The below example clarifies this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt1yLHsIE-kH",
        "colab_type": "code",
        "outputId": "46825495-22c9-4cc0-b18a-53f310620006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "a = torch.ones(10)\n",
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6umlITCaE_-r",
        "colab_type": "code",
        "outputId": "39ee53ac-cf72-4d1c-fe61-2e6966584776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.requires_grad = True\n",
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOXhle3FMu5",
        "colab_type": "code",
        "outputId": "4db600c2-c6d9-41e2-b95a-81b7976e8600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = 2*a\n",
        "b.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBCy0MTPFNw6",
        "colab_type": "code",
        "outputId": "dbcd0199-12a9-4ea3-c8d9-207c92a2b49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(a.is_leaf)\n",
        "print(b.is_leaf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COtQrZf3Gb_M",
        "colab_type": "text"
      },
      "source": [
        "Since `b` is not a **leaf Variable**, its `grad` will by degault be destroyed during computation.<br>\n",
        "We can used `b.retain_grad()` to ask PyTorch to retain its `grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4dnUuoGr7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.retain_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A13yk-8XGteU",
        "colab_type": "code",
        "outputId": "c6e1459b-41ff-49df-b02c-a84687acf16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "c = b.mean()\n",
        "print(f\"requires_grad: {c.requires_grad}\")\n",
        "print(f\"is_lead: {c.is_leaf}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requires_grad: True\n",
            "is_lead: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCBXiXdGvM7",
        "colab_type": "code",
        "outputId": "df1b209d-b5df-4a94-b7c7-d4b28dd92f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# pretend c is the loss being computed\n",
        "c.backward()\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnyGJjm7G9yM",
        "colab_type": "text"
      },
      "source": [
        "Now we redo the experiment but with a **hook** that multiplies `b`'s grad by 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-2bzclHJUs",
        "colab_type": "code",
        "outputId": "6fba9014-a249-431b-85d5-da8482cbe9c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "a = torch.ones(10)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.register_hook(lambda x:print(x))\n",
        "b.mean().backward() # pretend the mean of b is the loss we want to back-prop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtFRGFtlHd0t",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that, the print out is exactly the same result by using **hook** on `b`, and the `lambda` function automatically take the `b.grad` as input.<br>\n",
        "This gives us a sense that hook is tracking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilIASlZvH963",
        "colab_type": "code",
        "outputId": "51f118b1-72f6-4950-f3c0-872184b45606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJA-J_laIA_H",
        "colab_type": "text"
      },
      "source": [
        "There are several uses of functionality as above:\n",
        "1. We can print the *value* of gradient for **debugging**. We can also log them. This is especially useful with `non-leaf` variables whose gradients are freed up unless we perform `retain_grad` upon them. Doing the latter can lead to increased memory retention. Hooks provide much cleaner way to aggregate these values.\n",
        "2. We can modify gradient **during** the backward pass. This is very important. While we can still access the `grad` variable of a tensor in a network, we can only access it after the **entire backward pass** has been processed. For example, we multiplied `b`'s gradient by 2, and now the subsequent gradient calculations, like those of `a`(or any tensor that will depend upon `b` for gradient) used `2*brad(b)` instead of `grad(b)`. In contrast, had we individually updated the parameters **after** the `backward`, we'd have to multily `b.grad` as well as `a.grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHm9_tHdJHt-",
        "colab_type": "code",
        "outputId": "eafe0e32-3579-467d-fb5b-344a59f4a264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# to demonstrate\n",
        "a = torch.ones(10)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.mean().backward()\n",
        "\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r6lGboZJXVn",
        "colab_type": "code",
        "outputId": "146abb5b-dd76-48e7-a2df-2491abd50910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "b.grad *= 2\n",
        "print(a.grad, b.grad) # Note that in this case, a's grad needs to be updated mannually"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbaWOr3vJbWQ",
        "colab_type": "text"
      },
      "source": [
        "## Hooks for nn.Module objects\n",
        "For **backward hook**:\n",
        "`hook(module, grad_input, grad_output)`\n",
        "___\n",
        "For **forward hook**:\n",
        "`hook(module, input, output)`\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQT_tOFZJs6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride=2) # (8-2+0)/2+1 = 4\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I1E-eIqJvZQ",
        "colab_type": "code",
        "outputId": "2cbf707d-6957-4f9d-e74a-1c87a6941013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "Net = myNet()\n",
        "summary(Net,torch.zeros(1,3,8,8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================================================\n",
            "         Kernel Shape   Output Shape Params Mult-Adds\n",
            "Layer                                                \n",
            "0_conv  [3, 10, 2, 2]  [1, 10, 4, 4]  130.0     1.92k\n",
            "1_relu              -  [1, 10, 4, 4]      -         -\n",
            "2_fc1        [160, 5]            [5]  805.0     800.0\n",
            "-------------------------------------------------------\n",
            "                      Totals\n",
            "Total params           935.0\n",
            "Trainable params       935.0\n",
            "Non-trainable params     0.0\n",
            "Mult-Adds              2.72k\n",
            "=======================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_conv</th>\n",
              "      <td>[3, 10, 2, 2]</td>\n",
              "      <td>[1, 10, 4, 4]</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[1, 10, 4, 4]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_fc1</th>\n",
              "      <td>[160, 5]</td>\n",
              "      <td>[5]</td>\n",
              "      <td>805.0</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Kernel Shape   Output Shape  Params  Mult-Adds\n",
              "Layer                                                  \n",
              "0_conv  [3, 10, 2, 2]  [1, 10, 4, 4]   130.0     1920.0\n",
              "1_relu              -  [1, 10, 4, 4]     NaN        NaN\n",
              "2_fc1        [160, 5]            [5]   805.0      800.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iLsBZPUJ6hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hook_fn(m,i,o):\n",
        "    print(m)\n",
        "    print(\"---------Input Grad----------\")\n",
        "\n",
        "    for grad in i:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print(\"None found for input Gradient\")\n",
        "    \n",
        "    print(\"--------Output Grad----------\")\n",
        "    for grad in o:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print(\"None found for output Gradient\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHzpCMysq0zd",
        "colab_type": "code",
        "outputId": "377ab6c8-9591-4236-f959-3e7eaa4b4fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "Net.named_modules"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.named_modules of myNet(\n",
              "  (conv): Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=160, out_features=5, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m11brNsmq9J8",
        "colab_type": "code",
        "outputId": "98618e7c-a1e5-444d-cb41-3ed2e0c4b682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net.conv.register_backward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7fc70953ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWCYFGuZrDiN",
        "colab_type": "code",
        "outputId": "6c9ed40d-f0e7-4094-a119-cb2b442a69c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net.fc1.register_backward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7fc709536b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgqlLmXOrKhc",
        "colab_type": "code",
        "outputId": "6e4cdd1a-3958-4dca-98c1-f547d0b76ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inp = torch.rand(1,3,8,8)\n",
        "out = Net(inp)\n",
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1495, -0.0683,  0.1981,  0.0851, -0.0905], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kweZoTb1rQB8",
        "colab_type": "code",
        "outputId": "14cedf15-2e41-4265-ffe9-6b86b84633c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# pretend we have the following as loss\n",
        "(1-out.mean()).backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=160, out_features=5, bias=True)\n",
            "---------Input Grad----------\n",
            "torch.Size([5])\n",
            "torch.Size([5])\n",
            "--------Output Grad----------\n",
            "torch.Size([5])\n",
            "\n",
            "\n",
            "Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
            "---------Input Grad----------\n",
            "None found for input Gradient\n",
            "torch.Size([10, 3, 2, 2])\n",
            "torch.Size([10])\n",
            "--------Output Grad----------\n",
            "torch.Size([1, 10, 4, 4])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-_oNZPrQsX",
        "colab_type": "text"
      },
      "source": [
        "Note that, the `Linear layer` gets called first because the backward pass actually go through it first and then backprop to the `conv layer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxa-QfPNsG__",
        "colab_type": "text"
      },
      "source": [
        "## Proper way of implementing Hooks(in **back-prop**)er way of implementing Hooks(in **back-prop**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gggioe8JvXQ2",
        "colab_type": "text"
      },
      "source": [
        "We have:\n",
        "1.  torch.autograd.Variable.register_hook (Python method, in Automatic differentiation package)\n",
        "2.  torch.nn.Module.register_backward_hook (Python method, in torch.nn)\n",
        "3.  torch.nn.Module.register_forward_hook\n",
        "\n",
        "The first `register_hook`，is for any **Variable**. It's essentially a **callback** function that is going to be executed every time when `Autograd` gradient is computed.<br>\n",
        "While `Module.register_backward_hook` & `n.Module.register_forward_hook` are for `nn.Module` object and their `hook_fn` shoud take torch:\n",
        "<br>`def hook_fn(m, i, o):` where `i` refers to input and `o` refers to output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIL-6XN9vduD",
        "colab_type": "text"
      },
      "source": [
        "### An example\n",
        "Using `named_parameters` function we can accomplish `gradient modifying/clipping`. <br>\n",
        "The following example does two things:\n",
        "1. Turn gradients of linear biases into zero while back-prop (no updates for biase)\n",
        "2. Make sure that for no gradient going to `conv layer` is less than 0 (all positive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5G2odS-vmgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2,stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "    def forward(self,x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        x.register_hook(lambda grad: torch.clamp(grad, min=0)) # minimun back-prop gradient of value 0\n",
        "\n",
        "        # print whether there is any negative grad\n",
        "        x.register_hook(lambda grad: print(\"Gradients less than zero:\", bool((grad<0).any())))\n",
        "        \n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1zPOxs9z2yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = myNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV_j9ytFz4HL",
        "colab_type": "code",
        "outputId": "17ca2a2e-a15a-4a7e-a81e-a69a18c77811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    print(name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv.weight\n",
            "conv.bias\n",
            "fc1.weight\n",
            "fc1.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSf36kx90BOa",
        "colab_type": "code",
        "outputId": "5b848d26-b650-4f71-d161-863a0c99b331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    if 'fc' in name and 'bias' in name:\n",
        "        print(name, param, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.bias\n",
            "Parameter containing:\n",
            "tensor([-0.0190, -0.0193, -0.0728,  0.0082,  0.0160], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsd-dQl0PJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    if 'fc' in name and 'bias' in name:\n",
        "        # assign zero to bias grad with identical dimensions\n",
        "        param.register_hook(lambda grad: torch.zeros_like(grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-l2x34d0kcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = net(torch.randn(1,3,8,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bAPAHHX0pq8",
        "colab_type": "code",
        "outputId": "b26853f6-a771-40d3-9b3f-830c7a541531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(1-out).mean().backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients less than zero: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quh1OR4606RE",
        "colab_type": "code",
        "outputId": "f6f4c1e2-a0ce-40ef-8a5f-8749d5ad1fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'the bias for linear layer is: {net.fc1.bias.grad}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the bias for linear layer is: tensor([0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-dt3yhb1BBk",
        "colab_type": "text"
      },
      "source": [
        "# Trick #3\n",
        "flops_counter_PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQvziiNM1IXh",
        "colab_type": "text"
      },
      "source": [
        "### Flop counter for convolutional networks in PyTorch framework\n",
        "This script is designed to compute the theoretical amount of multiply-add operations in CNNs.<br>\n",
        "It also can compute the number of parameters and print *per-layer* computational cost of a givent network.<br>\n",
        "Supported layers:\n",
        "* Conv1d/2d/3d (including grouping)\n",
        "* ConvTranspose2d (including grouping)\n",
        "* BatchNorm1d/2d/3d\n",
        "* Activations (ReLU, PReLU, ELU, ReLU6, LeakyReLU)\n",
        "* Linear\n",
        "* Upsample\n",
        "* Poolings (AvgPool1d/2d/3d, MaxPool1d/2d/3d and adaptive ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wpSS5595cOI",
        "colab_type": "text"
      },
      "source": [
        "### Usage tips\n",
        "* This script doesn't take into account `torch.nn.functional`.* operations. For an instance, if one have a semantic segmentation model and use `torch.nn.functional.interpolate` to upscale features, these operations won't contribute to overall amount of flops. To avoid that one can use `torch.nn.Upsample` instead of `torch.nn.functional.interpolate`.\n",
        "* `ptflops` launches a given model on a random tensor and estimates amount of computations during inference. Complicated models can have several inputs, some of them could be optional. To construct non-trivial input one can use the `input_constructor` argument of the `get_model_complexity_info`. `input_constructor` is a function that takes the input spatial resolution as a tuple and returns a dict with named input arguments of the model. Next this dict would be passed to the model as keyworded arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwtE3OXY5xwz",
        "colab_type": "code",
        "outputId": "841fda5e-373c-4b5d-dce3-852bbab3ed0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
            "  Cloning https://github.com/sovrasov/flops-counter.pytorch.git to /tmp/pip-req-build-v7epwkpj\n",
            "  Running command git clone -q https://github.com/sovrasov/flops-counter.pytorch.git /tmp/pip-req-build-v7epwkpj\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from ptflops==0.4) (1.3.1+cu100)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch->ptflops==0.4) (1.17.3)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.4-cp36-none-any.whl size=7862 sha256=3c1336b31600d48dbfd47b4fb2efedee3613e1ae1326ea3c7cace7d59a885645\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f276_ger/wheels/00/ce/d1/169969eba40b2078b42c637bc9aac0f265e75a8a951b4e8570\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-d5hME36DI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from Utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aah51Bxf6OXU",
        "colab_type": "code",
        "outputId": "869e0d63-f858-45db-8eb7-b144339919e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Create SSD300 with pretrained weights in the base-architecture\n",
        "n_classes = 20\n",
        "model = SSD300(n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wG4WiSu6SBw",
        "colab_type": "code",
        "outputId": "d9bb6578-6275-4bcb-88e8-54d8b39e9949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "    model = SSD300(n_classes)\n",
        "    flops, params = get_model_complexity_info(model, (3,300,300))\n",
        "    print(f'Flops: {flops}')\n",
        "    print(f'Params: {params}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n",
            "SSD300(\n",
            "  31.409 GMac, 100.000% MACs, \n",
            "  (base): VGGBase_BN(\n",
            "    29.983 GMac, 95.461% MACs, \n",
            "    (conv1_1): Conv2d(0.161 GMac, 0.513% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_1_1): BatchNorm2d(0.012 GMac, 0.037% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv1_2): Conv2d(3.324 GMac, 10.581% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_1_2): BatchNorm2d(0.012 GMac, 0.037% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (pool1): MaxPool2d(0.006 GMac, 0.018% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv2_1): Conv2d(1.662 GMac, 5.291% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_2_1): BatchNorm2d(0.006 GMac, 0.018% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2_2): Conv2d(3.321 GMac, 10.572% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_2_2): BatchNorm2d(0.006 GMac, 0.018% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (pool2): MaxPool2d(0.003 GMac, 0.009% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv3_1): Conv2d(1.66 GMac, 5.286% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_3_1): BatchNorm2d(0.003 GMac, 0.009% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3_2): Conv2d(3.319 GMac, 10.568% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_3_2): BatchNorm2d(0.003 GMac, 0.009% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3_3): Conv2d(3.319 GMac, 10.568% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_3_3): BatchNorm2d(0.003 GMac, 0.009% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (pool3): MaxPool2d(0.001 GMac, 0.005% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (conv4_1): Conv2d(1.704 GMac, 5.426% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_4_1): BatchNorm2d(0.001 GMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4_2): Conv2d(3.408 GMac, 10.849% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_4_2): BatchNorm2d(0.001 GMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4_3): Conv2d(3.408 GMac, 10.849% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_4_3): BatchNorm2d(0.001 GMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (pool4): MaxPool2d(0.001 GMac, 0.002% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv5_1): Conv2d(0.852 GMac, 2.712% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_5_1): BatchNorm2d(0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv5_2): Conv2d(0.852 GMac, 2.712% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_5_2): BatchNorm2d(0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv5_3): Conv2d(0.852 GMac, 2.712% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn_5_3): BatchNorm2d(0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (pool5): MaxPool2d(0.0 GMac, 0.001% MACs, kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (conv6): Conv2d(1.704 GMac, 5.425% MACs, 512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "    (conv7): Conv2d(0.379 GMac, 1.206% MACs, 1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (aux_convs): AuxiliaryConvolutions(\n",
            "    0.231 GMac, 0.735% MACs, \n",
            "    (conv8_1): Conv2d(0.095 GMac, 0.302% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (conv8_2): Conv2d(0.118 GMac, 0.376% MACs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (conv9_1): Conv2d(0.007 GMac, 0.021% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (conv9_2): Conv2d(0.007 GMac, 0.023% MACs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (conv10_1): Conv2d(0.001 GMac, 0.003% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (conv10_2): Conv2d(0.003 GMac, 0.008% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (conv11_1): Conv2d(0.0 GMac, 0.001% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (conv11_2): Conv2d(0.0 GMac, 0.001% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "  )\n",
            "  (pred_convs): PredictionConvolutions(\n",
            "    1.195 GMac, 3.804% MACs, \n",
            "    (loc_conv4_3): Conv2d(0.106 GMac, 0.339% MACs, 512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (loc_conv7): Conv2d(0.08 GMac, 0.254% MACs, 1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (loc_conv8_2): Conv2d(0.011 GMac, 0.035% MACs, 512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (loc_conv9_2): Conv2d(0.001 GMac, 0.004% MACs, 256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (loc_conv10_2): Conv2d(0.0 GMac, 0.001% MACs, 256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (loc_conv11_2): Conv2d(0.0 GMac, 0.000% MACs, 256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (cl_conv4_3): Conv2d(0.532 GMac, 1.695% MACs, 512, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (cl_conv7): Conv2d(0.399 GMac, 1.271% MACs, 1024, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (cl_conv8_2): Conv2d(0.055 GMac, 0.176% MACs, 512, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (cl_conv9_2): Conv2d(0.007 GMac, 0.022% MACs, 256, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (cl_conv10_2): Conv2d(0.002 GMac, 0.005% MACs, 256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (cl_conv11_2): Conv2d(0.0 GMac, 0.001% MACs, 256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "Flops: 31.41 GMac\n",
            "Params: 26.16 M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2RMyz8L6qyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_model_complexity_info??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElRC_UyfwEOT",
        "colab_type": "text"
      },
      "source": [
        "# Trick #4\n",
        "Torchviz to visualize PyTorch execution graphs and traces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LZJ7O8F0gc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0aaa0939-5149-46df-e9a4-0bd5eef0b5f4"
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.3.1+cu100)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.17.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=0affc6da8f5f01332395a52be0b79c445c33958b783e4ccfcd50fedb29b878bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCT2cafk0ht1",
        "colab_type": "text"
      },
      "source": [
        "### Let's start with a basic example(base MLP model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhrQ0obV1ovZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchviz import make_dot, make_dot_from_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEQ44ppZ1w52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "3d5088a9-4826-4d80-cc45-c499fdc90702"
      },
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('W0', nn.Linear(8,16))\n",
        "model.add_module('tanh', nn.Tanh())\n",
        "model.add_module('W1', nn.Linear(16,1))\n",
        "\n",
        "inp = torch.randn(1,8)\n",
        "\n",
        "make_dot(model(inp), params = dict(model.named_parameters()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f00957d9630>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"266pt\" height=\"309pt\"\n viewBox=\"0.00 0.00 265.50 309.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 305)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-305 261.5,-305 261.5,4 -4,4\"/>\n<!-- 139640484763240 -->\n<g id=\"node1\" class=\"node\">\n<title>139640484763240</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"171,-21 67,-21 67,0 171,0 171,-21\"/>\n<text text-anchor=\"middle\" x=\"119\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640484762400 -->\n<g id=\"node2\" class=\"node\">\n<title>139640484762400</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"56,-91 0,-91 0,-57 56,-57 56,-91\"/>\n<text text-anchor=\"middle\" x=\"28\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W1.bias</text>\n<text text-anchor=\"middle\" x=\"28\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139640484762400&#45;&gt;139640484763240 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139640484762400&#45;&gt;139640484763240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M52.3863,-56.9832C65.6468,-47.73 81.9815,-36.3316 95.1567,-27.1379\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"97.4986,-29.7717 103.6965,-21.1788 93.4928,-24.0311 97.4986,-29.7717\"/>\n</g>\n<!-- 139640484763352 -->\n<g id=\"node3\" class=\"node\">\n<title>139640484763352</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-84.5 74.5,-84.5 74.5,-63.5 163.5,-63.5 163.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"119\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TanhBackward</text>\n</g>\n<!-- 139640484763352&#45;&gt;139640484763240 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139640484763352&#45;&gt;139640484763240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M119,-63.2281C119,-54.5091 119,-41.9699 119,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.5001,-31.1128 119,-21.1128 115.5001,-31.1129 122.5001,-31.1128\"/>\n</g>\n<!-- 139640484763520 -->\n<g id=\"node4\" class=\"node\">\n<title>139640484763520</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"169,-154.5 65,-154.5 65,-133.5 169,-133.5 169,-154.5\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640484763520&#45;&gt;139640484763352 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139640484763520&#45;&gt;139640484763352</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M117.3038,-133.3685C117.5945,-123.1925 118.0411,-107.5606 118.4031,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.9063,-94.8275 118.6934,-84.7315 114.9091,-94.6275 121.9063,-94.8275\"/>\n</g>\n<!-- 139640484763632 -->\n<g id=\"node5\" class=\"node\">\n<title>139640484763632</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"104,-231 48,-231 48,-197 104,-197 104,-231\"/>\n<text text-anchor=\"middle\" x=\"76\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W0.bias</text>\n<text text-anchor=\"middle\" x=\"76\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 139640484763632&#45;&gt;139640484763520 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139640484763632&#45;&gt;139640484763520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M86.1348,-196.6966C92.0172,-186.6535 99.4448,-173.9722 105.5395,-163.5667\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.6454,-165.189 110.6794,-154.7913 102.6052,-161.6512 108.6454,-165.189\"/>\n</g>\n<!-- 139640484763688 -->\n<g id=\"node6\" class=\"node\">\n<title>139640484763688</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"195.5,-224.5 122.5,-224.5 122.5,-203.5 195.5,-203.5 195.5,-224.5\"/>\n<text text-anchor=\"middle\" x=\"159\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640484763688&#45;&gt;139640484763520 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139640484763688&#45;&gt;139640484763520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M152.6211,-203.3685C146.2688,-192.7814 136.3731,-176.2886 128.6223,-163.3705\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.5852,-161.5057 123.4389,-154.7315 125.5827,-165.1072 131.5852,-161.5057\"/>\n</g>\n<!-- 139640484763800 -->\n<g id=\"node7\" class=\"node\">\n<title>139640484763800</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"193.5,-301 124.5,-301 124.5,-267 193.5,-267 193.5,-301\"/>\n<text text-anchor=\"middle\" x=\"159\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W0.weight</text>\n<text text-anchor=\"middle\" x=\"159\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 8)</text>\n</g>\n<!-- 139640484763800&#45;&gt;139640484763688 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139640484763800&#45;&gt;139640484763688</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159,-266.6966C159,-257.0634 159,-245.003 159,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.5001,-234.7912 159,-224.7913 155.5001,-234.7913 162.5001,-234.7912\"/>\n</g>\n<!-- 139640484763408 -->\n<g id=\"node8\" class=\"node\">\n<title>139640484763408</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"257.5,-84.5 184.5,-84.5 184.5,-63.5 257.5,-63.5 257.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640484763408&#45;&gt;139640484763240 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139640484763408&#45;&gt;139640484763240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M203.6971,-63.2281C187.4805,-53.1325 163.0365,-37.9149 144.5702,-26.4187\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"146.3865,-23.4266 136.0474,-21.1128 142.6869,-29.3692 146.3865,-23.4266\"/>\n</g>\n<!-- 139640484763576 -->\n<g id=\"node9\" class=\"node\">\n<title>139640484763576</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"256.5,-161 187.5,-161 187.5,-127 256.5,-127 256.5,-161\"/>\n<text text-anchor=\"middle\" x=\"222\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">W1.weight</text>\n<text text-anchor=\"middle\" x=\"222\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 16)</text>\n</g>\n<!-- 139640484763576&#45;&gt;139640484763408 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139640484763576&#45;&gt;139640484763408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.7528,-126.6966C221.6152,-117.0634 221.4429,-105.003 221.2979,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"224.7967,-94.7402 221.1542,-84.7913 217.7975,-94.8403 224.7967,-94.7402\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P22juagj2XOP",
        "colab_type": "text"
      },
      "source": [
        "The method is built for directed graphs of PyTorch operations, built during **forward** propagation and showing which operations will be called on **backward**. <br>\n",
        "It omits subgraphs which do not require gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrGtgTXg3CP1",
        "colab_type": "text"
      },
      "source": [
        "### Visualiza AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGh60Zs3t7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models import AlexNet\n",
        "\n",
        "model = AlexNet()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhMRGffO3zo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c13229bb-5362-4762-8a2c-a50fbba24479"
      },
      "source": [
        "x = torch.randn(1,3,227,227).requires_grad_(True)\n",
        "y = model(x)\n",
        "make_dot(y, params = dict(list(model.named_parameters()) + [('x',x)]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f008c7eda90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"562pt\" height=\"896pt\"\n viewBox=\"0.00 0.00 562.36 896.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.6283 .6283) rotate(0) translate(4 1422)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1422 891,-1422 891,4 -4,4\"/>\n<!-- 139640333723520 -->\n<g id=\"node1\" class=\"node\">\n<title>139640333723520</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"772.5,-21 668.5,-21 668.5,0 772.5,0 772.5,-21\"/>\n<text text-anchor=\"middle\" x=\"720.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640333723744 -->\n<g id=\"node2\" class=\"node\">\n<title>139640333723744</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"655.5,-91 567.5,-91 567.5,-57 655.5,-57 655.5,-91\"/>\n<text text-anchor=\"middle\" x=\"611.5\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.6.bias</text>\n<text text-anchor=\"middle\" x=\"611.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1000)</text>\n</g>\n<!-- 139640333723744&#45;&gt;139640333723520 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139640333723744&#45;&gt;139640333723520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M640.71,-56.9832C657.0516,-47.4631 677.2911,-35.6722 693.2964,-26.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"695.2906,-29.2369 702.1694,-21.1788 691.7669,-23.1884 695.2906,-29.2369\"/>\n</g>\n<!-- 139640333725480 -->\n<g id=\"node3\" class=\"node\">\n<title>139640333725480</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"767.5,-84.5 673.5,-84.5 673.5,-63.5 767.5,-63.5 767.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"720.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333725480&#45;&gt;139640333723520 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139640333725480&#45;&gt;139640333723520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M720.5,-63.2281C720.5,-54.5091 720.5,-41.9699 720.5,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"724.0001,-31.1128 720.5,-21.1128 717.0001,-31.1129 724.0001,-31.1128\"/>\n</g>\n<!-- 139640333722288 -->\n<g id=\"node4\" class=\"node\">\n<title>139640333722288</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"767.5,-154.5 663.5,-154.5 663.5,-133.5 767.5,-133.5 767.5,-154.5\"/>\n<text text-anchor=\"middle\" x=\"715.5\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640333722288&#45;&gt;139640333725480 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139640333722288&#45;&gt;139640333725480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M716.2594,-133.3685C716.9862,-123.1925 718.1028,-107.5606 719.0078,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"722.512,-94.9555 719.7335,-84.7315 715.5298,-94.4567 722.512,-94.9555\"/>\n</g>\n<!-- 139640333722008 -->\n<g id=\"node5\" class=\"node\">\n<title>139640333722008</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"651.5,-231 563.5,-231 563.5,-197 651.5,-197 651.5,-231\"/>\n<text text-anchor=\"middle\" x=\"607.5\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.4.bias</text>\n<text text-anchor=\"middle\" x=\"607.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096)</text>\n</g>\n<!-- 139640333722008&#45;&gt;139640333722288 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139640333722008&#45;&gt;139640333722288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M633.9198,-196.8761C651.0968,-185.7428 673.3632,-171.3109 690.2931,-160.3378\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"692.5955,-163.0165 699.0834,-154.6404 688.7882,-157.1424 692.5955,-163.0165\"/>\n</g>\n<!-- 139640333725536 -->\n<g id=\"node6\" class=\"node\">\n<title>139640333725536</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"761,-224.5 670,-224.5 670,-203.5 761,-203.5 761,-224.5\"/>\n<text text-anchor=\"middle\" x=\"715.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139640333725536&#45;&gt;139640333722288 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139640333725536&#45;&gt;139640333722288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M715.5,-203.3685C715.5,-193.1925 715.5,-177.5606 715.5,-164.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"719.0001,-164.7315 715.5,-154.7315 712.0001,-164.7316 719.0001,-164.7315\"/>\n</g>\n<!-- 139640333721728 -->\n<g id=\"node7\" class=\"node\">\n<title>139640333721728</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"758.5,-294.5 664.5,-294.5 664.5,-273.5 758.5,-273.5 758.5,-294.5\"/>\n<text text-anchor=\"middle\" x=\"711.5\" y=\"-280.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333721728&#45;&gt;139640333725536 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139640333721728&#45;&gt;139640333725536</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M712.1075,-273.3685C712.689,-263.1925 713.5822,-247.5606 714.3062,-234.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"717.8105,-234.915 714.8868,-224.7315 710.8219,-234.5156 717.8105,-234.915\"/>\n</g>\n<!-- 139640333723240 -->\n<g id=\"node8\" class=\"node\">\n<title>139640333723240</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"763.5,-358 659.5,-358 659.5,-337 763.5,-337 763.5,-358\"/>\n<text text-anchor=\"middle\" x=\"711.5\" y=\"-344.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139640333723240&#45;&gt;139640333721728 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139640333723240&#45;&gt;139640333721728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.5,-336.7281C711.5,-328.0091 711.5,-315.4699 711.5,-304.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"715.0001,-304.6128 711.5,-294.6128 708.0001,-304.6129 715.0001,-304.6128\"/>\n</g>\n<!-- 139640333722680 -->\n<g id=\"node9\" class=\"node\">\n<title>139640333722680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"647.5,-428 559.5,-428 559.5,-394 647.5,-394 647.5,-428\"/>\n<text text-anchor=\"middle\" x=\"603.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.1.bias</text>\n<text text-anchor=\"middle\" x=\"603.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096)</text>\n</g>\n<!-- 139640333722680&#45;&gt;139640333723240 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139640333722680&#45;&gt;139640333723240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M632.442,-393.9832C648.6337,-384.4631 668.6875,-372.6722 684.546,-363.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"686.4912,-366.2645 693.3376,-358.1788 682.9432,-360.2302 686.4912,-366.2645\"/>\n</g>\n<!-- 139640333724808 -->\n<g id=\"node10\" class=\"node\">\n<title>139640333724808</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"757,-421.5 666,-421.5 666,-400.5 757,-400.5 757,-421.5\"/>\n<text text-anchor=\"middle\" x=\"711.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139640333724808&#45;&gt;139640333723240 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139640333724808&#45;&gt;139640333723240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.5,-400.2281C711.5,-391.5091 711.5,-378.9699 711.5,-368.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"715.0001,-368.1128 711.5,-358.1128 708.0001,-368.1129 715.0001,-368.1128\"/>\n</g>\n<!-- 139640333724192 -->\n<g id=\"node11\" class=\"node\">\n<title>139640333724192</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"762,-491.5 649,-491.5 649,-470.5 762,-470.5 762,-491.5\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-477.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n</g>\n<!-- 139640333724192&#45;&gt;139640333724808 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139640333724192&#45;&gt;139640333724808</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M706.4113,-470.3685C707.2835,-460.1925 708.6234,-444.5606 709.7093,-431.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"713.2133,-431.9939 710.5802,-421.7315 706.2388,-431.3961 713.2133,-431.9939\"/>\n</g>\n<!-- 139640333722848 -->\n<g id=\"node12\" class=\"node\">\n<title>139640333722848</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"788.5,-555 622.5,-555 622.5,-534 788.5,-534 788.5,-555\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AdaptiveAvgPool2DBackward</text>\n</g>\n<!-- 139640333722848&#45;&gt;139640333724192 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139640333722848&#45;&gt;139640333724192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-533.7281C705.5,-525.0091 705.5,-512.4699 705.5,-501.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-501.6128 705.5,-491.6128 702.0001,-501.6129 709.0001,-501.6128\"/>\n</g>\n<!-- 139640333440112 -->\n<g id=\"node13\" class=\"node\">\n<title>139640333440112</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"795.5,-612 615.5,-612 615.5,-591 795.5,-591 795.5,-612\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-598.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139640333440112&#45;&gt;139640333722848 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139640333440112&#45;&gt;139640333722848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-590.7787C705.5,-583.6134 705.5,-573.9517 705.5,-565.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-565.1732 705.5,-555.1732 702.0001,-565.1732 709.0001,-565.1732\"/>\n</g>\n<!-- 139640333440784 -->\n<g id=\"node14\" class=\"node\">\n<title>139640333440784</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"752.5,-669 658.5,-669 658.5,-648 752.5,-648 752.5,-669\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-655.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333440784&#45;&gt;139640333440112 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139640333440784&#45;&gt;139640333440112</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-647.7787C705.5,-640.6134 705.5,-630.9517 705.5,-622.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-622.1732 705.5,-612.1732 702.0001,-622.1732 709.0001,-622.1732\"/>\n</g>\n<!-- 139640333441960 -->\n<g id=\"node15\" class=\"node\">\n<title>139640333441960</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"786.5,-726 624.5,-726 624.5,-705 786.5,-705 786.5,-726\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-712.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333441960&#45;&gt;139640333440784 -->\n<g id=\"edge14\" class=\"edge\">\n<title>139640333441960&#45;&gt;139640333440784</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-704.7787C705.5,-697.6134 705.5,-687.9517 705.5,-679.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-679.1732 705.5,-669.1732 702.0001,-679.1732 709.0001,-679.1732\"/>\n</g>\n<!-- 139640333442968 -->\n<g id=\"node16\" class=\"node\">\n<title>139640333442968</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"635.5,-789.5 541.5,-789.5 541.5,-768.5 635.5,-768.5 635.5,-789.5\"/>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-775.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333442968&#45;&gt;139640333441960 -->\n<g id=\"edge15\" class=\"edge\">\n<title>139640333442968&#45;&gt;139640333441960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M608.0832,-768.3715C626.8966,-758.1608 655.5379,-742.6162 676.902,-731.0212\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"678.7335,-734.0094 685.8529,-726.1631 675.3944,-727.8571 678.7335,-734.0094\"/>\n</g>\n<!-- 139640333441512 -->\n<g id=\"node17\" class=\"node\">\n<title>139640333441512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"669.5,-853 507.5,-853 507.5,-832 669.5,-832 669.5,-853\"/>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-839.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333441512&#45;&gt;139640333442968 -->\n<g id=\"edge16\" class=\"edge\">\n<title>139640333441512&#45;&gt;139640333442968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M588.5,-831.7281C588.5,-823.0091 588.5,-810.4699 588.5,-799.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"592.0001,-799.6128 588.5,-789.6128 585.0001,-799.6129 592.0001,-799.6128\"/>\n</g>\n<!-- 139640333442408 -->\n<g id=\"node18\" class=\"node\">\n<title>139640333442408</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"521.5,-916.5 427.5,-916.5 427.5,-895.5 521.5,-895.5 521.5,-916.5\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-902.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333442408&#45;&gt;139640333441512 -->\n<g id=\"edge17\" class=\"edge\">\n<title>139640333442408&#45;&gt;139640333441512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M493.581,-895.3715C511.8299,-885.2066 539.5689,-869.7555 560.3548,-858.1774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"562.3237,-861.087 569.3567,-853.1631 558.9174,-854.9717 562.3237,-861.087\"/>\n</g>\n<!-- 139640333440560 -->\n<g id=\"node19\" class=\"node\">\n<title>139640333440560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"555.5,-980 393.5,-980 393.5,-959 555.5,-959 555.5,-980\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-966.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333440560&#45;&gt;139640333442408 -->\n<g id=\"edge18\" class=\"edge\">\n<title>139640333440560&#45;&gt;139640333442408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M474.5,-958.7281C474.5,-950.0091 474.5,-937.4699 474.5,-926.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.0001,-926.6128 474.5,-916.6128 471.0001,-926.6129 478.0001,-926.6128\"/>\n</g>\n<!-- 139640333440224 -->\n<g id=\"node20\" class=\"node\">\n<title>139640333440224</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"407.5,-1043.5 227.5,-1043.5 227.5,-1022.5 407.5,-1022.5 407.5,-1043.5\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1029.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139640333440224&#45;&gt;139640333440560 -->\n<g id=\"edge19\" class=\"edge\">\n<title>139640333440224&#45;&gt;139640333440560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M343.7783,-1022.3715C369.8946,-1011.8086 410.1242,-995.5374 439.0559,-983.8357\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.4396,-987.0515 448.3977,-980.0573 437.8149,-980.5622 440.4396,-987.0515\"/>\n</g>\n<!-- 139640333440448 -->\n<g id=\"node21\" class=\"node\">\n<title>139640333440448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"364.5,-1107 270.5,-1107 270.5,-1086 364.5,-1086 364.5,-1107\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1093.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333440448&#45;&gt;139640333440224 -->\n<g id=\"edge20\" class=\"edge\">\n<title>139640333440448&#45;&gt;139640333440224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-1085.7281C317.5,-1077.0091 317.5,-1064.4699 317.5,-1053.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-1053.6128 317.5,-1043.6128 314.0001,-1053.6129 321.0001,-1053.6128\"/>\n</g>\n<!-- 139640333442240 -->\n<g id=\"node22\" class=\"node\">\n<title>139640333442240</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"398.5,-1164 236.5,-1164 236.5,-1143 398.5,-1143 398.5,-1164\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1150.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333442240&#45;&gt;139640333440448 -->\n<g id=\"edge21\" class=\"edge\">\n<title>139640333442240&#45;&gt;139640333440448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-1142.7787C317.5,-1135.6134 317.5,-1125.9517 317.5,-1117.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-1117.1732 317.5,-1107.1732 314.0001,-1117.1732 321.0001,-1117.1732\"/>\n</g>\n<!-- 139640333442856 -->\n<g id=\"node23\" class=\"node\">\n<title>139640333442856</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"250.5,-1227.5 70.5,-1227.5 70.5,-1206.5 250.5,-1206.5 250.5,-1227.5\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1213.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139640333442856&#45;&gt;139640333442240 -->\n<g id=\"edge22\" class=\"edge\">\n<title>139640333442856&#45;&gt;139640333442240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M186.7783,-1206.3715C212.8946,-1195.8086 253.1242,-1179.5374 282.0559,-1167.8357\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.4396,-1171.0515 291.3977,-1164.0573 280.8149,-1164.5622 283.4396,-1171.0515\"/>\n</g>\n<!-- 139640333439776 -->\n<g id=\"node24\" class=\"node\">\n<title>139640333439776</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"207.5,-1291 113.5,-1291 113.5,-1270 207.5,-1270 207.5,-1291\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1277.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n</g>\n<!-- 139640333439776&#45;&gt;139640333442856 -->\n<g id=\"edge23\" class=\"edge\">\n<title>139640333439776&#45;&gt;139640333442856</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.5,-1269.7281C160.5,-1261.0091 160.5,-1248.4699 160.5,-1237.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.0001,-1237.6128 160.5,-1227.6128 157.0001,-1237.6129 164.0001,-1237.6128\"/>\n</g>\n<!-- 139640333440840 -->\n<g id=\"node25\" class=\"node\">\n<title>139640333440840</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"241.5,-1348 79.5,-1348 79.5,-1327 241.5,-1327 241.5,-1348\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1334.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139640333440840&#45;&gt;139640333439776 -->\n<g id=\"edge24\" class=\"edge\">\n<title>139640333440840&#45;&gt;139640333439776</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.5,-1326.7787C160.5,-1319.6134 160.5,-1309.9517 160.5,-1301.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.0001,-1301.1732 160.5,-1291.1732 157.0001,-1301.1732 164.0001,-1301.1732\"/>\n</g>\n<!-- 139640333440896 -->\n<g id=\"node26\" class=\"node\">\n<title>139640333440896</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"93,-1418 0,-1418 0,-1384 93,-1384 93,-1418\"/>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-1404.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">x</text>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-1391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 3, 227, 227)</text>\n</g>\n<!-- 139640333440896&#45;&gt;139640333440840 -->\n<g id=\"edge25\" class=\"edge\">\n<title>139640333440896&#45;&gt;139640333440840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.0499,-1383.9832C94.3009,-1374.3741 115.705,-1362.4516 132.5167,-1353.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.2956,-1356.1027 141.3286,-1348.1788 130.8892,-1349.9874 134.2956,-1356.1027\"/>\n</g>\n<!-- 139640333439944 -->\n<g id=\"node27\" class=\"node\">\n<title>139640333439944</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"209.5,-1418 111.5,-1418 111.5,-1384 209.5,-1384 209.5,-1418\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1404.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.0.weight</text>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-1391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 3, 11, 11)</text>\n</g>\n<!-- 139640333439944&#45;&gt;139640333440840 -->\n<g id=\"edge26\" class=\"edge\">\n<title>139640333439944&#45;&gt;139640333440840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.5,-1383.9832C160.5,-1376.1157 160.5,-1366.6973 160.5,-1358.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.0001,-1358.3686 160.5,-1348.3687 157.0001,-1358.3687 164.0001,-1358.3686\"/>\n</g>\n<!-- 139640333441232 -->\n<g id=\"node28\" class=\"node\">\n<title>139640333441232</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"311.5,-1418 227.5,-1418 227.5,-1384 311.5,-1384 311.5,-1418\"/>\n<text text-anchor=\"middle\" x=\"269.5\" y=\"-1404.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.0.bias</text>\n<text text-anchor=\"middle\" x=\"269.5\" y=\"-1391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 139640333441232&#45;&gt;139640333440840 -->\n<g id=\"edge27\" class=\"edge\">\n<title>139640333441232&#45;&gt;139640333440840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.29,-1383.9832C223.9484,-1374.4631 203.7089,-1362.6722 187.7036,-1353.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.2331,-1350.1884 178.8306,-1348.1788 185.7094,-1356.2369 189.2331,-1350.1884\"/>\n</g>\n<!-- 139640333443024 -->\n<g id=\"node29\" class=\"node\">\n<title>139640333443024</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"366.5,-1234 268.5,-1234 268.5,-1200 366.5,-1200 366.5,-1234\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1220.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.3.weight</text>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-1207.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (192, 64, 5, 5)</text>\n</g>\n<!-- 139640333443024&#45;&gt;139640333442240 -->\n<g id=\"edge28\" class=\"edge\">\n<title>139640333443024&#45;&gt;139640333442240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-1199.9832C317.5,-1192.1157 317.5,-1182.6973 317.5,-1174.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-1174.3686 317.5,-1164.3687 314.0001,-1174.3687 321.0001,-1174.3686\"/>\n</g>\n<!-- 139640333441456 -->\n<g id=\"node30\" class=\"node\">\n<title>139640333441456</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"468.5,-1234 384.5,-1234 384.5,-1200 468.5,-1200 468.5,-1234\"/>\n<text text-anchor=\"middle\" x=\"426.5\" y=\"-1220.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.3.bias</text>\n<text text-anchor=\"middle\" x=\"426.5\" y=\"-1207.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (192)</text>\n</g>\n<!-- 139640333441456&#45;&gt;139640333442240 -->\n<g id=\"edge29\" class=\"edge\">\n<title>139640333441456&#45;&gt;139640333442240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M397.29,-1199.9832C380.9484,-1190.4631 360.7089,-1178.6722 344.7036,-1169.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"346.2331,-1166.1884 335.8306,-1164.1788 342.7094,-1172.2369 346.2331,-1166.1884\"/>\n</g>\n<!-- 139640333442352 -->\n<g id=\"node31\" class=\"node\">\n<title>139640333442352</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"523.5,-1050 425.5,-1050 425.5,-1016 523.5,-1016 523.5,-1050\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-1036.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.6.weight</text>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-1023.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (384, 192, 3, 3)</text>\n</g>\n<!-- 139640333442352&#45;&gt;139640333440560 -->\n<g id=\"edge30\" class=\"edge\">\n<title>139640333442352&#45;&gt;139640333440560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M474.5,-1015.9832C474.5,-1008.1157 474.5,-998.6973 474.5,-990.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.0001,-990.3686 474.5,-980.3687 471.0001,-990.3687 478.0001,-990.3686\"/>\n</g>\n<!-- 139640333441792 -->\n<g id=\"node32\" class=\"node\">\n<title>139640333441792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"625.5,-1050 541.5,-1050 541.5,-1016 625.5,-1016 625.5,-1050\"/>\n<text text-anchor=\"middle\" x=\"583.5\" y=\"-1036.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.6.bias</text>\n<text text-anchor=\"middle\" x=\"583.5\" y=\"-1023.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (384)</text>\n</g>\n<!-- 139640333441792&#45;&gt;139640333440560 -->\n<g id=\"edge31\" class=\"edge\">\n<title>139640333441792&#45;&gt;139640333440560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M554.29,-1015.9832C537.9484,-1006.4631 517.7089,-994.6722 501.7036,-985.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"503.2331,-982.1884 492.8306,-980.1788 499.7094,-988.2369 503.2331,-982.1884\"/>\n</g>\n<!-- 139640333441176 -->\n<g id=\"node33\" class=\"node\">\n<title>139640333441176</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"637.5,-923 539.5,-923 539.5,-889 637.5,-889 637.5,-923\"/>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-909.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.8.weight</text>\n<text text-anchor=\"middle\" x=\"588.5\" y=\"-896.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 384, 3, 3)</text>\n</g>\n<!-- 139640333441176&#45;&gt;139640333441512 -->\n<g id=\"edge32\" class=\"edge\">\n<title>139640333441176&#45;&gt;139640333441512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M588.5,-888.9832C588.5,-881.1157 588.5,-871.6973 588.5,-863.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"592.0001,-863.3686 588.5,-853.3687 585.0001,-863.3687 592.0001,-863.3686\"/>\n</g>\n<!-- 139640333441680 -->\n<g id=\"node34\" class=\"node\">\n<title>139640333441680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"739.5,-923 655.5,-923 655.5,-889 739.5,-889 739.5,-923\"/>\n<text text-anchor=\"middle\" x=\"697.5\" y=\"-909.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.8.bias</text>\n<text text-anchor=\"middle\" x=\"697.5\" y=\"-896.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 139640333441680&#45;&gt;139640333441512 -->\n<g id=\"edge33\" class=\"edge\">\n<title>139640333441680&#45;&gt;139640333441512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M668.29,-888.9832C651.9484,-879.4631 631.7089,-867.6722 615.7036,-858.3479\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.2331,-855.1884 606.8306,-853.1788 613.7094,-861.2369 617.2331,-855.1884\"/>\n</g>\n<!-- 139640333442576 -->\n<g id=\"node35\" class=\"node\">\n<title>139640333442576</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"757.5,-796 653.5,-796 653.5,-762 757.5,-762 757.5,-796\"/>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-782.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.10.weight</text>\n<text text-anchor=\"middle\" x=\"705.5\" y=\"-769.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 256, 3, 3)</text>\n</g>\n<!-- 139640333442576&#45;&gt;139640333441960 -->\n<g id=\"edge34\" class=\"edge\">\n<title>139640333442576&#45;&gt;139640333441960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M705.5,-761.9832C705.5,-754.1157 705.5,-744.6973 705.5,-736.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.0001,-736.3686 705.5,-726.3687 702.0001,-736.3687 709.0001,-736.3686\"/>\n</g>\n<!-- 139640333441568 -->\n<g id=\"node36\" class=\"node\">\n<title>139640333441568</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"865.5,-796 775.5,-796 775.5,-762 865.5,-762 865.5,-796\"/>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-782.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">features.10.bias</text>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-769.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 139640333441568&#45;&gt;139640333441960 -->\n<g id=\"edge35\" class=\"edge\">\n<title>139640333441568&#45;&gt;139640333441960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M789.6821,-761.9832C772.2798,-752.3741 750.6879,-740.4516 733.7287,-731.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"735.2856,-727.9487 724.8396,-726.1788 731.9019,-734.0766 735.2856,-727.9487\"/>\n</g>\n<!-- 139640333723576 -->\n<g id=\"node37\" class=\"node\">\n<title>139640333723576</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"860,-421.5 787,-421.5 787,-400.5 860,-400.5 860,-421.5\"/>\n<text text-anchor=\"middle\" x=\"823.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640333723576&#45;&gt;139640333723240 -->\n<g id=\"edge36\" class=\"edge\">\n<title>139640333723576&#45;&gt;139640333723240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M804.7537,-400.3715C786.825,-390.2066 759.5727,-374.7555 739.1514,-363.1774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"740.7328,-360.0506 730.3074,-358.1631 737.2803,-366.14 740.7328,-360.0506\"/>\n</g>\n<!-- 139640333724416 -->\n<g id=\"node38\" class=\"node\">\n<title>139640333724416</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"881,-498 780,-498 780,-464 881,-464 881,-498\"/>\n<text text-anchor=\"middle\" x=\"830.5\" y=\"-484.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.1.weight</text>\n<text text-anchor=\"middle\" x=\"830.5\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096, 9216)</text>\n</g>\n<!-- 139640333724416&#45;&gt;139640333723576 -->\n<g id=\"edge37\" class=\"edge\">\n<title>139640333724416&#45;&gt;139640333723576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M828.7697,-463.6966C827.8063,-454.0634 826.6003,-442.003 825.5852,-431.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"829.0569,-431.3933 824.5791,-421.7913 822.0916,-432.0899 829.0569,-431.3933\"/>\n</g>\n<!-- 139640333722792 -->\n<g id=\"node39\" class=\"node\">\n<title>139640333722792</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"860,-224.5 787,-224.5 787,-203.5 860,-203.5 860,-224.5\"/>\n<text text-anchor=\"middle\" x=\"823.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640333722792&#45;&gt;139640333722288 -->\n<g id=\"edge38\" class=\"edge\">\n<title>139640333722792&#45;&gt;139640333722288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M807.0971,-203.3685C789.3119,-191.841 760.7246,-173.3123 740.2161,-160.0197\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"741.9986,-157.0041 731.7034,-154.5022 738.1913,-162.8782 741.9986,-157.0041\"/>\n</g>\n<!-- 139640333725144 -->\n<g id=\"node40\" class=\"node\">\n<title>139640333725144</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"878,-301 777,-301 777,-267 878,-267 878,-301\"/>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.4.weight</text>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4096, 4096)</text>\n</g>\n<!-- 139640333725144&#45;&gt;139640333722792 -->\n<g id=\"edge39\" class=\"edge\">\n<title>139640333725144&#45;&gt;139640333722792</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M826.5112,-266.6966C825.9608,-257.0634 825.2716,-245.003 824.6915,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"828.1815,-234.5753 824.1166,-224.7913 821.1929,-234.9747 828.1815,-234.5753\"/>\n</g>\n<!-- 139640333722512 -->\n<g id=\"node41\" class=\"node\">\n<title>139640333722512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"868,-84.5 795,-84.5 795,-63.5 868,-63.5 868,-84.5\"/>\n<text text-anchor=\"middle\" x=\"831.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139640333722512&#45;&gt;139640333723520 -->\n<g id=\"edge40\" class=\"edge\">\n<title>139640333722512&#45;&gt;139640333723520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M812.9211,-63.3715C795.1525,-53.2066 768.1434,-37.7555 747.9046,-26.1774\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"749.5575,-23.0908 739.1395,-21.1631 746.0816,-29.1668 749.5575,-23.0908\"/>\n</g>\n<!-- 139640333724024 -->\n<g id=\"node42\" class=\"node\">\n<title>139640333724024</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"887,-161 786,-161 786,-127 887,-127 887,-161\"/>\n<text text-anchor=\"middle\" x=\"836.5\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">classifier.6.weight</text>\n<text text-anchor=\"middle\" x=\"836.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1000, 4096)</text>\n</g>\n<!-- 139640333724024&#45;&gt;139640333722512 -->\n<g id=\"edge41\" class=\"edge\">\n<title>139640333724024&#45;&gt;139640333722512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M835.264,-126.6966C834.576,-117.0634 833.7145,-105.003 832.9894,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"836.4745,-94.5165 832.2708,-84.7913 829.4923,-95.0153 836.4745,-94.5165\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm-T7L-b0iEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fb4a4506-94ef-4268-902c-d2bc1652aae2"
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from Utils import *\n",
        "\n",
        "# Create SSD300 with pretrained weights in the base-architecture\n",
        "n_classes = 20\n",
        "model = SSD300(n_classes)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded base model with pre-trained weights\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJBrmUrg0iUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(1,3,300,300)\n",
        "y = model(x)\n",
        "dot = make_dot(y, params = dict(list(model.named_parameters())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDXQGEYD5exK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "508e3499-290e-4738-9710-0bbc6edf0658"
      },
      "source": [
        "dot.render('VGG300_BN.gv', view=True)  "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'VGG300_BN.gv.pdf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0teUrcv7KGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "491bca3a-587e-46d1-89db-7ffb7cd717ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gabOHy7FZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DerHv4qw5gcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCwrRaRyUNG",
        "colab_type": "text"
      },
      "source": [
        "# Trick #5\n",
        "[Awesome PyTorch list](https://github.com/bharathgs/Awesome-pytorch-list)\n",
        "This is a truly awesome repo full of practical tutorials that implements various state-of-the-art deep learning techniques using PyTorch including:\n",
        "1. NLP & Speech Processing\n",
        "2. Computer Vision\n",
        "3. Probabilistic/Generative Libraries\n",
        "4. Other libraries\n",
        "5. Paper implementations<br>\n",
        "\n",
        "Basically a good place to look into when starting a new project to check for relevant realization techniques.<br>\n",
        "Since deep learning is such a fast developing fielding, if it weren't for the reason that this repo stoped getting updated 2 years ago, it should be #1 on this list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o77f6yEAzv0b"
      },
      "source": [
        "# Trick #6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B1wXhJpVzwFn"
      },
      "source": [
        "# Trick #7\n",
        "**AdaBound optimizer**<br>\n",
        "Finally, AdaBound is available in PyTorch. One of the most powerful optimizer that out performs Adam in some cases with super fast convergence rate. Definely, something you would want to try out when fast prototyping.<br>\n",
        "The method is based on [Adaptive Gradient Methods with Dynamic Bound of Learning Rate](https://openreview.net/forum?id=Bkg3g2R9FX).In Proc. of ICLR 2019."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDzlQWrgBod4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## implementation\n",
        "optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOIUgigYBbw3",
        "colab_type": "text"
      },
      "source": [
        "As described in the paper, AdaBound is an optimizer that behavces like **Adam** at the beginning of the training, and gradually transforms to SGD at the end.  In this way, it can **combines the benefits of adaptive methods, viz. fast initial process, and the good final generalization properties of SGD.** <br>\n",
        "The `final_lr` parameter indicates **Adabound** would transforms to an SGD with this learninig rate. In common cases, a default final learning rate of `0.1` can achieve relatively good and statble results on *unseen data*.<br>\n",
        "This method is not very sensitive to it's hyperparameters. *See Appendix G of the paper for more details*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWOrq3XtCP4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5QgaUjHXzwPE"
      },
      "source": [
        "# Trick #8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8iUk8aILzwSZ"
      },
      "source": [
        "# Trick #9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SnlJ9ELgzwVP"
      },
      "source": [
        "# Trick #10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYI6oXV2zwX5"
      },
      "source": [
        "# Trick #11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JUn7Wei7zwbp"
      },
      "source": [
        "# Trick #12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYu-p8NMz42w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}