{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced_usage_for_PyTorch",
      "provenance": [],
      "collapsed_sections": [
        "o53MyOvZTmmg",
        "ki0QJM1rgmXm",
        "cDpZgdBwwl4H",
        "P-CayC2IzJ-8",
        "pgEcIGc71HEK",
        "8QmwwVrtlYrC",
        "9vjEG4EY1Xf6",
        "b1LmMwZ14WMW",
        "ySQiNr5OyCIY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sylar257/My-data-science-tool-kit/blob/master/Advanced_usage_for_PyTorch(torch%20hook%20included).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZtbRaQqSu1Z",
        "colab_type": "text"
      },
      "source": [
        "# Objective\n",
        "1. Difference between PyTorch classes like `nn.Module`, `nn.Functional`\n",
        "2. How to customize training options such as `lr` for different layers, *weight initialization*\n",
        "3. **Tensorboard** with PyTorch\n",
        "4. How to visualiza the computation graph and print it's intermediate values for **debugging**\n",
        "5. PyTorch **Hooks** for debugging and monitoring training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o53MyOvZTmmg",
        "colab_type": "text"
      },
      "source": [
        "## `nn.Module` vs `nn.Functional`\n",
        "\n",
        "PyTorch layers are normally implemented with either `torch.nn.Module` objects or `torch.nn.Functional` functions.<br>\n",
        "___\n",
        "With `torch.nn.Module` we define layers in `__init__` and then invoke them in `forward` method. This is a *Object Oriented* way to do things.<br>\n",
        "On the other hand, `nn.functional` provides some **layers/activations** in form of *functions* that can be directly called on the input rather than defining as an object. E.g., in order to rescale an image tensor, we can call `torch.nn.functional.interpolate` on an image tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikMAT_niVAUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3bs2c19VV6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simulate an input of batch_size = 1, n_channels = 3, 64x64 image\n",
        "inp = torch.randn(1,3,64,64) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quAS0LfbVcF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn layers\n",
        "avg_pool = nn.AvgPool2d(kernel_size=4)\n",
        "nn_out = avg_pool(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U3HPlGTVdcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn.Functional functions\n",
        "f_out  = F.avg_pool2d(inp,kernel_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAopzqq_WYxy",
        "colab_type": "code",
        "outputId": "ad66846b-9f05-4f08-96bd-a696b97d993d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check is the two are the same\n",
        "print(torch.equal(nn_out, f_out))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFd-X2qXWui8",
        "colab_type": "text"
      },
      "source": [
        "### Stateful-ness in PyTorch\n",
        "As the result of the two method are actually the same, the difference lies in their *statefulness*.<br>\n",
        "In most cases, layers can be viewed as a function in PyTorch where we feed in an input and it spits out an output.In the mean time, layers holds **weights** and **biases** that need to be stored and updated while we are training. Therefore, programmatically, layers are more than just functions but hold these *states* that will be altered during our training.<br>\n",
        "Hence, for layers that needs to hold certain **weights & biases** or any **states** we create a class for them with `torch.nn.Module`. **Batch Norm layers** and **dropout layers** behahves differently during training and inferernce which is also benificial to have them under `torch.nn.Module`.<br>\n",
        "On the other hand, `torch.nn.functional` have the layers that bear no weights and no state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuGR2A1IYmsL",
        "colab_type": "text"
      },
      "source": [
        "### nn.Parameter\n",
        "PyTorch has a `nn.Parameter` class, which will be automatically created with and `nn.Module`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XlB52UhYvnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10,5)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6n64PwqZNL8",
        "colab_type": "code",
        "outputId": "505607d7-6bcb-46c7-b28f-fdf2373bde21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "myNet = net()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.1716, -0.1476, -0.2967, -0.1605,  0.1744,  0.0588, -0.0607, -0.0973,\n",
            "          0.0017,  0.2567],\n",
            "        [-0.1697,  0.1477,  0.1557,  0.2791,  0.0775,  0.0166, -0.3029,  0.2463,\n",
            "          0.0950,  0.0751],\n",
            "        [ 0.1641,  0.0460, -0.1584, -0.1920,  0.1690, -0.1267, -0.2761, -0.0781,\n",
            "          0.2130,  0.0741],\n",
            "        [-0.1212,  0.0420, -0.1198, -0.0004, -0.2889, -0.0960, -0.0641,  0.1144,\n",
            "         -0.2615,  0.0941],\n",
            "        [ 0.1211,  0.1952, -0.1380, -0.2176, -0.2004, -0.0063,  0.0482,  0.1178,\n",
            "         -0.2555, -0.0974]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0363, -0.1625,  0.0170, -0.2657,  0.2369], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5P4T63BZWmL",
        "colab_type": "text"
      },
      "source": [
        "Every `nn.Module` has a `.parameter()` function which will return a generator that contains its **trainable parameters**. <br>\n",
        "`nn.Parameter` is a subclass of the `Tensor` class. When we invoke `parameters()` function of a `nn.Module` object, it returns all it's members which are of `nn.Parameter` object.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wOZIqUtave3",
        "colab_type": "code",
        "outputId": "553e63d0-52b2-4882-e4a0-8354d0849b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# if we assign a tensor to nn.Module object, it won't show up in parameter()\n",
        "class net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10,5)\n",
        "        self.tensor = torch.ones(3,4) # this won't show up in parameter list\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net1()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 3.7555e-02, -1.4767e-01,  1.9410e-01,  1.5218e-01,  3.5893e-02,\n",
            "          2.2223e-01,  6.2907e-02, -1.0649e-01, -1.6596e-01, -7.3398e-02],\n",
            "        [ 2.7306e-01, -2.8168e-01,  2.5340e-01, -8.7366e-02,  7.9438e-02,\n",
            "          2.8687e-01, -6.8957e-02,  1.3743e-01, -2.0911e-01,  1.1205e-01],\n",
            "        [-2.5343e-01, -1.5147e-01,  1.1081e-01,  5.5938e-03, -8.1562e-02,\n",
            "          1.9062e-01,  3.1233e-01, -2.4967e-01, -7.3349e-02,  2.7371e-01],\n",
            "        [-1.1500e-01,  1.1376e-01,  2.0995e-01, -3.2674e-02,  1.9078e-01,\n",
            "          1.5551e-04,  1.8036e-01,  1.9926e-01,  1.1221e-01,  2.6856e-01],\n",
            "        [-1.1548e-01,  9.0936e-02, -2.2158e-01,  1.2729e-01,  3.0146e-01,\n",
            "         -2.8080e-01, -1.4860e-01,  5.5613e-02, -5.9475e-02, -2.4967e-01]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.1166,  0.2048,  0.0324,  0.1969,  0.0412], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1KeuZhAbavz",
        "colab_type": "code",
        "outputId": "84d6bda7-5718-4f84-9aab-404eb70591b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# if we assign a parameter to nn.Module object\n",
        "class net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10,5)\n",
        "        self.tensor = nn.Parameter(torch.ones(3,4)) # this will show up in the parameter list later(first tensor)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net2()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.2334,  0.1393,  0.1337,  0.2153, -0.1557,  0.0870,  0.2214, -0.1071,\n",
            "         -0.2104,  0.2835],\n",
            "        [ 0.2420, -0.0492, -0.0207, -0.1436, -0.1048,  0.2308, -0.2629, -0.3126,\n",
            "          0.2198, -0.0791],\n",
            "        [ 0.2438,  0.0797, -0.2304, -0.1093, -0.0235,  0.0010,  0.1841, -0.2489,\n",
            "         -0.0359, -0.2649],\n",
            "        [-0.0340, -0.2460,  0.2960,  0.1572,  0.3124,  0.2922,  0.2609,  0.0740,\n",
            "         -0.1762, -0.2802],\n",
            "        [ 0.1357,  0.3020, -0.2723, -0.0351, -0.2707, -0.2037, -0.2255, -0.3047,\n",
            "         -0.0311,  0.2793]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.0610, -0.2802,  0.0327, -0.2188, -0.1466], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtR3D9OnbqVv",
        "colab_type": "text"
      },
      "source": [
        "### nn.ModuleList and nn.ParameterList()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAgzDHgdeL8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_list = [nn.Conv2d(5,5,3),\n",
        "              nn.BatchNorm2d(5),\n",
        "              nn.Linear(5,2)]\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init___(self):\n",
        "        super().__init__()\n",
        "        self.layers = layer_list\n",
        "    \n",
        "    def forward(x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpUo0jNHesf9",
        "colab_type": "code",
        "outputId": "85eb234f-0dbc-4069-870e-8f2ae3a41f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net = myNet()\n",
        "print(list(net.parameters())) # this wouldn't return of the parameters in the layers we have created"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23REK0_LeyUs",
        "colab_type": "text"
      },
      "source": [
        "We don't have any return because *Python List* does not register the parameters of Modules.<br>\n",
        "For the remedy, we need to wrap the *Python List* with `nn.ModuleList` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDkPZHaefbpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_list = [nn.Conv2d(5,5,3),\n",
        "              nn.BatchNorm2d(5),\n",
        "              nn.Linear(5,2)]\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layer_list)\n",
        "    def forward(x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHi06UlAffyq",
        "colab_type": "code",
        "outputId": "72f680f2-39b6-447f-e2f1-b9310ff88f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "net = myNet()\n",
        "\n",
        "print(list(net.parameters())) # after wrapping layer list with nn.ModuleList"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[[[ 0.0167, -0.0941, -0.0975],\n",
            "          [-0.0904, -0.0776,  0.0857],\n",
            "          [-0.0116, -0.1320,  0.0430]],\n",
            "\n",
            "         [[ 0.0728, -0.0244, -0.1005],\n",
            "          [ 0.0257,  0.1284,  0.1096],\n",
            "          [ 0.1145, -0.0819, -0.1282]],\n",
            "\n",
            "         [[ 0.1166, -0.0895, -0.1362],\n",
            "          [-0.0459,  0.0195,  0.0245],\n",
            "          [ 0.0814, -0.0519, -0.0371]],\n",
            "\n",
            "         [[ 0.0919,  0.0754,  0.0160],\n",
            "          [-0.0700,  0.0950,  0.0453],\n",
            "          [-0.1389,  0.1135, -0.0531]],\n",
            "\n",
            "         [[ 0.0958, -0.0471,  0.0050],\n",
            "          [-0.1152, -0.0286,  0.0719],\n",
            "          [ 0.0336, -0.0494, -0.0293]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1179,  0.0415, -0.1463],\n",
            "          [-0.0612, -0.1056,  0.0241],\n",
            "          [-0.0161, -0.0765,  0.0995]],\n",
            "\n",
            "         [[-0.0059,  0.1078, -0.1028],\n",
            "          [-0.0170, -0.0061, -0.1074],\n",
            "          [-0.1286,  0.0056,  0.0240]],\n",
            "\n",
            "         [[-0.0597, -0.0979, -0.1324],\n",
            "          [-0.0622,  0.1174,  0.0270],\n",
            "          [-0.0173, -0.1064, -0.0431]],\n",
            "\n",
            "         [[ 0.0386, -0.1348, -0.0076],\n",
            "          [ 0.1070, -0.0629,  0.0111],\n",
            "          [ 0.0151, -0.0295,  0.0530]],\n",
            "\n",
            "         [[-0.1064, -0.0686,  0.1454],\n",
            "          [ 0.0011, -0.0232,  0.0659],\n",
            "          [ 0.0268,  0.1320, -0.0444]]],\n",
            "\n",
            "\n",
            "        [[[-0.1220,  0.0218,  0.0136],\n",
            "          [-0.0590,  0.0392,  0.0613],\n",
            "          [-0.0480,  0.1169,  0.0743]],\n",
            "\n",
            "         [[-0.0445, -0.0924, -0.0551],\n",
            "          [ 0.0513, -0.0068,  0.1100],\n",
            "          [ 0.0670,  0.1332, -0.0054]],\n",
            "\n",
            "         [[-0.0541, -0.1093, -0.0921],\n",
            "          [-0.0485,  0.1187,  0.0492],\n",
            "          [-0.0311,  0.0543, -0.1219]],\n",
            "\n",
            "         [[ 0.0774, -0.1421,  0.0443],\n",
            "          [-0.1488,  0.1283, -0.1440],\n",
            "          [-0.0089,  0.0022,  0.0090]],\n",
            "\n",
            "         [[ 0.1130, -0.1350, -0.1069],\n",
            "          [-0.1202, -0.0299,  0.1026],\n",
            "          [-0.0399, -0.0776, -0.1268]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0013, -0.0905, -0.0163],\n",
            "          [ 0.0651,  0.0031, -0.0748],\n",
            "          [ 0.0669, -0.0011,  0.0803]],\n",
            "\n",
            "         [[ 0.1221,  0.1335,  0.0224],\n",
            "          [ 0.0291,  0.0890,  0.0968],\n",
            "          [ 0.0809, -0.0974,  0.1289]],\n",
            "\n",
            "         [[ 0.0758,  0.1371, -0.0081],\n",
            "          [ 0.0657,  0.0799,  0.0603],\n",
            "          [ 0.0641,  0.0263, -0.0336]],\n",
            "\n",
            "         [[ 0.1147, -0.0868, -0.0610],\n",
            "          [-0.0617, -0.0244, -0.1472],\n",
            "          [ 0.1397,  0.0726, -0.0586]],\n",
            "\n",
            "         [[-0.0654, -0.0146,  0.0395],\n",
            "          [ 0.0239,  0.1067, -0.0559],\n",
            "          [ 0.0931, -0.0649, -0.1452]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0899, -0.0259, -0.0607],\n",
            "          [-0.0455,  0.0670, -0.0274],\n",
            "          [-0.1280, -0.0255,  0.0158]],\n",
            "\n",
            "         [[-0.0005,  0.0884,  0.0075],\n",
            "          [ 0.1461, -0.0925, -0.0247],\n",
            "          [-0.1059,  0.0785,  0.0508]],\n",
            "\n",
            "         [[ 0.0347, -0.1076, -0.0024],\n",
            "          [ 0.0234, -0.1016,  0.0453],\n",
            "          [ 0.0397, -0.1220,  0.0948]],\n",
            "\n",
            "         [[ 0.1363,  0.1367,  0.0566],\n",
            "          [-0.0887,  0.0965,  0.0824],\n",
            "          [ 0.1021, -0.1377, -0.1178]],\n",
            "\n",
            "         [[-0.1366, -0.0877, -0.0673],\n",
            "          [ 0.0841, -0.1021, -0.0533],\n",
            "          [-0.0917, -0.1310, -0.1251]]]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0617, 0.1241, 0.0970, 0.0544, 0.0019], requires_grad=True), Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1753,  0.4412,  0.1125,  0.1111,  0.3081],\n",
            "        [ 0.2448,  0.2773, -0.2754, -0.1550,  0.2122]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.3700, -0.3314], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYnRuzlLgBoX",
        "colab_type": "code",
        "outputId": "6a5b2fb2-2859-4774-d206-7517d3d5f633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "net.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki0QJM1rgmXm",
        "colab_type": "text"
      },
      "source": [
        "## 2. Weight Initialization\n",
        "PyTorch offers different weight initialization options for us within `nn.init.`<br>\n",
        "We have `constant_`&`uniform_`; `xavier_constant_`&`xavier_uniform_`; and `Kaiming_constant_`&`Kaiming_uniform`\n",
        "___\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e_XujCRnPTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(10,10,3)\n",
        "        self.bn   = nn.BatchNorm2d(10)\n",
        "\n",
        "    def weights_init(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.normal_(module.weight, mean=0.0, std = 1.0)\n",
        "                nn.init.constant_(module.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyMXqZPind4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Net = myNet()\n",
        "Net.weights_init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7puaykRn-oN",
        "colab_type": "code",
        "outputId": "bb01e7a2-85f0-4cd0-def3-b2309bc54ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "for module in Net.modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        weights = module.weight\n",
        "        weights = weights.reshape(-1).detach().cpu().numpy()\n",
        "        print(module.bias) # chech if biases are all 0\n",
        "        \n",
        "        plt.hist(weights)\n",
        "        plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQg4y5JDTLuktQg4y5JDTLuktSg/wXkQYDR3aIKFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izWNswGfoluH",
        "colab_type": "text"
      },
      "source": [
        "### modules() vs children()\n",
        "The difference of the two is very slight but quite important. <br>\n",
        "As we know, a `nn.Module` object can contain other `nn.Module` objects as it's data members. <br>\n",
        "`nn.children()` will only return an *iterable* of the `nn.Module` objects which are data members. <br>\n",
        "___\n",
        "on the other hand, `nn.Modules` goes *recursively* inside each `nn.Module` object, printing each `nn.Module` object that comes along the way until there are no `nn.module` object left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcSR_Wrmsvje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convBN = nn.Sequential(nn.Conv2d(10,10,3),nn.BatchNorm2d(10))\n",
        "        self.linear = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMiHpjkptGjc",
        "colab_type": "code",
        "outputId": "ca1ef2a6-11b3-4608-f2dc-9e08668c9616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "Net = myNet()\n",
        "print(\"printing children\\n----------------------------------------------\")\n",
        "print(list(Net.children()))\n",
        "print(\"\\n\\nprinting modules\\n---------------------------------------------\")\n",
        "print(list(Net.modules()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "printing children\n",
            "----------------------------------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "), Linear(in_features=10, out_features=2, bias=True)]\n",
            "\n",
            "\n",
            "printing modules\n",
            "---------------------------------------------\n",
            "[myNet(\n",
            "  (convBN): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
            "), Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "), Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Linear(in_features=10, out_features=2, bias=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qHOhGOFtfFS",
        "colab_type": "text"
      },
      "source": [
        "### Summary on printing info about model\n",
        "PyToch provides 4 convinient functions for printing out infomation our model:\n",
        "1. `named_parameters`. Return an *iterator* which gives a tuple containing **name** of the parameters (e.g., `self.conv` would have `conv.weight` and `conv.bias`)\n",
        "2. `named_modules`.  Similar to above but return `modules()` functions\n",
        "3. `named_children`. Similar to above but return `children()`\n",
        "4. `named_buffers`.  Return buffer tensors such as running mean average of a Batch Norm layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huki20dfv5Sv",
        "colab_type": "code",
        "outputId": "7919fa4f-17e3-4951-e4a8-78510fcdc982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "for x in Net.named_modules():\n",
        "  print(x[0], x[1], \"\\n-------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " myNet(\n",
            "  (convBN): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
            ") \n",
            "-------------------------------\n",
            "convBN Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ") \n",
            "-------------------------------\n",
            "convBN.0 Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)) \n",
            "-------------------------------\n",
            "convBN.1 BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
            "-------------------------------\n",
            "linear Linear(in_features=10, out_features=2, bias=True) \n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4NLXnvxwDg_",
        "colab_type": "code",
        "outputId": "be79d44b-3052-42f5-f612-c9801fdfec1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "for x in Net.named_children():\n",
        "  print(x[0], x[1], \"\\n-------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convBN Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ") \n",
            "-------------------------------\n",
            "linear Linear(in_features=10, out_features=2, bias=True) \n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSIJY1RNwWuK",
        "colab_type": "code",
        "outputId": "8cff58d3-6416-442d-c89d-bb67510e33a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "for x in Net.named_children():\n",
        "  print(x[0], \"\\n-------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convBN \n",
            "-------------------------------\n",
            "linear \n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfYHv3YwwhHZ",
        "colab_type": "code",
        "outputId": "337d6656-0f6c-42a6-caf7-58413b62fc78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "for x in Net.named_children():\n",
        "  print(x[1], \"\\n-------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ") \n",
            "-------------------------------\n",
            "Linear(in_features=10, out_features=2, bias=True) \n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDpZgdBwwl4H",
        "colab_type": "text"
      },
      "source": [
        "## Different Learning Rates for Different Layers\n",
        "\n",
        "Now we have a solid fundation to move on to learn how to apply differnt **hyper-parametes** to different layers or layer groups.<br>\n",
        "With this, we will be able to apply different learning rate for each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHcLEK14xTtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10,5)\n",
        "        self.fc2 = nn.Linear(5,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.fc1(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4szPmQoxod_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Net = myNet()\n",
        "optimizer = torch.optim.SGD(Net.parameters(), lr=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7r355b8xvpZ",
        "colab_type": "text"
      },
      "source": [
        "Optionally, we can provide our optimizer with a dictionary of **learnable parameters** and their corresponding **settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkROdkCyW6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD([\n",
        "                             {\"params\":Net.fc1.parameters(), \"lr\": 1e-3, \"momentum\":0.99},\n",
        "                             {\"params\":Net.fc2.parameters(), \"lr\": 1e-2, \"momentum\":0.9 }\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-CayC2IzJ-8",
        "colab_type": "text"
      },
      "source": [
        "## Scheduling Learning Rates\n",
        "PyTorch provides support for **learning rate scheduling** with it's `torch.optim.lr_scheduler` module. It has a variety of learning rate schedules.<br>\n",
        "Fortunately, they are all well commented"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "albFuM0dzz1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,max_lr=1e-3, total_steps=1000, epochs=10,steps_per_epoch=100,pct_start=0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgEcIGc71HEK",
        "colab_type": "text"
      },
      "source": [
        "## GPU monitoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygjVag7Q4tYV",
        "colab_type": "code",
        "outputId": "665aa077-51b2-4c33-d9ff-5fee0781ee9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!pip install gputil"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=c83c395720cc78e046592ea757d6bc3433cb3b2ffea6d614247d153bd3ddafdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Z_o6yj4vnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from GPUtil import showUtilization as gpu_usage\n",
        "# gpu_usage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AC-EWkx404P",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch Hooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAlsdwd2k9fT",
        "colab_type": "text"
      },
      "source": [
        "PyTorch hook is a tool that we can *register* to any **tensor** or **nn.Module** during our computation so that we can monitor what is going on with our `forward` and `backward` loops.<bR>\n",
        "The `forward` is not refered to `nn.Module.forward` bu the `torch.Autograd.Function` object that is the `grad_fn` of a **tensor**.<br>\n",
        "Notice, that a `nn.Module` like `nn.Linear` can have multiple `forward` invocations. It's output is created by two operations, $Y = W*X+B$, *addition* and *multiplication* and thus there will be two `forward` calls. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QmwwVrtlYrC",
        "colab_type": "text"
      },
      "source": [
        "## Hook types\n",
        "1. The Forward Hook\n",
        "2. The Backward Hook\n",
        "\n",
        "A forward hook is excuted during the forward pass, while the backward hook is executed when `backward` function is called both of which are *functions* of `Autograd.Funciton` object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csY3nggBmoFS",
        "colab_type": "text"
      },
      "source": [
        "A hook in PyTorch is basically a funciotn, with a very specific signature. When we say a hook is executed, in reality, we are talkingabout this function being executed.<br>\n",
        "`grad` is basically the value contained in the `grad` attribute of the tensor **after** `backward` is called. The function is not supposed to modify it's argument. It must either return `None` or a Tensor which will be used in place of `grad` for further gradient computations.<br>\n",
        "The below example clarifies this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fylcROOnaFl",
        "colab_type": "code",
        "outputId": "9d179d9f-7c26-4a21-9ef1-4c2e354543ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(10)\n",
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Xp_zlenm5_",
        "colab_type": "code",
        "outputId": "9c85c2a7-0b7e-4f39-eb87-7edc1e98da9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.requires_grad = True\n",
        "a.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1J3XD5UnrYz",
        "colab_type": "code",
        "outputId": "1fb6db2f-5236-42a5-8eb6-8e877c5870d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = 2*a\n",
        "b.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55aeoyTHnxpk",
        "colab_type": "code",
        "outputId": "b0d9fd2d-6bb5-4eaa-914c-7f12fdd51fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(a.is_leaf)\n",
        "print(b.is_leaf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOroG4vFqvMi",
        "colab_type": "text"
      },
      "source": [
        "Since `b` is not a **leaf variable**, its `grad` will by default be destroyed during computation.<br>\n",
        "We can used `b.retain_grad()` to ask PyTorch to retain its `grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8qS1qB9n2Bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.retain_grad()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCRNYObprBQC",
        "colab_type": "code",
        "outputId": "4533aa7b-7394-41b5-cdee-5c7c6a877483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "c = b.mean()\n",
        "print(f\"requires_grad: {c.requires_grad}\")\n",
        "print(f\"is_lead: {c.is_leaf}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requires_grad: True\n",
            "is_lead: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-kxFjBPzbj-",
        "colab_type": "code",
        "outputId": "ebfc560c-f472-4194-eae8-1d9bf9454c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2., grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvmNBroGrMyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9PDclW3rQwJ",
        "colab_type": "code",
        "outputId": "5d736357-8b27-44df-d02e-d478a7bc3f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
            "        0.1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUrZ0g9CrToS",
        "colab_type": "text"
      },
      "source": [
        "Now, we redo the experment but with a **hook** that multiplies `b`'s grad by 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VC0hQrUrnDu",
        "colab_type": "code",
        "outputId": "71464b39-3ccd-46a6-ef0d-b6e6c84efad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.register_hook(lambda x:print(x))\n",
        "b.mean().backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s17QdKvVr3xL",
        "colab_type": "code",
        "outputId": "2e242839-0499-47d1-b8ed-ef00408df049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RdXfxynr50a",
        "colab_type": "code",
        "outputId": "98519b3f-a582-4a9a-d77d-5e87d202cbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgNfqr-9zAYK",
        "colab_type": "code",
        "outputId": "8352078d-f35b-4665-88aa-806452c7334e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sid1DP5dzBGe",
        "colab_type": "text"
      },
      "source": [
        "There are several uses of functionality as above:\n",
        "1. We can print the *value* of gradient for *debugging*. We can also log them. This is especially useful with *non-lead* variables whose gradients are greed up unless we cann `retain_grad`upon them. Dping the latter can lead to increased memory retention. Hooks provide much cleaner way to aggregate these values.\n",
        "2. We can modify gradient **during** the backward pass. This is very important. While we can still access the `grad` variable of a tensor in a network, we can only access it after the **entire** backward pass has been done. For example, we multiplied `b`'s gradient by 2, and now the subsequent gradient calculations, like those of `a`(or any tensor that will depend upon `b` for gradient) use `2*grad(b)` instead of `grad(b)`. In contrast, had we individually updated the parameters **after** the `backward`, we'd have to multiply `b.grad` as well as `a.grad`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxKZAD_a1Gqe",
        "colab_type": "code",
        "outputId": "3a6dc80b-e70c-4b5c-83fd-b1f9016ab390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "a.requires_grad = True\n",
        "b = 2*a\n",
        "b.retain_grad()\n",
        "b.mean().backward()\n",
        "\n",
        "print(a.grad, b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000]) tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqil9Lip1UYD",
        "colab_type": "code",
        "outputId": "a69a597c-2f57-4c23-9269-da5962ea36f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b.grad *= 2\n",
        "\n",
        "print(a.grad, b.grad) # in this case, a's grad needs to be updated mannuly since we modified b's grad after backward is finished."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000]) tensor([0.4000, 0.4000, 0.4000, 0.4000, 0.4000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vjEG4EY1Xf6",
        "colab_type": "text"
      },
      "source": [
        "## Hooks for nn.Module objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQtqUQst1qUK",
        "colab_type": "text"
      },
      "source": [
        "For **backward hook**:\n",
        "`hook(module, grad_input, grad_output)`\n",
        "___\n",
        "For **forward hook**:\n",
        "`hook(module, input, output)`\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnwvMjv52C7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2, stride=2) # (8-2+0)/2+1 = 4\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8-lvydk2_Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Net = myNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6YHumwo3A38",
        "colab_type": "code",
        "outputId": "b6ad5569-98d2-4a74-af1a-6a32e9dc8e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "Net.named_modules"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.named_modules of myNet(\n",
              "  (conv): Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=160, out_features=5, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXjOn1fo3Ces",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hook_fn(m, i, o):\n",
        "    print(m)\n",
        "    print(\"--------Input Grad--------\")\n",
        "\n",
        "    for grad in i:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print(\"None found for input Gradient\")\n",
        "\n",
        "    print(\"--------Output Grad--------\")\n",
        "    for grad in o:\n",
        "        try:\n",
        "            print(grad.shape)\n",
        "        except AttributeError:\n",
        "            print(\"None found for output Gradient\")\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNzkfHs_3ypF",
        "colab_type": "code",
        "outputId": "25ccea45-2949-4b00-e3df-03623686eaa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net.conv.register_backward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f0558643a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bmdvuFN4GXs",
        "colab_type": "code",
        "outputId": "a388c572-471c-498f-97b6-5ccd37a9a921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Net.fc1.register_backward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f05c5ce8c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iVmwPVs4Lze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = torch.rand(1,3,8,8)\n",
        "out = Net(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_s9iGJ4RpO",
        "colab_type": "code",
        "outputId": "84a2c6f6-e70c-4d8a-c3fa-a33ebd49d6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1955,  0.1971, -0.0998, -0.0385, -0.0288], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxcE5fSw4Sf8",
        "colab_type": "code",
        "outputId": "301608d1-1464-4a96-a753-d3bd5cb2f8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "(1-out.mean()).backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=160, out_features=5, bias=True)\n",
            "--------Input Grad--------\n",
            "torch.Size([5])\n",
            "torch.Size([5])\n",
            "--------Output Grad--------\n",
            "torch.Size([5])\n",
            "\n",
            "\n",
            "Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
            "--------Input Grad--------\n",
            "None found for input Gradient\n",
            "torch.Size([10, 3, 2, 2])\n",
            "torch.Size([10])\n",
            "--------Output Grad--------\n",
            "torch.Size([1, 10, 4, 4])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1LmMwZ14WMW",
        "colab_type": "text"
      },
      "source": [
        "## Proper way of implementing Hooks(in **back-prop**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVwGNntK4GVQ",
        "colab_type": "text"
      },
      "source": [
        "We have:\n",
        "1.  torch.autograd.Variable.register_hook (Python method, in Automatic differentiation package\n",
        "2.  torch.nn.Module.register_backward_hook (Python method, in torch.nn)\n",
        "3.  torch.nn.Module.register_forward_hook\n",
        "\n",
        "The first `register_hook`，is for any **Variable**. It's essentially a **callback** function that is going to be executed every time when `Autograd` gradient is computed.<br>\n",
        "While `Module.register_backward_hook` & `n.Module.register_forward_hook` are for `nn.Module` object and their `hook_fn` shoud take torch:\n",
        "<br>`def hook_fn(m, i, o):` where `i` refers to input and `o` refers to output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R3HX-ESrXzc",
        "colab_type": "text"
      },
      "source": [
        "#### An example\n",
        "Using `named_parameters` function we can accomplish *gradient modifying/clipping*.<br>\n",
        "The following example dose two things:\n",
        "1. Turn gradients of linear bises into zero while back-prop (no updates for biase)\n",
        "2. Make sure that for no gradient going to *conv layer* is less than 0 (all positive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utuqUw41r51L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqx8Xlj-vOOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3,10,2,stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1  = nn.Linear(160,5)\n",
        "    def forward(self,x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        x.register_hook(lambda grad: torch.clamp(grad, min=0)) # minimun back-prop gradient of value 0\n",
        "\n",
        "        # print whether there is any negative grad\n",
        "        x.register_hook(lambda grad: print(\"Gradients less than zero:\", bool((grad<0).any())))\n",
        "        \n",
        "        return self.fc1(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojk915howuc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = myNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZOGXSTAwwC-",
        "colab_type": "code",
        "outputId": "faa68cb8-5ca7-46a2-a018-87a0e7650a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    print(name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv.weight\n",
            "conv.bias\n",
            "fc1.weight\n",
            "fc1.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5rAfw0Dw2yl",
        "colab_type": "code",
        "outputId": "f25aea00-6e51-4d20-d951-7d5a62736d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    if 'fc' in name and 'bias' in name:\n",
        "        print(name,param,sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.bias\n",
            "Parameter containing:\n",
            "tensor([-0.0599,  0.0697, -0.0308,  0.0265,  0.0305], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwKMw064xXGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "    if 'fc' in name and 'bias' in name:\n",
        "        param.register_hook(lambda grad: torch.zeros_like(grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_HZkYecxrIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = net(torch.randn(1,3,8,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGFCooSDxwFg",
        "colab_type": "code",
        "outputId": "e38cacd2-e494-4b64-ff52-f2d765aa3fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(1-out).mean().backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients less than zero: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9O-yaFcx6UA",
        "colab_type": "code",
        "outputId": "60f0b07c-e2ac-4807-fcda-cd1f3e61a881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'The biases are: {net.fc1.bias.grad}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The biases are: tensor([0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQiNr5OyCIY",
        "colab_type": "text"
      },
      "source": [
        "## Hook implementation in **forward-prop** for Visualizating activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyxReL_YyYCa",
        "colab_type": "text"
      },
      "source": [
        "The `Tensor` object doesn't have a forward hook, while `nn.Module` objects have one, which is excuted when a `forward` is called.<br>\n",
        "We can use forward hooks to save intermediate feature maps by saving the feature maps to a python variable external to the hook function. See the example below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xq95sKiy7B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualization = {}\n",
        "inp = torch.randn(1,3,8,8)\n",
        "\n",
        "def hook_fn(m, i, o):\n",
        "    visualization[m] = o\n",
        "    print(f'the module is {m}')\n",
        "    print(f'the input  length  is {len(i)}')\n",
        "    print(f'the output length is {(len(o))}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNDCDDhPzV0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = myNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGvQ2JQ8zYy7",
        "colab_type": "code",
        "outputId": "39935ff2-581b-4818-ea7b-075d372c8b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for name, layer in net._modules.items():\n",
        "    print(name,'|', layer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv | Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
            "relu | ReLU()\n",
            "fc1 | Linear(in_features=160, out_features=5, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U6cJau4zeqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, layer in net._modules.items():\n",
        "    layer.register_forward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDOTFamb0CqO",
        "colab_type": "code",
        "outputId": "307dd87d-5c49-40e1-c56e-b13a25ffb331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "out = net(inp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the module is Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
            "the input  length  is 1\n",
            "the output length is 1\n",
            "the module is ReLU()\n",
            "the input  length  is 1\n",
            "the output length is 1\n",
            "the module is Linear(in_features=160, out_features=5, bias=True)\n",
            "the input  length  is 1\n",
            "the output length is 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFfrsBcW0FVU",
        "colab_type": "text"
      },
      "source": [
        "Generally, the `ouput` for a `nn.Module` is the output of the last `forward`. However, the above functionality can be safely replicated without using hooks. Just simply append the intermediate output in the forward function of `nn.Module` object to a list.<br>\n",
        "However, it might be a bit problematic to print the intermediate activation of modules inside `nn.Sequential`. To get past this, we need to register a hook to **children modules** of the Sequential but not to the `Sequential` itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ycqwmp1Qy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv  = nn.Conv2d(3,10,2, stride = 2)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.flatten = lambda x: x.view(-1)\n",
        "        self.fc1   = nn.Linear(160,5)\n",
        "        self.seq   = nn.Sequential(nn.Linear(5,3), nn.Linear(3,2))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.relu(self.conv(x))\n",
        "        x = self.fc1(self.flatten(x))\n",
        "        x = self.seq(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UymiXySa14O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = myNet()\n",
        "visualization={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PGjitm915P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hook_fn(m, i, o):\n",
        "    visualization[m] = o"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL_5ryEs2DdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_layers(net):\n",
        "    for name, layers in net._modules.items():\n",
        "        # It one of the 'item' is a nn.Sequential, no hooks are registered\n",
        "        # therefore, we can recursively register hhok on all it's module children\n",
        "        if isinstance(layers, nn.Sequential):\n",
        "            get_all_layers(layers)\n",
        "        else:\n",
        "            layers.register_forward_hook(hook_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_155EUf2sFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_all_layers(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK9DYY142uWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = net(torch.randn(1,3,8,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-5sMjW52-2h",
        "colab_type": "code",
        "outputId": "1343aadb-8dae-4ddc-a335-a255b195b2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "visualization.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2)), ReLU(), Linear(in_features=160, out_features=5, bias=True), Linear(in_features=5, out_features=3, bias=True), Linear(in_features=3, out_features=2, bias=True)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4HmCMLv3AWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(1, 1)\n",
        "w = torch.randn(1, 1, requires_grad=True)\n",
        "w.register_hook(lambda x: print(f\"w's grad is: {x}\"))\n",
        "y = torch.randn(1, 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgFOwyAR5e4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = x*w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85lB8jQj5ggW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = (out-y)**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLVLOI2R5iqJ",
        "colab_type": "code",
        "outputId": "643bfd7a-5772-4275-afeb-86d568ed3a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss.register_hook(lambda x:print(f'loss is: {x}'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f0558aea860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juT5Lskh5nl-",
        "colab_type": "code",
        "outputId": "a5aa5b2b-22be-4be4-c59f-70923618aa73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss.mean().backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss is: tensor([[1.]])\n",
            "w's grad is: tensor([[-0.3534]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZEGTFpP5qm2",
        "colab_type": "text"
      },
      "source": [
        "## An Toy Example to understand Pytorch Hooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pz6L8onCGPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSfmRQUQCNjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.fc1 = nn.Linear(2,2)\n",
        "        self.s1  = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(2,2)\n",
        "        self.s2  = nn.Sigmoid()\n",
        "        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n",
        "        self.fc1.bias   = torch.nn.Parameter(torch.Tensor([0.35]))\n",
        "        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n",
        "        self.fc2.bias   = torch.nn.Parameter(torch.Tensor([0.6]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.s2(self.fc2(self.s1(self.fc1(x))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdnlo9oCsPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ee1f0e6e-c93b-4ac6-8823-01eba613f527"
      },
      "source": [
        "net = Net()\n",
        "net"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (s1): Sigmoid()\n",
              "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (s2): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9YKCbxdCvMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ba4c858b-d835-4409-93c6-6e96c417541e"
      },
      "source": [
        "list(net.parameters())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.1500, 0.2000],\n",
              "         [0.2500, 0.3000]], requires_grad=True), Parameter containing:\n",
              " tensor([0.3500], requires_grad=True), Parameter containing:\n",
              " tensor([[0.4000, 0.4500],\n",
              "         [0.5000, 0.5500]], requires_grad=True), Parameter containing:\n",
              " tensor([0.6000], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0hSMAUDcFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "45587f47-ee8c-40d1-9d15-b4cda5229b40"
      },
      "source": [
        "weight2 = list(net.parameters())[2]\n",
        "weight2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.4000, 0.4500],\n",
              "        [0.5000, 0.5500]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXbf_zFZEJm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = torch.Tensor([0.05, 0.1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJW37DkEQtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbcebaaf-0c8b-42a0-e3df-ff1b261bf96b"
      },
      "source": [
        "out = net(data)\n",
        "target = torch.Tensor([0.01, 0.99]) # a dummy target, for example\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(out, target)\n",
        "loss"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2984, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRk-XGyTEfA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A simple hook class that returns the input and output of a layer during forward/backward pass\n",
        "class Hook():\n",
        "    def __init__(self, module, backward=False):\n",
        "        if backward==False:\n",
        "            self.hook = module.register_forward_hook(self.hook_fn)\n",
        "        else:\n",
        "            self.hook = module.register_backward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.input = input\n",
        "        self.output = output\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nvgcNqSQc4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "aaa69c1a-c622-4e51-b768-d18e86cc9625"
      },
      "source": [
        "net._modules"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fc1', Linear(in_features=2, out_features=2, bias=True)),\n",
              "             ('s1', Sigmoid()),\n",
              "             ('fc2', Linear(in_features=2, out_features=2, bias=True)),\n",
              "             ('s2', Sigmoid())])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwPKR8BwQfn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9a616c34-08be-4c96-ec45-c6a98012ac27"
      },
      "source": [
        "list(net._modules.items())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fc1', Linear(in_features=2, out_features=2, bias=True)),\n",
              " ('s1', Sigmoid()),\n",
              " ('fc2', Linear(in_features=2, out_features=2, bias=True)),\n",
              " ('s2', Sigmoid())]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG1-IvV1QNY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "e2435bb7-e201-47be-f94c-6aad60c91613"
      },
      "source": [
        "# Register hooks on each layer\n",
        "hookF = [Hook(layer[1]) for layer in list(net._modules.items())]\n",
        "hookB = [Hook(layer[1], backward=True) for layer in list(net._modules.items())]\n",
        "\n",
        "# run a data batch\n",
        "out = net(data)\n",
        "\n",
        "print('***'*3+'Forward Hooks Inputs & Outputs ' + '***'*3)\n",
        "for hook in hookF:\n",
        "    print(f'Input is: {hook.input}, and output is: {hook.output}')\n",
        "    print('---'*10)\n",
        "print('***'*3+'Backward Hook Inputs & Outputs ' + '***'*3)\n",
        "for hook in hookB:\n",
        "    print(f'Input is: {hook.input}, and output is: {hook.output}')\n",
        "    print('---'*10)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*********Forward Hooks Inputs & Outputs *********\n",
            "Input is: (tensor([0.0500, 0.1000]),), and output is: tensor([0.3775, 0.3925], grad_fn=<AddBackward0>)\n",
            "------------------------------\n",
            "Input is: (tensor([0.3775, 0.3925], grad_fn=<AddBackward0>),), and output is: tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward>)\n",
            "------------------------------\n",
            "Input is: (tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward>),), and output is: tensor([1.1059, 1.2249], grad_fn=<AddBackward0>)\n",
            "------------------------------\n",
            "Input is: (tensor([1.1059, 1.2249], grad_fn=<AddBackward0>),), and output is: tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward>)\n",
            "------------------------------\n",
            "*********Backward Hook Inputs & Outputs *********\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-677505f4953c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'***'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Backward Hook Inputs & Outputs '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'***'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhookB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Input is: {hook.input}, and output is: {hook.output}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Hook' object has no attribute 'input'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGIbJ5jdSksU",
        "colab_type": "text"
      },
      "source": [
        "We have an attribute error for the above snippets because we haven't run through the backward pass. Therefore, the backward hook has register anything yet.\n",
        "Below, we add in the line: `out.backward(torch.tensor([1,1]), dtyp=torch.float), retain_graph = True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO4PPVSSR1MC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a14ce60f-2d53-4c70-8987-173b2cdeccac"
      },
      "source": [
        "# Register hooks on each layer\n",
        "hookF = [Hook(layer[1]) for layer in list(net._modules.items())]\n",
        "hookB = [Hook(layer[1], backward=True) for layer in list(net._modules.items())]\n",
        "\n",
        "# run a data batch\n",
        "out = net(data)\n",
        "print(f'The model output is :{out} \\n')\n",
        "\n",
        "print('***'*3+'Forward Hooks Inputs & Outputs ' + '***'*3)\n",
        "for hook in hookF:\n",
        "    print(f'Input is: {hook.input}, and output is: {hook.output}')\n",
        "    print('---'*10)\n",
        "\n",
        "# back-prop here\n",
        "out.backward(torch.tensor([2,2], dtype=torch.float), retain_graph = True)\n",
        "\n",
        "print('***'*3+'Backward Hook Inputs & Outputs ' + '***'*3)\n",
        "for hook in hookB:\n",
        "    print(f'Input is: {hook.input}, and output is: {hook.output}')\n",
        "    print('---'*10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model output is :tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward>) \n",
            "\n",
            "*********Forward Hooks Inputs & Outputs *********\n",
            "Input is: (tensor([0.0500, 0.1000]),), and output is: tensor([0.3775, 0.3925], grad_fn=<AddBackward0>)\n",
            "------------------------------\n",
            "Input is: (tensor([0.3775, 0.3925], grad_fn=<AddBackward0>),), and output is: tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward>)\n",
            "------------------------------\n",
            "Input is: (tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward>),), and output is: tensor([1.1059, 1.2249], grad_fn=<AddBackward0>)\n",
            "------------------------------\n",
            "Input is: (tensor([1.1059, 1.2249], grad_fn=<AddBackward0>),), and output is: tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward>)\n",
            "------------------------------\n",
            "*********Backward Hook Inputs & Outputs *********\n",
            "Input is: (tensor([0.0784, 0.0869]), tensor([0.1653])), and output is: (tensor([0.0784, 0.0869]),)\n",
            "------------------------------\n",
            "Input is: (tensor([0.0784, 0.0869]),), and output is: (tensor([0.3250, 0.3612]),)\n",
            "------------------------------\n",
            "Input is: (tensor([0.3736, 0.3510]), tensor([0.7247])), and output is: (tensor([0.3736, 0.3510]),)\n",
            "------------------------------\n",
            "Input is: (tensor([0.3736, 0.3510]),), and output is: (tensor([2., 2.]),)\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxQuFuGmY0Al",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "badeb4cb-4a25-4525-e872-2e63563526c3"
      },
      "source": [
        "hookB[0].input"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0784, 0.0869]), tensor([0.1653]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj79mQvlSOgy",
        "colab_type": "text"
      },
      "source": [
        "## Interpretation of **Input** and **Output** of forward and backward passes\n",
        "Things to notice:\n",
        "1. Because backward pass runs from back to the start, it's **parameter order** should be reversed compared to the forward pass. Therefore, to be clearer, we will be using a different *naming convention* below.\n",
        "2. For forward pass, **previous layer** of layer 2 is layer1; for backward pass, previous layer 2 is layer 3.\n",
        "3. **Model output** is the output of the last layer in for ward pass.<br>\n",
        "<br>\n",
        "\n",
        "`layer.register_forward_hook(module, input, output)`:\n",
        "* **Input**:  previous layer's output\n",
        "* **Output**: current layer's output\n",
        "    <br>\n",
        "\n",
        "`layer.register_backward_hook(module, grad_out, grad_in)`:\n",
        "* **Grad_in**: gradien of model output *w.r.t* layer output # from forward pass\n",
        "    * a tensor that represent the **error of each neuron in this layer** (= gradient of modeul output *w.r.t* layer output = how much it should be improved before learning rate)\n",
        "    * For the last layer: e.g. [2,2] <=> gradient of model output *w.r.t* itself, which means calculate all gradients as normal.\n",
        "    * It can also be considered as a weight map: e.g. [1, 0] turn off the secon gradient; [2,1] put double weight on first gradient etc.\n",
        "\n",
        "* **Grad_out**: Grad_in*(gradient of layer output *w.r.t* layer input)\n",
        "    * =**next layer's error** (due to the chain rule)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_yCG14U6oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c9214cc-6190-44be-9828-772f987aef37"
      },
      "source": [
        "# Comfirm the calculation with the print results above\n",
        "# the 4th layer - sigmoid\n",
        "\n",
        "forward_output = np.array([0.7514, 0.7729])\n",
        "grad_in = np.array([2,2])  # Sigmoid layer\n",
        "\n",
        "# grad of sigmoid(x) wrt x is: sigmoid(x)(1-sigmoid(x))\n",
        "grad_out = grad_in*(forward_output*(1-forward_output)); grad_out"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.37359608, 0.35105118])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVX3zYUZ2Uv",
        "colab_type": "text"
      },
      "source": [
        "## Modify the gradients with hooks\n",
        "* Hook function doesn't change gradients by default\n",
        "* But if **return** is called, the returned value will be the gradient output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZqgp3lPbguF",
        "colab_type": "text"
      },
      "source": [
        "### Guided backpropagation with hooks - Visualize CNN(deconv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHzJ36qtb2nG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Guided_backprop():\n",
        "    \"\"\"\n",
        "    Visualize CNN activation maps with guided backprop.\n",
        "    Return: An image that represent what the network learnt for reconizing the given image.\n",
        "    Methods: First layer input that minimize the error between the last layer's output, for the given class, and the true label(=1)\n",
        "\n",
        "    ! Call visualize(image) to get the image representation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.image_reconstruction = None\n",
        "        self.activation_maps = []\n",
        "\n",
        "        # eval mode\n",
        "        self.model.eval()\n",
        "        self.register_hooks()\n",
        "\n",
        "    def register_hooks(self):\n",
        "        # change the modules\n",
        "        modules = list(self.model.features._modules.items())\n",
        "\n",
        "        # register hooks to relu layers\n",
        "        for name, module in modules:\n",
        "            if isinstance(module, nn.ReLU):\n",
        "                module.register_forward_hook(forward_hook_fn)\n",
        "                module.register_backward_hook(backward_hook_fn)\n",
        "\n",
        "        # register hook to the first layer\n",
        "        first_layer = modules[0][1]\n",
        "        first_layer.register_backward_hook(first_layer_hook_fn)\n",
        "\n",
        "        def first_layer_hook_fn(module, grad_out, grad_in):\n",
        "            \"\"\"\n",
        "            Return reconstructed activation image\n",
        "            \"\"\"\n",
        "            self.image_reconstruction = grad_out[0]\n",
        "\n",
        "        def forward_hook_fn(module, input, output):\n",
        "            \"\"\"\n",
        "            Stores the forwrad pass outputs (activation maps)\n",
        "            \"\"\"\n",
        "            self.activation_maps.append(output)\n",
        "        \n",
        "        def backwrad_hook_fn(module, grad_out, grad_in):\n",
        "            \"\"\"\n",
        "            Output the grad of model output w.r.t layer (only positive)\n",
        "            \"\"\"\n",
        "            # Gradient of forward_output w.r.t forward_input = error of activation om map:\n",
        "            # for relu layer: grad of zero = 0, grad of identity = 1\n",
        "            grad = self.activation_maps[-1] # corresponding forward pass output\n",
        "            grad[grad>0] = 1  # grad of reln when > 0\n",
        "\n",
        "            # set negative output gradient to 0 #!???\n",
        "            positive_grad_out = torch.clamp(input=grad_out[0], min=0.)\n",
        "\n",
        "            # backward grad_out = grad_out*(grad of forward output w.r.t forward input)\n",
        "            new_grad_out = positive_grad_out*grad\n",
        "\n",
        "            del self.forwrad_output[-1]\n",
        "\n",
        "            # For hook function, the returned value will be the new grad_out\n",
        "            return (new_grad_out,)\n",
        "    \n",
        "    def visualize(self, input_image, target_class):\n",
        "        # last Layer output\n",
        "        model_output = self.model(input_image)\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        # only calculate gradient w.r.t target class\n",
        "        # set the other classes to 0:  e.g. [0,0,1]\n",
        "        grad_target_map = torch.zeros(model_output.shape, dtype=torch.float)\n",
        "        grad_target_map[0][target_class] = 1\n",
        "\n",
        "        model_output.backward(grad_target_map)\n",
        "\n",
        "        # Convert Pytorch variable to numpy array\n",
        "        # [0] to get rid of the first channel (1,3,224,224)\n",
        "        result = self.image_reconstruction.data.numpy()[0]\n",
        "        return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wynp1L3K2OlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8746323d-f742-44d6-df78-26f042deb0e1"
      },
      "source": [
        "import torchvision\n",
        "model = torchvision.models.vgg16(pretrained=True)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:20<00:00, 27.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB_xaVZw2PbR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "18fcb327-e352-456e-ac1d-8641c534edae"
      },
      "source": [
        "model.features"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU(inplace=True)\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU(inplace=True)\n",
              "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): ReLU(inplace=True)\n",
              "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (18): ReLU(inplace=True)\n",
              "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (20): ReLU(inplace=True)\n",
              "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (25): ReLU(inplace=True)\n",
              "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (27): ReLU(inplace=True)\n",
              "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiVWBziF2nyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f22cde51-4165-4dbc-9177-72595c102082"
      },
      "source": [
        "model.features._modules.items()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_items([('0', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('1', ReLU(inplace=True)), ('2', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('3', ReLU(inplace=True)), ('4', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('5', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('6', ReLU(inplace=True)), ('7', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('8', ReLU(inplace=True)), ('9', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('10', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('11', ReLU(inplace=True)), ('12', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('13', ReLU(inplace=True)), ('14', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('15', ReLU(inplace=True)), ('16', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('17', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('18', ReLU(inplace=True)), ('19', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('20', ReLU(inplace=True)), ('21', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('22', ReLU(inplace=True)), ('23', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('24', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('25', ReLU(inplace=True)), ('26', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('27', ReLU(inplace=True)), ('28', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('29', ReLU(inplace=True)), ('30', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5ax9kwM3g0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d6cec5f-47e3-4b66-bd72-0d0965c43ec2"
      },
      "source": [
        "len(model.features._modules.items())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFc7kJdP38XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modules = list(model.features._modules.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9exW3sRL7BHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bd3df27-0ce6-41e2-e29b-ef7679c60043"
      },
      "source": [
        "modules[0][1]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8hBdsfA7De1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}